{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1527bc09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Playdata2\\miniconda3\\envs\\final-env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import requests\n",
    "import joblib\n",
    "import numpy as np\n",
    "import torch\n",
    "from typing import TypedDict, List, Optional, Dict, Any, Tuple\n",
    "from dotenv import load_dotenv\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a62648",
   "metadata": {},
   "source": [
    "# LLM Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29ec55f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 1) .env에서 OPENAI_API_KEY 불러오기\n",
    "load_dotenv()\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# 2) 프롬프트 정의\n",
    "parse_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"너는 향수 쿼리 파서야.\n",
    "사용자의 질문에서 다음 정보를 JSON 형식으로 추출해줘:\n",
    "- brand: 브랜드명 (예: 샤넬, 디올, 입생로랑 등)\n",
    "- concentration: (퍼퓸, 코롱 등)\n",
    "- day_night_score: 사용시간 (주간, 야간, 데일리 등)\n",
    "- gender: 성별 (남성, 여성, 유니섹스)\n",
    "- season_score: 계절 (봄, 여름, 가을, 겨울)\n",
    "- sizes: 용량 (30ml, 50ml, 100ml 등) 단위는 무시하고 숫자만\n",
    "\n",
    "없는 값은 null로 두고, 반드시 유효한 JSON 형식으로만 응답해줘.\n",
    "\n",
    "예시:\n",
    "{{\"brand\": \"샤넬\", \"gender\": null, \"sizes\": \"50ml\", \"season_score\": null, \"concentration\": null, \"day_night_score\": null}}\"\"\"),\n",
    "    (\"user\", \"{query}\")\n",
    "])\n",
    "\n",
    "def run_llm_parser(query: str):\n",
    "    chain = parse_prompt | llm\n",
    "    ai_response = chain.invoke({\"query\": query})\n",
    "    response_text = ai_response.content.strip()\n",
    "\n",
    "    # JSON 부분만 추출\n",
    "    if \"```json\" in response_text:\n",
    "        response_text = response_text.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "    elif \"```\" in response_text:\n",
    "        response_text = response_text.split(\"```\")[1].strip()\n",
    "\n",
    "    parsed = json.loads(response_text)\n",
    "    return parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f31932e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 쿼리: 딥띠크 50ml 향수 있어?\n",
      "파싱 결과: {\n",
      "  \"brand\": \"딥띠크\",\n",
      "  \"gender\": null,\n",
      "  \"sizes\": \"50\",\n",
      "  \"season_score\": null,\n",
      "  \"concentration\": null,\n",
      "  \"day_night_score\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3) 테스트 실행\n",
    "if __name__ == \"__main__\":\n",
    "    query = \"딥띠크 50ml 향수 있어?\"\n",
    "    parsed = run_llm_parser(query)\n",
    "    print(\"원본 쿼리:\", query)\n",
    "    print(\"파싱 결과:\", json.dumps(parsed, ensure_ascii=False, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f990886e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, json\n",
    "\n",
    "# ---- 메타필터 함수들 ----\n",
    "def filter_brand(brand_value):\n",
    "    valid_brands = [\n",
    "        '겔랑', '구찌', '끌로에', '나르시소 로드리게즈', '니샤네', '도르세', '디올', '딥티크', '랑콤',\n",
    "        '로라 메르시에', '로에베', '록시땅', '르 라보', '메모', '메종 마르지엘라', '메종 프란시스 커정',\n",
    "        '멜린앤게츠', '미우미우', '바이레도', '반클리프 아펠', '버버리', '베르사체', '불가리', '비디케이',\n",
    "        '산타 마리아 노벨라', '샤넬', '세르주 루텐', '시슬리 코스메틱', '아쿠아 디 파르마', '에따 리브르 도량쥬',\n",
    "        '에르메스', '에스티 로더', '엑스 니힐로', '이니시오 퍼퓸', '이솝', '입생로랑', '제르조프', '조 말론',\n",
    "        '조르지오 아르마니', '줄리엣 헤즈 어 건', '지방시', '질 스튜어트', '크리드', '킬리안', '톰 포드',\n",
    "        '티파니앤코', '퍼퓸 드 말리', '펜할리곤스', '프라다', '프레데릭 말'\n",
    "    ]\n",
    "    if brand_value is None:\n",
    "        return None\n",
    "    return brand_value if brand_value in valid_brands else None\n",
    "\n",
    "\n",
    "def filter_concentration(concentration_value):\n",
    "    valid_concentrations = ['솔리드 퍼퓸', '엑스트레 드 퍼퓸', '오 드 뚜왈렛', '오 드 코롱', '오 드 퍼퓸', '퍼퓸']\n",
    "    if concentration_value is None:\n",
    "        return None\n",
    "    return concentration_value if concentration_value in valid_concentrations else None\n",
    "\n",
    "\n",
    "def filter_day_night_score(day_night_value):\n",
    "    valid_day_night = [\"day\", \"night\"]\n",
    "    if day_night_value is None:\n",
    "        return None\n",
    "    if isinstance(day_night_value, str) and ',' in day_night_value:\n",
    "        values = [v.strip() for v in day_night_value.split(',')]\n",
    "        filtered_values = [v for v in values if v in valid_day_night]\n",
    "        return ','.join(filtered_values) if filtered_values else None\n",
    "    return day_night_value if day_night_value in valid_day_night else None\n",
    "\n",
    "\n",
    "def filter_gender(gender_value):\n",
    "    valid_genders = ['Female', 'Male', 'Unisex', 'unisex ']\n",
    "    if gender_value is None:\n",
    "        return None\n",
    "    return gender_value if gender_value in valid_genders else None\n",
    "\n",
    "\n",
    "def filter_season_score(season_value):\n",
    "    valid_seasons = ['winter', 'spring', 'summer', 'fall']\n",
    "    if season_value is None:\n",
    "        return None\n",
    "    return season_value if season_value in valid_seasons else None\n",
    "\n",
    "\n",
    "def filter_sizes(sizes_value):\n",
    "    \"\"\"숫자만 추출해서 유효값인지 확인\"\"\"\n",
    "    valid_sizes = ['30', '50', '75', '100', '150']\n",
    "    if sizes_value is None:\n",
    "        return None\n",
    "    if isinstance(sizes_value, str):\n",
    "        numbers = re.findall(r'\\d+', sizes_value)\n",
    "        for num in numbers:\n",
    "            if num in valid_sizes:\n",
    "                return num\n",
    "    return str(sizes_value) if str(sizes_value) in valid_sizes else None\n",
    "\n",
    "\n",
    "def apply_meta_filters(parsed_json: dict) -> dict:\n",
    "    \"\"\"파싱된 JSON에 메타필터링 적용\"\"\"\n",
    "    if not parsed_json or \"error\" in parsed_json:\n",
    "        return parsed_json\n",
    "    \n",
    "    return {\n",
    "        'brand': filter_brand(parsed_json.get('brand')),\n",
    "        'concentration': filter_concentration(parsed_json.get('concentration')),\n",
    "        'day_night_score': filter_day_night_score(parsed_json.get('day_night_score')),\n",
    "        'gender': filter_gender(parsed_json.get('gender')),\n",
    "        'season_score': filter_season_score(parsed_json.get('season_score')),\n",
    "        'sizes': filter_sizes(parsed_json.get('sizes'))\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a788cfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "import os\n",
    "\n",
    "# Pinecone 초기화\n",
    "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "\n",
    "# perfume-vectordb2 인덱스 지정\n",
    "index = pc.Index(\"perfume-vectordb2\")\n",
    "\n",
    "\n",
    "def build_pinecone_filter(filtered_json: dict) -> dict:\n",
    "    \"\"\"\n",
    "    메타필터링 결과를 Pinecone filter dict로 변환\n",
    "    \"\"\"\n",
    "    pinecone_filter = {}\n",
    "    if filtered_json.get(\"brand\"):\n",
    "        pinecone_filter[\"brand\"] = {\"$eq\": filtered_json[\"brand\"]}\n",
    "    if filtered_json.get(\"sizes\"):\n",
    "        pinecone_filter[\"sizes\"] = {\"$eq\": filtered_json[\"sizes\"]}\n",
    "    if filtered_json.get(\"season_score\"):\n",
    "        pinecone_filter[\"season_score\"] = {\"$eq\": filtered_json[\"season_score\"]}\n",
    "    if filtered_json.get(\"gender\"):\n",
    "        pinecone_filter[\"gender\"] = {\"$eq\": filtered_json[\"gender\"]}\n",
    "    if filtered_json.get(\"concentration\"):\n",
    "        pinecone_filter[\"concentration\"] = {\"$eq\": filtered_json[\"concentration\"]}\n",
    "    if filtered_json.get(\"day_night_score\"):\n",
    "        pinecone_filter[\"day_night_score\"] = {\"$eq\": filtered_json[\"day_night_score\"]}\n",
    "    return pinecone_filter\n",
    "\n",
    "\n",
    "def query_pinecone(vector, filtered_json: dict, top_k: int = 5):\n",
    "    \"\"\"\n",
    "    Pinecone 벡터 검색 + 메타데이터 필터 적용\n",
    "    \"\"\"\n",
    "    pinecone_filter = build_pinecone_filter(filtered_json)\n",
    "\n",
    "    result = index.query(\n",
    "        vector=vector,\n",
    "        top_k=top_k,\n",
    "        include_metadata=True,\n",
    "        filter=pinecone_filter if pinecone_filter else None\n",
    "    )\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0864ab27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기서 부터 혼돈시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b28be830",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Playdata2\\miniconda3\\envs\\final-env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 검색된 문서들 ===\n",
      "\n",
      "[1]\n",
      "{\n",
      "  \"id\": \"perfume_3009ee702f886c68\",\n",
      "  \"brand\": \"딥티크\",\n",
      "  \"concentration\": \"오 드 뚜왈렛\",\n",
      "  \"day_night_score\": \"night\",\n",
      "  \"gender\": \"Unisex\",\n",
      "  \"name\": \"오 데 썽 오 드 뚜왈렛\",\n",
      "  \"no\": 143.0,\n",
      "  \"season_score\": \"winter\",\n",
      "  \"sizes\": [\n",
      "    \"50\",\n",
      "    \"100\"\n",
      "  ],\n",
      "  \"text\": \"감각의 물 또는 에센스의 물로 해석되는 향\"\n",
      "}\n",
      "\n",
      "[2]\n",
      "{\n",
      "  \"id\": \"perfume_8c25220938bc55f8\",\n",
      "  \"brand\": \"딥티크\",\n",
      "  \"concentration\": \"오 드 뚜왈렛\",\n",
      "  \"day_night_score\": \"night\",\n",
      "  \"gender\": \"Unisex\",\n",
      "  \"name\": \"필로시코스 오 드 뚜왈렛\",\n",
      "  \"no\": 161.0,\n",
      "  \"season_score\": \"spring\",\n",
      "  \"sizes\": [\n",
      "    \"50\",\n",
      "    \"100\"\n",
      "  ],\n",
      "  \"text\": \"신선하고 달콤한 무화과의 모든것을 느낄 수 있는 향\"\n",
      "}\n",
      "\n",
      "[3]\n",
      "{\n",
      "  \"id\": \"perfume_3e3c134ca8e46fac\",\n",
      "  \"brand\": \"딥티크\",\n",
      "  \"concentration\": \"오 드 뚜왈렛\",\n",
      "  \"day_night_score\": \"day\",\n",
      "  \"gender\": \"Unisex\",\n",
      "  \"name\": \"롬브르 단 로 오 드 뚜왈렛\",\n",
      "  \"no\": 138.0,\n",
      "  \"season_score\": \"spring\",\n",
      "  \"sizes\": [\n",
      "    \"50\",\n",
      "    \"100\"\n",
      "  ],\n",
      "  \"text\": \"비 오는 날 뿌리기 좋은 쌉싸름한 장미잎향\"\n",
      "}\n",
      "\n",
      "[4]\n",
      "{\n",
      "  \"id\": \"perfume_d52dc5f679a0ff96\",\n",
      "  \"brand\": \"딥티크\",\n",
      "  \"concentration\": \"오 드 뚜왈렛\",\n",
      "  \"day_night_score\": \"day\",\n",
      "  \"gender\": \"Unisex\",\n",
      "  \"name\": \"도손 오 드 뚜왈렛\",\n",
      "  \"no\": 132.0,\n",
      "  \"season_score\": \"spring\",\n",
      "  \"sizes\": [\n",
      "    \"50\",\n",
      "    \"100\"\n",
      "  ],\n",
      "  \"text\": \"미풍에 불어온 튜베로즈의 향기\"\n",
      "}\n",
      "\n",
      "[5]\n",
      "{\n",
      "  \"id\": \"perfume_4f3f344dea2a270f\",\n",
      "  \"brand\": \"딥티크\",\n",
      "  \"concentration\": \"오 드 뚜왈렛\",\n",
      "  \"day_night_score\": \"day\",\n",
      "  \"gender\": \"Unisex\",\n",
      "  \"name\": \"로 파피에 오 드 뚜왈렛\",\n",
      "  \"no\": 137.0,\n",
      "  \"season_score\": \"fall\",\n",
      "  \"sizes\": [\n",
      "    \"50\"\n",
      "  ],\n",
      "  \"text\": \"머스크의 중심에 더해진 다양한 단면들을 보여 주는 향기의 만남\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# pip install -U pinecone-client openai python-dotenv\n",
    "import os, json\n",
    "from typing import Dict, Any, List\n",
    "from dotenv import load_dotenv\n",
    "from pinecone import Pinecone, PineconeApiException\n",
    "from openai import OpenAI\n",
    "\n",
    "# ========= 0) ENV & CLIENTS =========\n",
    "load_dotenv()\n",
    "oa = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "index = pc.Index(\"perfume-vectordb2\")\n",
    "EMBED_MODEL = \"text-embedding-3-small\"\n",
    "\n",
    "# ========= 1) FILTER BUILDER =========\n",
    "def build_pinecone_filter(filtered_json: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Pinecone 메타필터.\n",
    "    - sizes: 배열/스칼라 모두 커버하기 위해 $in 사용 ([\"50\"] 형태)\n",
    "    - 나머지는 $eq\n",
    "    \"\"\"\n",
    "    f: Dict[str, Any] = {}\n",
    "    if filtered_json.get(\"brand\"):\n",
    "        f[\"brand\"] = {\"$eq\": filtered_json[\"brand\"]}\n",
    "    if filtered_json.get(\"sizes\"):\n",
    "        f[\"sizes\"] = {\"$in\": [str(filtered_json[\"sizes\"])]}  # 배열/스칼라 모두 안전\n",
    "    if filtered_json.get(\"season_score\"):\n",
    "        f[\"season_score\"] = {\"$eq\": filtered_json[\"season_score\"]}\n",
    "    if filtered_json.get(\"gender\"):\n",
    "        f[\"gender\"] = {\"$eq\": filtered_json[\"gender\"]}\n",
    "    if filtered_json.get(\"concentration\"):\n",
    "        f[\"concentration\"] = {\"$eq\": filtered_json[\"concentration\"]}\n",
    "    if filtered_json.get(\"day_night_score\"):\n",
    "        f[\"day_night_score\"] = {\"$eq\": filtered_json[\"day_night_score\"]}\n",
    "    return f\n",
    "\n",
    "# ========= 2) QUERY =========\n",
    "def query_pinecone(vector: List[float], filtered_json: Dict[str, Any], top_k: int = 5):\n",
    "    \"\"\"\n",
    "    Pinecone 쿼리 (메타필터 + 문서 메타데이터 포함).\n",
    "    필터 오류 시 sizes 필터 제거 후 재시도하고, 결과는 클라이언트에서 후필터링.\n",
    "    \"\"\"\n",
    "    primary_filter = build_pinecone_filter(filtered_json) or None\n",
    "    try:\n",
    "        return index.query(\n",
    "            vector=vector,\n",
    "            top_k=top_k,\n",
    "            include_metadata=True,\n",
    "            filter=primary_filter\n",
    "        )\n",
    "    except PineconeApiException as e:\n",
    "        # 필터 연산/타입 이슈 등으로 400이 날 수 있으므로 sizes만 제거하고 재시도\n",
    "        if primary_filter and \"sizes\" in primary_filter:\n",
    "            fallback_filter = dict(primary_filter)\n",
    "            fallback_filter.pop(\"sizes\", None)\n",
    "            res = index.query(\n",
    "                vector=vector,\n",
    "                top_k=top_k,\n",
    "                include_metadata=True,\n",
    "                filter=fallback_filter if fallback_filter else None\n",
    "            )\n",
    "            # 클라이언트 후필터: sizes 일치만 남김\n",
    "            want_size = str(filtered_json.get(\"sizes\"))\n",
    "            if want_size:\n",
    "                res[\"matches\"] = [\n",
    "                    m for m in res.get(\"matches\", [])\n",
    "                    if want_size in (m.get(\"metadata\", {}).get(\"sizes\") or [])\n",
    "                    or str(m.get(\"metadata\", {}).get(\"sizes\")) == want_size\n",
    "                ]\n",
    "            return res\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "# ========= 3) PRETTY PRINT =========\n",
    "def print_docs_only(res):\n",
    "    print(\"=== 검색된 문서들 ===\")\n",
    "    for i, m in enumerate(res.get(\"matches\", []), start=1):\n",
    "        meta = m.get(\"metadata\", {}) or {}\n",
    "        doc = {\"id\": m.get(\"id\")}\n",
    "        doc.update(meta)\n",
    "        print(f\"\\n[{i}]\")\n",
    "        print(json.dumps(doc, ensure_ascii=False, indent=2))\n",
    "\n",
    "# ========= 4) DEMO =========\n",
    "if __name__ == \"__main__\":\n",
    "    filtered = {\n",
    "        \"brand\": \"딥티크\",\n",
    "        \"concentration\": None,\n",
    "        \"day_night_score\": None,\n",
    "        \"gender\": None,\n",
    "        \"season_score\": None,\n",
    "        \"sizes\": \"50\"\n",
    "    }\n",
    "    query_text = \"딥티크 50ml 향수 있어?\"\n",
    "\n",
    "    embed = oa.embeddings.create(model=EMBED_MODEL, input=query_text)\n",
    "    vector = embed.data[0].embedding\n",
    "\n",
    "    res = query_pinecone(vector, filtered, top_k=5)\n",
    "    print_docs_only(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f831afc2",
   "metadata": {},
   "source": [
    "# LLM parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4f81b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "🔍 사용자 쿼리: 샤넬 50ml 여성용 향수 추천해줘\n",
      "\n",
      "1️⃣ 쿼리 파싱 중...\n",
      "파싱 결과: {\n",
      "  \"brand\": \"샤넬\",\n",
      "  \"gender\": \"여성\",\n",
      "  \"sizes\": \"50\",\n",
      "  \"season_score\": null,\n",
      "  \"concentration\": null,\n",
      "  \"day_night_score\": null\n",
      "}\n",
      "\n",
      "2️⃣ 메타필터 적용 중...\n",
      "필터링 결과: {\n",
      "  \"brand\": \"샤넬\",\n",
      "  \"concentration\": null,\n",
      "  \"day_night_score\": null,\n",
      "  \"gender\": null,\n",
      "  \"season_score\": null,\n",
      "  \"sizes\": \"50\"\n",
      "}\n",
      "\n",
      "3️⃣ 쿼리 벡터화 중...\n",
      "벡터 차원: 1536\n",
      "\n",
      "4️⃣ 벡터 검색 중...\n",
      "검색된 향수 개수: 5\n",
      "\n",
      "5️⃣ 최종 응답 생성 중...\n",
      "\n",
      "🎯 최종 추천:\n",
      "안녕하세요! 샤넬의 50ml 여성용 향수를 찾고 계시군요. 여러 옵션이 있지만, 제가 추천드리고 싶은 향수는 **샤넬의 오 드 퍼퓸**입니다. \n",
      "\n",
      "### 추천 이유\n",
      "샤넬은 고급스러움과 우아함을 상징하는 브랜드로, 그들의 향수는 항상 뛰어난 품질과 독창성을 자랑합니다. 특히 오 드 퍼퓸은 농도가 높아 향이 오래 지속되며, 깊이 있는 향을 즐길 수 있습니다.\n",
      "\n",
      "### 향의 특징과 느낌\n",
      "이 향수는 가을에 잘 어울리는 따뜻하고 풍부한 향을 가지고 있습니다. 일반적으로 샤넬의 오 드 퍼퓸은 플로럴과 우디 노트가 조화를 이루며, 부드럽고 세련된 느낌을 줍니다. 특히, 여성스러움을 강조하면서도 강렬한 인상을 남기는 매력이 있습니다.\n",
      "\n",
      "### 적합한 상황\n",
      "이 향수는 주로 낮에 사용하기 적합합니다. 일상적인 외출이나 직장, 혹은 특별한 모임에서도 잘 어울립니다. 가을의 쌀쌀한 날씨와 함께하면 더욱 매력적인 향을 발산할 수 있습니다.\n",
      "\n",
      "### 가격대 및 용량 조언\n",
      "50ml 용량은 일반적으로 사용하기에 적당한 사이즈로, 가격대는 보통 10만원대 중반에서 후반에 형성되어 있습니다. 샤넬의 향수는 품질이 뛰어나기 때문에, 이 가격대는 충분히 가치가 있다고 생각합니다. \n",
      "\n",
      "이 향수는 당신의 매력을 한층 더 돋보이게 해줄 것입니다. 향수 구매 시 꼭 테스트해보시고, 본인에게 잘 어울리는지 확인해보세요! 궁금한 점이 더 있다면 언제든지 물어보세요. 😊\n",
      "\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "🔍 사용자 쿼리: 겨울에 사용하기 좋은 남성 향수가 뭐가 있을까?\n",
      "\n",
      "1️⃣ 쿼리 파싱 중...\n",
      "파싱 결과: {\n",
      "  \"brand\": null,\n",
      "  \"gender\": \"남성\",\n",
      "  \"sizes\": null,\n",
      "  \"season_score\": \"겨울\",\n",
      "  \"concentration\": null,\n",
      "  \"day_night_score\": null\n",
      "}\n",
      "\n",
      "2️⃣ 메타필터 적용 중...\n",
      "필터링 결과: {\n",
      "  \"brand\": null,\n",
      "  \"concentration\": null,\n",
      "  \"day_night_score\": null,\n",
      "  \"gender\": null,\n",
      "  \"season_score\": null,\n",
      "  \"sizes\": null\n",
      "}\n",
      "\n",
      "3️⃣ 쿼리 벡터화 중...\n",
      "벡터 차원: 1536\n",
      "\n",
      "4️⃣ 벡터 검색 중...\n",
      "검색된 향수 개수: 5\n",
      "\n",
      "5️⃣ 최종 응답 생성 중...\n",
      "\n",
      "🎯 최종 추천:\n",
      "겨울에 사용하기 좋은 남성 향수로는 **딥티크**의 향수를 추천해드릴게요! \n",
      "\n",
      "### 추천 이유\n",
      "딥티크는 고급스러운 향수로 유명한 브랜드이며, 겨울철에 잘 어울리는 따뜻하고 포근한 느낌을 주는 향을 가지고 있습니다. 특히, 겨울에는 따뜻한 향이 더욱 매력적으로 다가오죠.\n",
      "\n",
      "### 향의 특징과 느낌\n",
      "딥티크의 향수는 주로 우디하고 스파이시한 노트를 포함하고 있어, 차분하면서도 깊이 있는 향을 제공합니다. 이 향수는 겨울의 차가운 공기 속에서도 따뜻함을 느낄 수 있게 해주며, 부드러운 감촉과 함께 감각적인 매력을 더해줍니다.\n",
      "\n",
      "### 적합한 상황\n",
      "이 향수는 주로 낮에 사용하기 적합하며, 일상적인 외출이나 특별한 모임에서도 잘 어울립니다. 특히, 겨울철의 실내에서 친구들과의 만남이나 데이트에 적합한 선택이 될 것입니다.\n",
      "\n",
      "### 가격대 및 용량\n",
      "딥티크의 향수는 100ml 용량으로 제공되며, 가격대는 다소 높은 편이지만, 그만큼 품질이 뛰어나고 오랜 시간 지속되는 향을 제공합니다. 투자할 가치가 충분히 있는 제품이니, 겨울철에 잘 어울리는 향수를 찾고 계신다면 고려해보세요!\n",
      "\n",
      "이 향수로 따뜻하고 매력적인 겨울을 보내시길 바랍니다!\n",
      "\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "🔍 사용자 쿼리: 디올에서 나온 퍼퓸 중에 30ml짜리로 추천해줘\n",
      "\n",
      "1️⃣ 쿼리 파싱 중...\n",
      "파싱 결과: {\n",
      "  \"brand\": \"디올\",\n",
      "  \"gender\": null,\n",
      "  \"sizes\": \"30\",\n",
      "  \"season_score\": null,\n",
      "  \"concentration\": \"퍼퓸\",\n",
      "  \"day_night_score\": null\n",
      "}\n",
      "\n",
      "2️⃣ 메타필터 적용 중...\n",
      "필터링 결과: {\n",
      "  \"brand\": \"디올\",\n",
      "  \"concentration\": \"퍼퓸\",\n",
      "  \"day_night_score\": null,\n",
      "  \"gender\": null,\n",
      "  \"season_score\": null,\n",
      "  \"sizes\": \"30\"\n",
      "}\n",
      "\n",
      "3️⃣ 쿼리 벡터화 중...\n",
      "벡터 차원: 1536\n",
      "\n",
      "4️⃣ 벡터 검색 중...\n",
      "검색된 향수 개수: 0\n",
      "\n",
      "5️⃣ 최종 응답 생성 중...\n",
      "\n",
      "🎯 최종 추천:\n",
      "안녕하세요! 디올의 30ml 퍼퓸 중에서 추천해드릴 수 있는 제품은 **디올 쟈도르 (Dior J'adore)**입니다. 이 향수는 정말 많은 사랑을 받고 있는 클래식한 향수로, 여러 상황에서 활용하기 좋답니다.\n",
      "\n",
      "1. **왜 이 향수를 추천하는지**: 디올 쟈도르는 우아함과 여성스러움을 동시에 느낄 수 있는 향수로, 많은 사람들에게 사랑받는 아이템이에요. 특히, 다양한 연령대의 여성들이 사용하기에 적합한 향이죠.\n",
      "\n",
      "2. **향의 특징과 느낌**: 쟈도르는 플로럴 계열의 향수로, 자스민, 로즈, 일랑일랑 등의 꽃향기가 조화를 이루며, 상큼한 베르가못과 복숭아의 과일 향이 더해져 부드럽고 세련된 느낌을 줍니다. 이 향수는 마치 꽃밭에 서 있는 듯한 기분을 선사하며, 따뜻하고 매혹적인 잔향이 특징이에요.\n",
      "\n",
      "3. **어떤 상황에 적합한지**: 쟈도르는 데일리로 사용하기에도 좋고, 특별한 날이나 저녁 외출 시에도 잘 어울립니다. 친구들과의 모임이나 데이트, 혹은 중요한 비즈니스 미팅에서도 자신감을 주는 향이죠.\n",
      "\n",
      "4. **가격대나 용량 관련 조언**: 30ml 용량은 여행이나 외출 시 휴대하기에도 적당하고, 가격대는 대략 80,000원에서 120,000원 사이로 형성되어 있습니다. 처음 사용해보시는 분들에게는 30ml가 적당한 선택이 될 것 같아요.\n",
      "\n",
      "디올 쟈도르로 특별한 순간을 만들어보세요! 궁금한 점이 더 있으시면 언제든지 물어보세요. 😊\n",
      "\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "🔍 사용자 쿼리: 밤에 사용하기 좋은 유니섹스 향수 찾고 있어\n",
      "\n",
      "1️⃣ 쿼리 파싱 중...\n",
      "파싱 결과: {\n",
      "  \"brand\": null,\n",
      "  \"gender\": \"유니섹스\",\n",
      "  \"sizes\": null,\n",
      "  \"season_score\": null,\n",
      "  \"concentration\": null,\n",
      "  \"day_night_score\": \"야간\"\n",
      "}\n",
      "\n",
      "2️⃣ 메타필터 적용 중...\n",
      "필터링 결과: {\n",
      "  \"brand\": null,\n",
      "  \"concentration\": null,\n",
      "  \"day_night_score\": null,\n",
      "  \"gender\": null,\n",
      "  \"season_score\": null,\n",
      "  \"sizes\": null\n",
      "}\n",
      "\n",
      "3️⃣ 쿼리 벡터화 중...\n",
      "벡터 차원: 1536\n",
      "\n",
      "4️⃣ 벡터 검색 중...\n",
      "검색된 향수 개수: 5\n",
      "\n",
      "5️⃣ 최종 응답 생성 중...\n",
      "\n",
      "🎯 최종 추천:\n",
      "밤에 사용하기 좋은 유니섹스 향수를 찾고 계시군요! 제가 추천드릴 향수는 **이솝**의 오 드 퍼퓸입니다. \n",
      "\n",
      "### 추천 이유\n",
      "이솝은 자연에서 영감을 받은 고급스러운 향수로 유명한 브랜드입니다. 특히 이 향수는 유니섹스 제품으로, 남녀 모두에게 잘 어울리는 매력을 가지고 있습니다. \n",
      "\n",
      "### 향의 특징과 느낌\n",
      "이 향수는 가을에 잘 어울리는 따뜻하고 깊이 있는 향을 가지고 있습니다. 자연의 원료를 사용하여 부드럽고 세련된 느낌을 주며, 밤에 사용하기에 적합한 신비로운 매력을 발산합니다. \n",
      "\n",
      "### 적합한 상황\n",
      "이 향수는 특별한 저녁 외출이나 데이트, 혹은 친구들과의 모임 등 다양한 밤 시간대에 잘 어울립니다. 또한, 차분한 분위기를 연출하고 싶을 때도 좋습니다.\n",
      "\n",
      "### 가격대 및 용량\n",
      "이솝의 오 드 퍼퓸은 50ml 용량으로 제공되며, 일반적으로 중간 가격대에 위치해 있습니다. 고급스러운 향을 경험하면서도 합리적인 가격으로 즐길 수 있는 점이 매력적입니다.\n",
      "\n",
      "이 향수로 멋진 밤을 만들어보세요! 궁금한 점이 있으면 언제든지 물어보세요.\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os, json, re\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pinecone import Pinecone\n",
    "\n",
    "# 환경 변수 로드\n",
    "load_dotenv()\n",
    "\n",
    "# LLM 및 임베딩 모델 초기화\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "# Pinecone 초기화\n",
    "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "index = pc.Index(\"perfume-vectordb2\")\n",
    "\n",
    "# ========== LLM 파서 ==========\n",
    "parse_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"너는 향수 쿼리 파서야.\n",
    "사용자의 질문에서 다음 정보를 JSON 형식으로 추출해줘:\n",
    "- brand: 브랜드명 (예: 샤넬, 디올, 입생로랑 등)\n",
    "- concentration: (퍼퓸, 코롱 등)\n",
    "- day_night_score: 사용시간 (주간, 야간, 데일리 등)\n",
    "- gender: 성별 (남성, 여성, 유니섹스)\n",
    "- season_score: 계절 (봄, 여름, 가을, 겨울)\n",
    "- sizes: 용량 (30ml, 50ml, 100ml 등) 단위는 무시하고 숫자만\n",
    "\n",
    "없는 값은 null로 두고, 반드시 유효한 JSON 형식으로만 응답해줘.\n",
    "\n",
    "예시:\n",
    "{{\"brand\": \"샤넬\", \"gender\": null, \"sizes\": \"50\", \"season_score\": null, \"concentration\": null, \"day_night_score\": null}}\"\"\"),\n",
    "    (\"user\", \"{query}\")\n",
    "])\n",
    "\n",
    "def run_llm_parser(query: str):\n",
    "    \"\"\"사용자 쿼리를 JSON으로 파싱\"\"\"\n",
    "    try:\n",
    "        chain = parse_prompt | llm\n",
    "        ai_response = chain.invoke({\"query\": query})\n",
    "        response_text = ai_response.content.strip()\n",
    "\n",
    "        # JSON 부분만 추출\n",
    "        if \"```json\" in response_text:\n",
    "            response_text = response_text.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "        elif \"```\" in response_text:\n",
    "            response_text = response_text.split(\"```\")[1].strip()\n",
    "\n",
    "        parsed = json.loads(response_text)\n",
    "        return parsed\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"파싱 오류: {str(e)}\"}\n",
    "\n",
    "# ========== 메타필터 함수들 ==========\n",
    "def filter_brand(brand_value):\n",
    "    valid_brands = [\n",
    "        '겔랑', '구찌', '끌로에', '나르시소 로드리게즈', '니샤네', '도르세', '디올', '딥티크', '랑콤',\n",
    "        '로라 메르시에', '로에베', '록시땅', '르 라보', '메모', '메종 마르지엘라', '메종 프란시스 커정',\n",
    "        '멜린앤게츠', '미우미우', '바이레도', '반클리프 아펠', '버버리', '베르사체', '불가리', '비디케이',\n",
    "        '산타 마리아 노벨라', '샤넬', '세르주 루텐', '시슬리 코스메틱', '아쿠아 디 파르마', '에따 리브르 도량쥬',\n",
    "        '에르메스', '에스티 로더', '엑스 니힐로', '이니시오 퍼퓸', '이솝', '입생로랑', '제르조프', '조 말론',\n",
    "        '조르지오 아르마니', '줄리엣 헤즈 어 건', '지방시', '질 스튜어트', '크리드', '킬리안', '톰 포드',\n",
    "        '티파니앤코', '퍼퓸 드 말리', '펜할리곤스', '프라다', '프레데릭 말'\n",
    "    ]\n",
    "    if brand_value is None:\n",
    "        return None\n",
    "    return brand_value if brand_value in valid_brands else None\n",
    "\n",
    "def filter_concentration(concentration_value):\n",
    "    valid_concentrations = ['솔리드 퍼퓸', '엑스트레 드 퍼퓸', '오 드 뚜왈렛', '오 드 코롱', '오 드 퍼퓸', '퍼퓸']\n",
    "    if concentration_value is None:\n",
    "        return None\n",
    "    return concentration_value if concentration_value in valid_concentrations else None\n",
    "\n",
    "def filter_day_night_score(day_night_value):\n",
    "    valid_day_night = [\"day\", \"night\"]\n",
    "    if day_night_value is None:\n",
    "        return None\n",
    "    if isinstance(day_night_value, str) and ',' in day_night_value:\n",
    "        values = [v.strip() for v in day_night_value.split(',')]\n",
    "        filtered_values = [v for v in values if v in valid_day_night]\n",
    "        return ','.join(filtered_values) if filtered_values else None\n",
    "    return day_night_value if day_night_value in valid_day_night else None\n",
    "\n",
    "def filter_gender(gender_value):\n",
    "    valid_genders = ['Female', 'Male', 'Unisex', 'unisex ']\n",
    "    if gender_value is None:\n",
    "        return None\n",
    "    return gender_value if gender_value in valid_genders else None\n",
    "\n",
    "def filter_season_score(season_value):\n",
    "    valid_seasons = ['winter', 'spring', 'summer', 'fall']\n",
    "    if season_value is None:\n",
    "        return None\n",
    "    return season_value if season_value in valid_seasons else None\n",
    "\n",
    "def filter_sizes(sizes_value):\n",
    "    \"\"\"숫자만 추출해서 유효값인지 확인\"\"\"\n",
    "    valid_sizes = ['30', '50', '75', '100', '150']\n",
    "    if sizes_value is None:\n",
    "        return None\n",
    "    if isinstance(sizes_value, str):\n",
    "        numbers = re.findall(r'\\d+', sizes_value)\n",
    "        for num in numbers:\n",
    "            if num in valid_sizes:\n",
    "                return num\n",
    "    return str(sizes_value) if str(sizes_value) in valid_sizes else None\n",
    "\n",
    "def apply_meta_filters(parsed_json: dict) -> dict:\n",
    "    \"\"\"파싱된 JSON에 메타필터링 적용\"\"\"\n",
    "    if not parsed_json or \"error\" in parsed_json:\n",
    "        return parsed_json\n",
    "    \n",
    "    return {\n",
    "        'brand': filter_brand(parsed_json.get('brand')),\n",
    "        'concentration': filter_concentration(parsed_json.get('concentration')),\n",
    "        'day_night_score': filter_day_night_score(parsed_json.get('day_night_score')),\n",
    "        'gender': filter_gender(parsed_json.get('gender')),\n",
    "        'season_score': filter_season_score(parsed_json.get('season_score')),\n",
    "        'sizes': filter_sizes(parsed_json.get('sizes'))\n",
    "    }\n",
    "\n",
    "# ========== Pinecone 검색 함수들 ==========\n",
    "def build_pinecone_filter(filtered_json: dict) -> dict:\n",
    "    \"\"\"메타필터링 결과를 Pinecone filter dict로 변환\"\"\"\n",
    "    pinecone_filter = {}\n",
    "    if filtered_json.get(\"brand\"):\n",
    "        pinecone_filter[\"brand\"] = {\"$eq\": filtered_json[\"brand\"]}\n",
    "    if filtered_json.get(\"sizes\"):\n",
    "        pinecone_filter[\"sizes\"] = {\"$eq\": filtered_json[\"sizes\"]}\n",
    "    if filtered_json.get(\"season_score\"):\n",
    "        pinecone_filter[\"season_score\"] = {\"$eq\": filtered_json[\"season_score\"]}\n",
    "    if filtered_json.get(\"gender\"):\n",
    "        pinecone_filter[\"gender\"] = {\"$eq\": filtered_json[\"gender\"]}\n",
    "    if filtered_json.get(\"concentration\"):\n",
    "        pinecone_filter[\"concentration\"] = {\"$eq\": filtered_json[\"concentration\"]}\n",
    "    if filtered_json.get(\"day_night_score\"):\n",
    "        pinecone_filter[\"day_night_score\"] = {\"$eq\": filtered_json[\"day_night_score\"]}\n",
    "    return pinecone_filter\n",
    "\n",
    "def query_pinecone(vector, filtered_json: dict, top_k: int = 5):\n",
    "    \"\"\"Pinecone 벡터 검색 + 메타데이터 필터 적용\"\"\"\n",
    "    pinecone_filter = build_pinecone_filter(filtered_json)\n",
    "    \n",
    "    result = index.query(\n",
    "        vector=vector,\n",
    "        top_k=top_k,\n",
    "        include_metadata=True,\n",
    "        filter=pinecone_filter if pinecone_filter else None\n",
    "    )\n",
    "    return result\n",
    "\n",
    "# ========== RAG 응답 생성 ==========\n",
    "response_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"너는 향수 전문가야. 사용자의 질문에 대해 검색된 향수 정보를 바탕으로 친절하고 전문적인 추천을 해줘.\n",
    "\n",
    "추천할 때 다음을 포함해줘:\n",
    "1. 왜 이 향수를 추천하는지\n",
    "2. 향의 특징과 느낌\n",
    "3. 어떤 상황에 적합한지\n",
    "4. 가격대나 용량 관련 조언 (있다면)\n",
    "\n",
    "자연스럽고 친근한 톤으로 답변해줘.\"\"\"),\n",
    "    (\"user\", \"\"\"사용자 질문: {original_query}\n",
    "\n",
    "검색된 향수 정보:\n",
    "{search_results}\n",
    "\n",
    "위 정보를 바탕으로 향수를 추천해줘.\"\"\")\n",
    "])\n",
    "\n",
    "def format_search_results(pinecone_results):\n",
    "    \"\"\"Pinecone 검색 결과를 텍스트로 포맷팅\"\"\"\n",
    "    if not pinecone_results or not pinecone_results.get('matches'):\n",
    "        return \"검색된 향수가 없습니다.\"\n",
    "    \n",
    "    formatted_results = []\n",
    "    for i, match in enumerate(pinecone_results['matches'], 1):\n",
    "        metadata = match.get('metadata', {})\n",
    "        score = match.get('score', 0)\n",
    "        \n",
    "        result_text = f\"\"\"\n",
    "{i}. 향수명: {metadata.get('perfume_name', '정보없음')}\n",
    "   - 브랜드: {metadata.get('brand', '정보없음')}\n",
    "   - 성별: {metadata.get('gender', '정보없음')}\n",
    "   - 용량: {metadata.get('sizes', '정보없음')}ml\n",
    "   - 계절: {metadata.get('season_score', '정보없음')}\n",
    "   - 사용시간: {metadata.get('day_night_score', '정보없음')}\n",
    "   - 농도: {metadata.get('concentration', '정보없음')}\n",
    "   - 유사도 점수: {score:.3f}\n",
    "\"\"\"\n",
    "        formatted_results.append(result_text.strip())\n",
    "    \n",
    "    return \"\\n\\n\".join(formatted_results)\n",
    "\n",
    "def generate_response(original_query: str, search_results):\n",
    "    \"\"\"검색 결과를 바탕으로 최종 응답 생성\"\"\"\n",
    "    try:\n",
    "        formatted_results = format_search_results(search_results)\n",
    "        \n",
    "        chain = response_prompt | llm\n",
    "        response = chain.invoke({\n",
    "            \"original_query\": original_query,\n",
    "            \"search_results\": formatted_results\n",
    "        })\n",
    "        \n",
    "        return response.content\n",
    "    except Exception as e:\n",
    "        return f\"응답 생성 중 오류가 발생했습니다: {str(e)}\"\n",
    "\n",
    "# ========== 통합 RAG 파이프라인 ==========\n",
    "def perfume_rag_pipeline(user_query: str, top_k: int = 5):\n",
    "    \"\"\"\n",
    "    완전한 향수 추천 RAG 파이프라인\n",
    "    \n",
    "    Args:\n",
    "        user_query (str): 사용자 질문\n",
    "        top_k (int): 반환할 향수 개수\n",
    "    \n",
    "    Returns:\n",
    "        dict: 단계별 결과와 최종 추천\n",
    "    \"\"\"\n",
    "    print(f\"🔍 사용자 쿼리: {user_query}\")\n",
    "    \n",
    "    # 1단계: LLM으로 쿼리 파싱\n",
    "    print(\"\\n1️⃣ 쿼리 파싱 중...\")\n",
    "    parsed_json = run_llm_parser(user_query)\n",
    "    print(f\"파싱 결과: {json.dumps(parsed_json, ensure_ascii=False, indent=2)}\")\n",
    "    \n",
    "    if \"error\" in parsed_json:\n",
    "        return {\n",
    "            \"error\": \"쿼리 파싱에 실패했습니다.\",\n",
    "            \"details\": parsed_json\n",
    "        }\n",
    "    \n",
    "    # 2단계: 메타필터 적용\n",
    "    print(\"\\n2️⃣ 메타필터 적용 중...\")\n",
    "    filtered_json = apply_meta_filters(parsed_json)\n",
    "    print(f\"필터링 결과: {json.dumps(filtered_json, ensure_ascii=False, indent=2)}\")\n",
    "    \n",
    "    # 3단계: 쿼리 벡터화\n",
    "    print(\"\\n3️⃣ 쿼리 벡터화 중...\")\n",
    "    try:\n",
    "        query_vector = embeddings.embed_query(user_query)\n",
    "        print(f\"벡터 차원: {len(query_vector)}\")\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"error\": \"쿼리 벡터화에 실패했습니다.\",\n",
    "            \"details\": str(e)\n",
    "        }\n",
    "    \n",
    "    # 4단계: Pinecone 검색\n",
    "    print(\"\\n4️⃣ 벡터 검색 중...\")\n",
    "    try:\n",
    "        search_results = query_pinecone(query_vector, filtered_json, top_k)\n",
    "        print(f\"검색된 향수 개수: {len(search_results.get('matches', []))}\")\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"error\": \"벡터 검색에 실패했습니다.\",\n",
    "            \"details\": str(e)\n",
    "        }\n",
    "    \n",
    "    # 5단계: 최종 응답 생성\n",
    "    print(\"\\n5️⃣ 최종 응답 생성 중...\")\n",
    "    final_response = generate_response(user_query, search_results)\n",
    "    \n",
    "    return {\n",
    "        \"original_query\": user_query,\n",
    "        \"parsed_query\": parsed_json,\n",
    "        \"filtered_query\": filtered_json,\n",
    "        \"search_results\": search_results,\n",
    "        \"recommendation\": final_response,\n",
    "        \"status\": \"success\"\n",
    "    }\n",
    "\n",
    "# ========== 사용 예제 ==========\n",
    "if __name__ == \"__main__\":\n",
    "    # 테스트 쿼리들\n",
    "    test_queries = [\n",
    "        \"샤넬 50ml 여성용 향수 추천해줘\",\n",
    "        \"겨울에 사용하기 좋은 남성 향수가 뭐가 있을까?\",\n",
    "        \"디올에서 나온 퍼퓸 중에 30ml짜리로 추천해줘\",\n",
    "        \"밤에 사용하기 좋은 유니섹스 향수 찾고 있어\"\n",
    "    ]\n",
    "    \n",
    "    for query in test_queries:\n",
    "        print(\"=\"*80)\n",
    "        result = perfume_rag_pipeline(query)\n",
    "        \n",
    "        if result.get(\"status\") == \"success\":\n",
    "            print(f\"\\n🎯 최종 추천:\\n{result['recommendation']}\")\n",
    "        else:\n",
    "            print(f\"\\n❌ 오류: {result.get('error')}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# ========== 간단한 실행 함수 ==========\n",
    "def ask_perfume(query: str):\n",
    "    \"\"\"간단한 향수 검색 함수 - DB 결과만 반환\"\"\"\n",
    "    result = perfume_rag_pipeline(query)\n",
    "    if result.get(\"status\") == \"success\":\n",
    "        return result[\"formatted_results\"]\n",
    "    else:\n",
    "        return f\"죄송합니다. {result.get('error', '알 수 없는 오류가 발생했습니다.')}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f724a5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U langchain langgraph langchain-openai tiktoken\n",
    "import os, json\n",
    "from typing import TypedDict, List, Optional, Dict, Any\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "\n",
    "# ---------- 0) Config ----------\n",
    "os.environ.setdefault(\"OPENAI_API_KEY\", \"PUT_YOUR_KEY_HERE\")  # or set in env\n",
    "MODEL_NAME = \"gpt-4o-mini\"  # keep it small & fast for routing\n",
    "\n",
    "SUPERVISOR_SYSTEM_PROMPT = \"\"\"\n",
    "You are the “Perfume Recommendation Supervisor (Router)”. Analyze the user’s query (Korean or English) and route to exactly ONE agent below.\n",
    "\n",
    "[Agents]\n",
    "- LLM_parser         : Parses/normalizes multi-facet queries (2+ product facets).\n",
    "- FAQ_agent          : Perfume knowledge / definitions / differences / general questions.\n",
    "- human_fallback     : Non-perfume or off-topic queries.\n",
    "- price_agent        : Price-only intents (cheapest, price, buy, discount, etc.).\n",
    "- ML_agent           : Single-preference recommendations (mood/season vibe like “fresh summer”, “sweet”, etc.).\n",
    "\n",
    "[Facets to detect (“product facets”)]\n",
    "- brand            (e.g., Chanel, Dior, Creed)\n",
    "- season           (spring/summer/fall/winter; “for summer/winter”)\n",
    "- gender           (male/female/unisex)\n",
    "- sizes            (volume in ml: 30/50/100 ml)\n",
    "- day_night_score  (day/night/daily/office/club, etc.)\n",
    "- concentration    (EDT/EDP/Extrait/Parfum/Cologne)\n",
    "\n",
    "[Price intent keywords (not exhaustive)]\n",
    "- Korean: 가격, 최저가, 얼마, 가격대, 구매, 판매, 할인, 어디서 사, 배송비\n",
    "- English: price, cost, cheapest, buy, purchase, discount\n",
    "\n",
    "[FAQ examples]\n",
    "- Differences between EDP vs EDT, note definitions, longevity/projection, brand/line info.\n",
    "\n",
    "[Single-preference (ML_agent) examples]\n",
    "- “Recommend a cool perfume for summer”, “Recommend a sweet scent”, “One citrusy fresh pick”\n",
    "  (= 0–1 of the above facets mentioned; primarily taste/mood/situation).\n",
    "\n",
    "[Routing rules (priority)]\n",
    "1) Non-perfume / off-topic → human_fallback\n",
    "2) Clear price-only intent (even if one facet is present as context) → price_agent\n",
    "   e.g., “Chanel No. 5 50ml cheapest price?” → price_agent\n",
    "3) Count product facets in the query:\n",
    "   - If facets ≥ 2 → LLM_parser\n",
    "4) Otherwise (single-topic queries):\n",
    "   - Perfume knowledge/definitions → FAQ_agent\n",
    "   - Single taste/mood recommendation → ML_agent\n",
    "5) Tie-breakers:\n",
    "   - If price intent is clear → price_agent\n",
    "   - If facets ≥ 2 → LLM_parser\n",
    "   - Else: knowledge → FAQ_agent, taste → ML_agent\n",
    "\n",
    "[Output format]\n",
    "Return ONLY this JSON (no extra text):\n",
    "{{\n",
    "  \"next\": \"<LLM_parser|FAQ_agent|human_fallback|price_agent|ML_agent>\",\n",
    "  \"reason\": \"<one short English sentence>\",\n",
    "  \"facet_count\": <integer>,\n",
    "  \"facets\": {{\n",
    "    \"brand\": \"<value or null>\",\n",
    "    \"season\": \"<value or null>\",\n",
    "    \"gender\": \"<value or null>\",\n",
    "    \"sizes\": \"<value or null>\",\n",
    "    \"day_night_score\": \"<value or null>\",\n",
    "    \"concentration\": \"<value or null>\"\n",
    "  }},\n",
    "  \"scent_vibe\": \"<value if detected, else null>\",\n",
    "  \"query_intent\": \"<price|faq|scent_pref|non_perfume|other>\"\n",
    "}}\n",
    "\"\"\".strip()\n",
    "\n",
    "# ---------- 1) State ----------\n",
    "class AgentState(TypedDict):\n",
    "    messages: List[BaseMessage]           # conversation log\n",
    "    next: Optional[str]                   # routing decision key\n",
    "    router_json: Optional[Dict[str, Any]] # parsed JSON from router\n",
    "\n",
    "# ---------- 2) LLM (Supervisor) ----------\n",
    "llm = ChatOpenAI(model=MODEL_NAME, temperature=0)\n",
    "\n",
    "router_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", SUPERVISOR_SYSTEM_PROMPT),\n",
    "        (\"user\", \"{query}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "def supervisor_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Call the router LLM and return parsed JSON + routing target.\"\"\"\n",
    "    user_query = None\n",
    "    for m in reversed(state[\"messages\"]):\n",
    "        if isinstance(m, HumanMessage):\n",
    "            user_query = m.content\n",
    "            break\n",
    "    if not user_query:\n",
    "        user_query = \"(empty)\"\n",
    "\n",
    "    chain = router_prompt | llm\n",
    "    ai = chain.invoke({\"query\": user_query})\n",
    "    text = ai.content\n",
    "\n",
    "    # JSON strict parse\n",
    "    chosen = \"human_fallback\"\n",
    "    parsed: Dict[str, Any] = {}\n",
    "    try:\n",
    "        parsed = json.loads(text)\n",
    "        maybe = parsed.get(\"next\")\n",
    "        if isinstance(maybe, str) and maybe in {\"LLM_parser\",\"FAQ_agent\",\"human_fallback\",\"price_agent\",\"ML_agent\"}:\n",
    "            chosen = maybe\n",
    "    except Exception:\n",
    "        parsed = {\"error\": \"invalid_json\", \"raw\": text}\n",
    "\n",
    "    msgs = state[\"messages\"] + [AIMessage(content=text)]\n",
    "    return {\n",
    "        \"messages\": msgs,\n",
    "        \"next\": chosen,\n",
    "        \"router_json\": parsed\n",
    "    }\n",
    "\n",
    "# ---------- 3) Mock Agent Nodes (for testing) ----------\n",
    "def passthrough(name: str):\n",
    "    def _node(state: AgentState) -> AgentState:\n",
    "        payload = state.get(\"router_json\") or {}\n",
    "        summary = f\"[{name}] handled. reason={payload.get('reason')} facets={payload.get('facets')} intent={payload.get('query_intent')}\"\n",
    "        msgs = state[\"messages\"] + [AIMessage(content=summary)]\n",
    "        return {\"messages\": msgs, \"next\": None, \"router_json\": state.get(\"router_json\")}\n",
    "    return _node\n",
    "\n",
    "LLM_parser      = passthrough(\"LLM_parser\")\n",
    "FAQ_agent       = passthrough(\"FAQ_agent\")\n",
    "human_fallback  = passthrough(\"human_fallback\")\n",
    "price_agent     = passthrough(\"price_agent\")\n",
    "ML_agent        = passthrough(\"ML_agent\")\n",
    "\n",
    "# ---------- 4) Build Graph ----------\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"supervisor\", supervisor_node)\n",
    "graph.add_node(\"LLM_parser\", LLM_parser)\n",
    "graph.add_node(\"FAQ_agent\", FAQ_agent)\n",
    "graph.add_node(\"human_fallback\", human_fallback)\n",
    "graph.add_node(\"price_agent\", price_agent)\n",
    "graph.add_node(\"ML_agent\", ML_agent)\n",
    "\n",
    "graph.set_entry_point(\"supervisor\")\n",
    "\n",
    "# Conditional routing\n",
    "def router_edge(state: AgentState) -> str:\n",
    "    return state[\"next\"] or \"human_fallback\"\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"supervisor\",\n",
    "    router_edge,\n",
    "    {\n",
    "        \"LLM_parser\": \"LLM_parser\",\n",
    "        \"FAQ_agent\": \"FAQ_agent\",\n",
    "        \"human_fallback\": \"human_fallback\",\n",
    "        \"price_agent\": \"price_agent\",\n",
    "        \"ML_agent\": \"ML_agent\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# End states\n",
    "for node in [\"LLM_parser\", \"FAQ_agent\", \"human_fallback\", \"price_agent\", \"ML_agent\"]:\n",
    "    graph.add_edge(node, END)\n",
    "\n",
    "app = graph.compile()\n",
    "\n",
    "# ---------- 5) Batch Test ----------\n",
    "TEST_QUERIES = [\n",
    "    \"입생로랑 여성용 50ml 겨울용 향수 추천해줘.\",                 \n",
    "    \"디올 EDP로 가을 밤(야간)에 쓸 만한 향수 있어?\",                \n",
    "    \"EDP랑 EDT 차이가 뭐야?\",                                       \n",
    "    \"탑노트·미들노트·베이스노트가 각각 무슨 뜻이야?\",               \n",
    "    \"오늘 점심 뭐 먹을까?\",                                         \n",
    "    \"오늘 서울 날씨 어때?\",                                         \n",
    "    \"샤넬 넘버5 50ml 최저가 알려줘.\",                               \n",
    "    \"디올 소바쥬 가격 얼마야? 어디서 사는 게 제일 싸?\",             \n",
    "    \"여름에 시원한 향수 추천해줘.\",                                 \n",
    "    \"달달한 향 추천해줘.\",                                         \n",
    "]\n",
    "\n",
    "def run_tests():\n",
    "    for q in TEST_QUERIES:\n",
    "        print(\"=\"*80)\n",
    "        print(\"Query:\", q)\n",
    "        init: AgentState = {\n",
    "            \"messages\": [HumanMessage(content=q)],\n",
    "            \"next\": None,\n",
    "            \"router_json\": None\n",
    "        }\n",
    "        out = app.invoke(init)\n",
    "        ai_msgs = [m for m in out[\"messages\"] if isinstance(m, AIMessage)]\n",
    "        router_raw = ai_msgs[-2].content if len(ai_msgs) >= 2 else \"(no router output)\"\n",
    "        agent_summary = ai_msgs[-1].content if ai_msgs else \"(no agent output)\"\n",
    "        print(\"Router JSON:\", router_raw)\n",
    "        print(\"Agent summary:\", agent_summary)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_tests()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "befb7801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Query: 입생로랑 여성용 50ml 겨울용 향수 추천해줘.\n",
      "🔍 LLM_parser 실행: 입생로랑 여성용 50ml 겨울용 향수 추천해줘.\n",
      "Router JSON: {\n",
      "  \"next\": \"LLM_parser\",\n",
      "  \"reason\": \"The query contains multiple facets including brand, gender, size, and season.\",\n",
      "  \"facet_count\": 4,\n",
      "  \"facets\": {\n",
      "    \"brand\": \"입생로랑\",\n",
      "    \"season\": \"겨울\",\n",
      "    \"gender\": \"여성\",\n",
      "    \"sizes\": \"50ml\",\n",
      "    \"day_night_score\": null,\n",
      "    \"concentration\": null\n",
      "  },\n",
      "  \"scent_vibe\": null,\n",
      "  \"query_intent\": \"other\"\n",
      "}\n",
      "Agent summary: [LLM_parser] RAG 파이프라인 완료 ✅\n",
      "\n",
      "📊 파싱 결과: {\"brand\": \"입생로랑\", \"gender\": \"여성\", \"sizes\": \"50\", \"season_score\": \"겨울\", \"concentration\": null, \"day_night_score\": null}\n",
      "🔍 필터링 결과: {\"brand\": \"입생로랑\", \"concentration\": null, \"day_night_score\": null, \"gender\": null, \"season_score\": null, \"sizes\": \"50\"}\n",
      "🎯 검색된 향수 개수: 5\n",
      "\n",
      "💬 추천 결과:\n",
      "안녕하세요! 겨울에 사용할 입생로랑 여성용 향수를 찾고 계시군요. 제가 추천드릴 향수는 **입생로랑의 오 드 뚜왈렛 50ml**입니다. \n",
      "\n",
      "### 추천 이유\n",
      "이 향수는 겨울철에 특히 잘 어울리는 향으로, 따뜻하고 포근한 느낌을 주기 때문에 차가운 날씨에 잘 어울립니다. \n",
      "\n",
      "### 향의 특징과 느낌\n",
      "입생로랑의 오 드 뚜왈렛은 상큼하면서도 부드러운 플로럴 노트가 특징입니다. 처음에는 신선한 과일 향이 느껴지다가, 시간이 지나면서 따뜻한 우디 노트와 섞여 깊이 있는 향을 만들어냅니다. 이 조화로운 향은 기분을 좋게 하고, 자신감을 주는 매력이 있습니다.\n",
      "\n",
      "### 적합한 상황\n",
      "이 향수는 데일리로 사용하기에 적합하며, 특히 겨울철의 낮 시간에 잘 어울립니다. 친구들과의 만남이나 직장에서도 부담 없이 사용할 수 있어요. 또한, 특별한 날에 포인트로 사용하기에도 좋습니다.\n",
      "\n",
      "### 가격대 및 용량\n",
      "50ml 용량은 적당한 크기로, 일상에서 사용하기에 부담이 적습니다. 가격대는 보통 중간에서 약간 높은 편이지만, 품질과 향의 지속성을 고려했을 때 충분히 가치가 있습니다.\n",
      "\n",
      "이 향수가 당신의 겨울을 더욱 특별하게 만들어줄 거라 믿어요! 향수 구매 시 꼭 테스트해보시고, 본인에게 잘 어울리는지 확인해보세요. 궁금한 점이 더 있다면 언제든지 물어보세요!\n",
      "================================================================================\n",
      "Query: 디올 EDP로 가을 밤(야간)에 쓸 만한 향수 있어?\n",
      "🔍 LLM_parser 실행: 디올 EDP로 가을 밤(야간)에 쓸 만한 향수 있어?\n",
      "Router JSON: {\n",
      "  \"next\": \"LLM_parser\",\n",
      "  \"reason\": \"The query contains multiple facets including brand, concentration, season, and day/night score.\",\n",
      "  \"facet_count\": 4,\n",
      "  \"facets\": {\n",
      "    \"brand\": \"Dior\",\n",
      "    \"season\": \"fall\",\n",
      "    \"gender\": null,\n",
      "    \"sizes\": null,\n",
      "    \"day_night_score\": \"night\",\n",
      "    \"concentration\": \"EDP\"\n",
      "  },\n",
      "  \"scent_vibe\": null,\n",
      "  \"query_intent\": \"other\"\n",
      "}\n",
      "Agent summary: [LLM_parser] RAG 파이프라인 완료 ✅\n",
      "\n",
      "📊 파싱 결과: {\"brand\": \"디올\", \"concentration\": \"EDP\", \"day_night_score\": \"야간\", \"gender\": null, \"season_score\": \"가을\", \"sizes\": null}\n",
      "🔍 필터링 결과: {\"brand\": \"디올\", \"concentration\": null, \"day_night_score\": null, \"gender\": null, \"season_score\": null, \"sizes\": null}\n",
      "🎯 검색된 향수 개수: 5\n",
      "\n",
      "💬 추천 결과:\n",
      "안녕하세요! 가을 밤에 어울리는 디올 향수를 찾고 계시군요. 디올은 다양한 매력을 가진 향수로 유명한 브랜드인데요, 가을 밤에 잘 어울리는 향수를 추천해드릴게요.\n",
      "\n",
      "### 추천 향수: 디올 \"미스 디올 오 드 퍼퓸\" (Dior Miss Dior Eau de Parfum)\n",
      "\n",
      "1. **왜 이 향수를 추천하는지**: 미스 디올은 여성스러움과 우아함을 동시에 지닌 향수로, 가을 밤의 로맨틱한 분위기와 잘 어울립니다. 이 향수는 깊고 풍부한 플로럴 노트가 특징으로, 가을의 차분한 느낌을 잘 살려줍니다.\n",
      "\n",
      "2. **향의 특징과 느낌**: 미스 디올은 상큼한 베르가못과 장미의 조화로 시작해, 중간에는 우아한 재스민과 파촐리의 따뜻한 향이 더해집니다. 마지막에는 머스크와 앰버의 부드러운 잔향이 남아, 깊고 매혹적인 느낌을 줍니다. 이 조화는 가을 밤의 신비로운 분위기를 잘 표현해줍니다.\n",
      "\n",
      "3. **어떤 상황에 적합한지**: 이 향수는 특별한 저녁 외출이나 데이트, 혹은 친구들과의 모임 등 다양한 상황에서 사용하기 좋습니다. 특히 가을의 서늘한 밤에 따뜻한 옷과 함께하면 더욱 매력적인 조화를 이룰 것입니다.\n",
      "\n",
      "4. **가격대나 용량 관련 조언**: 미스 디올 오 드 퍼퓸은 보통 50ml와 100ml 용량으로 출시되며, 가격대는 약 100,000원에서 150,000원 사이입니다. 처음 사용해보신다면 50ml 용량을 추천드리며, 사용해보시고 마음에 드시면 100ml로 구매하시는 것도 좋습니다.\n",
      "\n",
      "가을 밤에 어울리는 이 향수로 특별한 순간을 만들어보세요! 궁금한 점이 더 있으시면 언제든지 물어보세요.\n",
      "================================================================================\n",
      "Query: EDP랑 EDT 차이가 뭐야?\n",
      "Router JSON: {\n",
      "  \"next\": \"FAQ_agent\",\n",
      "  \"reason\": \"The query is asking for a definition and difference between EDP and EDT.\",\n",
      "  \"facet_count\": 0,\n",
      "  \"facets\": {\n",
      "    \"brand\": null,\n",
      "    \"season\": null,\n",
      "    \"gender\": null,\n",
      "    \"sizes\": null,\n",
      "    \"day_night_score\": null,\n",
      "    \"concentration\": null\n",
      "  },\n",
      "  \"scent_vibe\": null,\n",
      "  \"query_intent\": \"faq\"\n",
      "}\n",
      "Agent summary: [FAQ_agent] handled. reason=The query is asking for a definition and difference between EDP and EDT. facets={'brand': None, 'season': None, 'gender': None, 'sizes': None, 'day_night_score': None, 'concentration': None} intent=faq\n",
      "================================================================================\n",
      "Query: 탑노트·미들노트·베이스노트가 각각 무슨 뜻이야?\n",
      "Router JSON: {\n",
      "  \"next\": \"FAQ_agent\",\n",
      "  \"reason\": \"User is asking for definitions related to perfume notes.\",\n",
      "  \"facet_count\": 0,\n",
      "  \"facets\": {\n",
      "    \"brand\": null,\n",
      "    \"season\": null,\n",
      "    \"gender\": null,\n",
      "    \"sizes\": null,\n",
      "    \"day_night_score\": null,\n",
      "    \"concentration\": null\n",
      "  },\n",
      "  \"scent_vibe\": null,\n",
      "  \"query_intent\": \"faq\"\n",
      "}\n",
      "Agent summary: [FAQ_agent] handled. reason=User is asking for definitions related to perfume notes. facets={'brand': None, 'season': None, 'gender': None, 'sizes': None, 'day_night_score': None, 'concentration': None} intent=faq\n",
      "================================================================================\n",
      "Query: 오늘 점심 뭐 먹을까?\n",
      "Router JSON: {\n",
      "  \"next\": \"human_fallback\",\n",
      "  \"reason\": \"The query is off-topic and not related to perfume.\",\n",
      "  \"facet_count\": 0,\n",
      "  \"facets\": {\n",
      "    \"brand\": null,\n",
      "    \"season\": null,\n",
      "    \"gender\": null,\n",
      "    \"sizes\": null,\n",
      "    \"day_night_score\": null,\n",
      "    \"concentration\": null\n",
      "  },\n",
      "  \"scent_vibe\": null,\n",
      "  \"query_intent\": \"non_perfume\"\n",
      "}\n",
      "Agent summary: [human_fallback] handled. reason=The query is off-topic and not related to perfume. facets={'brand': None, 'season': None, 'gender': None, 'sizes': None, 'day_night_score': None, 'concentration': None} intent=non_perfume\n",
      "================================================================================\n",
      "Query: 오늘 서울 날씨 어때?\n",
      "Router JSON: {\n",
      "  \"next\": \"human_fallback\",\n",
      "  \"reason\": \"The query is off-topic and not related to perfume.\",\n",
      "  \"facet_count\": 0,\n",
      "  \"facets\": {\n",
      "    \"brand\": null,\n",
      "    \"season\": null,\n",
      "    \"gender\": null,\n",
      "    \"sizes\": null,\n",
      "    \"day_night_score\": null,\n",
      "    \"concentration\": null\n",
      "  },\n",
      "  \"scent_vibe\": null,\n",
      "  \"query_intent\": \"non_perfume\"\n",
      "}\n",
      "Agent summary: [human_fallback] handled. reason=The query is off-topic and not related to perfume. facets={'brand': None, 'season': None, 'gender': None, 'sizes': None, 'day_night_score': None, 'concentration': None} intent=non_perfume\n",
      "================================================================================\n",
      "Query: 샤넬 넘버5 50ml 최저가 알려줘.\n",
      "Router JSON: {\n",
      "  \"next\": \"price_agent\",\n",
      "  \"reason\": \"Clear price intent detected.\",\n",
      "  \"facet_count\": 1,\n",
      "  \"facets\": {\n",
      "    \"brand\": \"Chanel\",\n",
      "    \"season\": null,\n",
      "    \"gender\": null,\n",
      "    \"sizes\": \"50 ml\",\n",
      "    \"day_night_score\": null,\n",
      "    \"concentration\": null\n",
      "  },\n",
      "  \"scent_vibe\": null,\n",
      "  \"query_intent\": \"price\"\n",
      "}\n",
      "Agent summary: [price_agent] handled. reason=Clear price intent detected. facets={'brand': 'Chanel', 'season': None, 'gender': None, 'sizes': '50 ml', 'day_night_score': None, 'concentration': None} intent=price\n",
      "================================================================================\n",
      "Query: 디올 소바쥬 가격 얼마야? 어디서 사는 게 제일 싸?\n",
      "Router JSON: {\n",
      "  \"next\": \"price_agent\",\n",
      "  \"reason\": \"Clear price intent detected.\",\n",
      "  \"facet_count\": 1,\n",
      "  \"facets\": {\n",
      "    \"brand\": \"Dior\",\n",
      "    \"season\": null,\n",
      "    \"gender\": null,\n",
      "    \"sizes\": null,\n",
      "    \"day_night_score\": null,\n",
      "    \"concentration\": null\n",
      "  },\n",
      "  \"scent_vibe\": null,\n",
      "  \"query_intent\": \"price\"\n",
      "}\n",
      "Agent summary: [price_agent] handled. reason=Clear price intent detected. facets={'brand': 'Dior', 'season': None, 'gender': None, 'sizes': None, 'day_night_score': None, 'concentration': None} intent=price\n",
      "================================================================================\n",
      "Query: 여름에 시원한 향수 추천해줘.\n",
      "Router JSON: {\n",
      "  \"next\": \"ML_agent\",\n",
      "  \"reason\": \"User is asking for a scent recommendation for summer.\",\n",
      "  \"facet_count\": 0,\n",
      "  \"facets\": {\n",
      "    \"brand\": null,\n",
      "    \"season\": \"summer\",\n",
      "    \"gender\": null,\n",
      "    \"sizes\": null,\n",
      "    \"day_night_score\": null,\n",
      "    \"concentration\": null\n",
      "  },\n",
      "  \"scent_vibe\": \"cool\",\n",
      "  \"query_intent\": \"scent_pref\"\n",
      "}\n",
      "Agent summary: [ML_agent] handled. reason=User is asking for a scent recommendation for summer. facets={'brand': None, 'season': 'summer', 'gender': None, 'sizes': None, 'day_night_score': None, 'concentration': None} intent=scent_pref\n",
      "================================================================================\n",
      "Query: 달달한 향 추천해줘.\n",
      "Router JSON: {\n",
      "  \"next\": \"ML_agent\",\n",
      "  \"reason\": \"User is asking for a sweet scent recommendation.\",\n",
      "  \"facet_count\": 0,\n",
      "  \"facets\": {\n",
      "    \"brand\": null,\n",
      "    \"season\": null,\n",
      "    \"gender\": null,\n",
      "    \"sizes\": null,\n",
      "    \"day_night_score\": null,\n",
      "    \"concentration\": null\n",
      "  },\n",
      "  \"scent_vibe\": \"sweet\",\n",
      "  \"query_intent\": \"scent_pref\"\n",
      "}\n",
      "Agent summary: [ML_agent] handled. reason=User is asking for a sweet scent recommendation. facets={'brand': None, 'season': None, 'gender': None, 'sizes': None, 'day_night_score': None, 'concentration': None} intent=scent_pref\n"
     ]
    }
   ],
   "source": [
    "# 연결버전\n",
    "# pip install -U langchain langgraph langchain-openai tiktoken python-dotenv pinecone-client\n",
    "import os, json, re\n",
    "from typing import TypedDict, List, Optional, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "from pinecone import Pinecone\n",
    "\n",
    "# 환경 변수 로드\n",
    "load_dotenv()\n",
    "\n",
    "# ---------- 0) Config ----------\n",
    "os.environ.setdefault(\"OPENAI_API_KEY\", \"PUT_YOUR_KEY_HERE\")  # or set in env\n",
    "MODEL_NAME = \"gpt-4o-mini\"  # keep it small & fast for routing\n",
    "\n",
    "SUPERVISOR_SYSTEM_PROMPT = \"\"\"\n",
    "You are the \"Perfume Recommendation Supervisor (Router)\". Analyze the user's query (Korean or English) and route to exactly ONE agent below.\n",
    "\n",
    "[Agents]\n",
    "- LLM_parser         : Parses/normalizes multi-facet queries (2+ product facets).\n",
    "- FAQ_agent          : Perfume knowledge / definitions / differences / general questions.\n",
    "- human_fallback     : Non-perfume or off-topic queries.\n",
    "- price_agent        : Price-only intents (cheapest, price, buy, discount, etc.).\n",
    "- ML_agent           : Single-preference recommendations (mood/season vibe like \"fresh summer\", \"sweet\", etc.).\n",
    "\n",
    "[Facets to detect (\"product facets\")]\n",
    "- brand            (e.g., Chanel, Dior, Creed)\n",
    "- season           (spring/summer/fall/winter; \"for summer/winter\")\n",
    "- gender           (male/female/unisex)\n",
    "- sizes            (volume in ml: 30/50/100 ml)\n",
    "- day_night_score  (day/night/daily/office/club, etc.)\n",
    "- concentration    (EDT/EDP/Extrait/Parfum/Cologne)\n",
    "\n",
    "[Price intent keywords (not exhaustive)]\n",
    "- Korean: 가격, 최저가, 얼마, 가격대, 구매, 판매, 할인, 어디서 사, 배송비\n",
    "- English: price, cost, cheapest, buy, purchase, discount\n",
    "\n",
    "[FAQ examples]\n",
    "- Differences between EDP vs EDT, note definitions, longevity/projection, brand/line info.\n",
    "\n",
    "[Single-preference (ML_agent) examples]\n",
    "- \"Recommend a cool perfume for summer\", \"Recommend a sweet scent\", \"One citrusy fresh pick\"\n",
    "  (= 0–1 of the above facets mentioned; primarily taste/mood/situation).\n",
    "\n",
    "[Routing rules (priority)]\n",
    "1) Non-perfume / off-topic → human_fallback\n",
    "2) Clear price-only intent (even if one facet is present as context) → price_agent\n",
    "   e.g., \"Chanel No. 5 50ml cheapest price?\" → price_agent\n",
    "3) Count product facets in the query:\n",
    "   - If facets ≥ 2 → LLM_parser\n",
    "4) Otherwise (single-topic queries):\n",
    "   - Perfume knowledge/definitions → FAQ_agent\n",
    "   - Single taste/mood recommendation → ML_agent\n",
    "5) Tie-breakers:\n",
    "   - If price intent is clear → price_agent\n",
    "   - If facets ≥ 2 → LLM_parser\n",
    "   - Else: knowledge → FAQ_agent, taste → ML_agent\n",
    "\n",
    "[Output format]\n",
    "Return ONLY this JSON (no extra text):\n",
    "{{\n",
    "  \"next\": \"<LLM_parser|FAQ_agent|human_fallback|price_agent|ML_agent>\",\n",
    "  \"reason\": \"<one short English sentence>\",\n",
    "  \"facet_count\": <integer>,\n",
    "  \"facets\": {{\n",
    "    \"brand\": \"<value or null>\",\n",
    "    \"season\": \"<value or null>\",\n",
    "    \"gender\": \"<value or null>\",\n",
    "    \"sizes\": \"<value or null>\",\n",
    "    \"day_night_score\": \"<value or null>\",\n",
    "    \"concentration\": \"<value or null>\"\n",
    "  }},\n",
    "  \"scent_vibe\": \"<value if detected, else null>\",\n",
    "  \"query_intent\": \"<price|faq|scent_pref|non_perfume|other>\"\n",
    "}}\n",
    "\"\"\".strip()\n",
    "\n",
    "# ---------- 1) State ----------\n",
    "class AgentState(TypedDict):\n",
    "    messages: List[BaseMessage]           # conversation log\n",
    "    next: Optional[str]                   # routing decision key\n",
    "    router_json: Optional[Dict[str, Any]] # parsed JSON from router\n",
    "\n",
    "# ---------- 2) LLM 초기화 ----------\n",
    "llm = ChatOpenAI(model=MODEL_NAME, temperature=0)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "# Pinecone 초기화\n",
    "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "index = pc.Index(\"perfume-vectordb2\")\n",
    "\n",
    "router_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", SUPERVISOR_SYSTEM_PROMPT),\n",
    "        (\"user\", \"{query}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "def supervisor_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Call the router LLM and return parsed JSON + routing target.\"\"\"\n",
    "    user_query = None\n",
    "    for m in reversed(state[\"messages\"]):\n",
    "        if isinstance(m, HumanMessage):\n",
    "            user_query = m.content\n",
    "            break\n",
    "    if not user_query:\n",
    "        user_query = \"(empty)\"\n",
    "\n",
    "    chain = router_prompt | llm\n",
    "    ai = chain.invoke({\"query\": user_query})\n",
    "    text = ai.content\n",
    "\n",
    "    # JSON strict parse\n",
    "    chosen = \"human_fallback\"\n",
    "    parsed: Dict[str, Any] = {}\n",
    "    try:\n",
    "        parsed = json.loads(text)\n",
    "        maybe = parsed.get(\"next\")\n",
    "        if isinstance(maybe, str) and maybe in {\"LLM_parser\",\"FAQ_agent\",\"human_fallback\",\"price_agent\",\"ML_agent\"}:\n",
    "            chosen = maybe\n",
    "    except Exception:\n",
    "        parsed = {\"error\": \"invalid_json\", \"raw\": text}\n",
    "\n",
    "    msgs = state[\"messages\"] + [AIMessage(content=text)]\n",
    "    return {\n",
    "        \"messages\": msgs,\n",
    "        \"next\": chosen,\n",
    "        \"router_json\": parsed\n",
    "    }\n",
    "\n",
    "# ---------- 3) RAG Pipeline Functions ----------\n",
    "parse_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"너는 향수 쿼리 파서야.\n",
    "사용자의 질문에서 다음 정보를 JSON 형식으로 추출해줘:\n",
    "- brand: 브랜드명 (예: 샤넬, 디올, 입생로랑 등)\n",
    "- concentration: (퍼퓸, 코롱 등)\n",
    "- day_night_score: 사용시간 (주간, 야간, 데일리 등)\n",
    "- gender: 성별 (남성, 여성, 유니섹스)\n",
    "- season_score: 계절 (봄, 여름, 가을, 겨울)\n",
    "- sizes: 용량 (30ml, 50ml, 100ml 등) 단위는 무시하고 숫자만\n",
    "\n",
    "없는 값은 null로 두고, 반드시 유효한 JSON 형식으로만 응답해줘.\n",
    "\n",
    "예시:\n",
    "{{\"brand\": \"샤넬\", \"gender\": null, \"sizes\": \"50\", \"season_score\": null, \"concentration\": null, \"day_night_score\": null}}\"\"\"),\n",
    "    (\"user\", \"{query}\")\n",
    "])\n",
    "\n",
    "def run_llm_parser(query: str):\n",
    "    \"\"\"사용자 쿼리를 JSON으로 파싱\"\"\"\n",
    "    try:\n",
    "        chain = parse_prompt | llm\n",
    "        ai_response = chain.invoke({\"query\": query})\n",
    "        response_text = ai_response.content.strip()\n",
    "\n",
    "        # JSON 부분만 추출\n",
    "        if \"```json\" in response_text:\n",
    "            response_text = response_text.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "        elif \"```\" in response_text:\n",
    "            response_text = response_text.split(\"```\")[1].strip()\n",
    "\n",
    "        parsed = json.loads(response_text)\n",
    "        return parsed\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"파싱 오류: {str(e)}\"}\n",
    "\n",
    "# 메타필터 함수들\n",
    "def filter_brand(brand_value):\n",
    "    valid_brands = [\n",
    "        '겔랑', '구찌', '끌로에', '나르시소 로드리게즈', '니샤네', '도르세', '디올', '딥티크', '랑콤',\n",
    "        '로라 메르시에', '로에베', '록시땅', '르 라보', '메모', '메종 마르지엘라', '메종 프란시스 커정',\n",
    "        '멜린앤게츠', '미우미우', '바이레도', '반클리프 아펠', '버버리', '베르사체', '불가리', '비디케이',\n",
    "        '산타 마리아 노벨라', '샤넬', '세르주 루텐', '시슬리 코스메틱', '아쿠아 디 파르마', '에따 리브르 도량쥬',\n",
    "        '에르메스', '에스티 로더', '엑스 니힐로', '이니시오 퍼퓸', '이솝', '입생로랑', '제르조프', '조 말론',\n",
    "        '조르지오 아르마니', '줄리엣 헤즈 어 건', '지방시', '질 스튜어트', '크리드', '킬리안', '톰 포드',\n",
    "        '티파니앤코', '퍼퓸 드 말리', '펜할리곤스', '프라다', '프레데릭 말'\n",
    "    ]\n",
    "    if brand_value is None:\n",
    "        return None\n",
    "    return brand_value if brand_value in valid_brands else None\n",
    "\n",
    "def filter_concentration(concentration_value):\n",
    "    valid_concentrations = ['솔리드 퍼퓸', '엑스트레 드 퍼퓸', '오 드 뚜왈렛', '오 드 코롱', '오 드 퍼퓸', '퍼퓸']\n",
    "    if concentration_value is None:\n",
    "        return None\n",
    "    return concentration_value if concentration_value in valid_concentrations else None\n",
    "\n",
    "def filter_day_night_score(day_night_value):\n",
    "    valid_day_night = [\"day\", \"night\"]\n",
    "    if day_night_value is None:\n",
    "        return None\n",
    "    if isinstance(day_night_value, str) and ',' in day_night_value:\n",
    "        values = [v.strip() for v in day_night_value.split(',')]\n",
    "        filtered_values = [v for v in values if v in valid_day_night]\n",
    "        return ','.join(filtered_values) if filtered_values else None\n",
    "    return day_night_value if day_night_value in valid_day_night else None\n",
    "\n",
    "def filter_gender(gender_value):\n",
    "    valid_genders = ['Female', 'Male', 'Unisex', 'unisex ']\n",
    "    if gender_value is None:\n",
    "        return None\n",
    "    return gender_value if gender_value in valid_genders else None\n",
    "\n",
    "def filter_season_score(season_value):\n",
    "    valid_seasons = ['winter', 'spring', 'summer', 'fall']\n",
    "    if season_value is None:\n",
    "        return None\n",
    "    return season_value if season_value in valid_seasons else None\n",
    "\n",
    "def filter_sizes(sizes_value):\n",
    "    valid_sizes = ['30', '50', '75', '100', '150']\n",
    "    if sizes_value is None:\n",
    "        return None\n",
    "    if isinstance(sizes_value, str):\n",
    "        numbers = re.findall(r'\\d+', sizes_value)\n",
    "        for num in numbers:\n",
    "            if num in valid_sizes:\n",
    "                return num\n",
    "    return str(sizes_value) if str(sizes_value) in valid_sizes else None\n",
    "\n",
    "def apply_meta_filters(parsed_json: dict) -> dict:\n",
    "    \"\"\"파싱된 JSON에 메타필터링 적용\"\"\"\n",
    "    if not parsed_json or \"error\" in parsed_json:\n",
    "        return parsed_json\n",
    "    \n",
    "    return {\n",
    "        'brand': filter_brand(parsed_json.get('brand')),\n",
    "        'concentration': filter_concentration(parsed_json.get('concentration')),\n",
    "        'day_night_score': filter_day_night_score(parsed_json.get('day_night_score')),\n",
    "        'gender': filter_gender(parsed_json.get('gender')),\n",
    "        'season_score': filter_season_score(parsed_json.get('season_score')),\n",
    "        'sizes': filter_sizes(parsed_json.get('sizes'))\n",
    "    }\n",
    "\n",
    "def build_pinecone_filter(filtered_json: dict) -> dict:\n",
    "    \"\"\"메타필터링 결과를 Pinecone filter dict로 변환\"\"\"\n",
    "    pinecone_filter = {}\n",
    "    if filtered_json.get(\"brand\"):\n",
    "        pinecone_filter[\"brand\"] = {\"$eq\": filtered_json[\"brand\"]}\n",
    "    if filtered_json.get(\"sizes\"):\n",
    "        pinecone_filter[\"sizes\"] = {\"$eq\": filtered_json[\"sizes\"]}\n",
    "    if filtered_json.get(\"season_score\"):\n",
    "        pinecone_filter[\"season_score\"] = {\"$eq\": filtered_json[\"season_score\"]}\n",
    "    if filtered_json.get(\"gender\"):\n",
    "        pinecone_filter[\"gender\"] = {\"$eq\": filtered_json[\"gender\"]}\n",
    "    if filtered_json.get(\"concentration\"):\n",
    "        pinecone_filter[\"concentration\"] = {\"$eq\": filtered_json[\"concentration\"]}\n",
    "    if filtered_json.get(\"day_night_score\"):\n",
    "        pinecone_filter[\"day_night_score\"] = {\"$eq\": filtered_json[\"day_night_score\"]}\n",
    "    return pinecone_filter\n",
    "\n",
    "def query_pinecone(vector, filtered_json: dict, top_k: int = 5):\n",
    "    \"\"\"Pinecone 벡터 검색 + 메타데이터 필터 적용\"\"\"\n",
    "    pinecone_filter = build_pinecone_filter(filtered_json)\n",
    "    \n",
    "    result = index.query(\n",
    "        vector=vector,\n",
    "        top_k=top_k,\n",
    "        include_metadata=True,\n",
    "        filter=pinecone_filter if pinecone_filter else None\n",
    "    )\n",
    "    return result\n",
    "\n",
    "response_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"너는 향수 전문가야. 사용자의 질문에 대해 검색된 향수 정보를 바탕으로 친절하고 전문적인 추천을 해줘.\n",
    "\n",
    "추천할 때 다음을 포함해줘:\n",
    "1. 왜 이 향수를 추천하는지\n",
    "2. 향의 특징과 느낌\n",
    "3. 어떤 상황에 적합한지\n",
    "4. 가격대나 용량 관련 조언 (있다면)\n",
    "\n",
    "자연스럽고 친근한 톤으로 답변해줘.\"\"\"),\n",
    "    (\"user\", \"\"\"사용자 질문: {original_query}\n",
    "\n",
    "검색된 향수 정보:\n",
    "{search_results}\n",
    "\n",
    "위 정보를 바탕으로 향수를 추천해줘.\"\"\")\n",
    "])\n",
    "\n",
    "def format_search_results(pinecone_results):\n",
    "    \"\"\"Pinecone 검색 결과를 텍스트로 포맷팅\"\"\"\n",
    "    if not pinecone_results or not pinecone_results.get('matches'):\n",
    "        return \"검색된 향수가 없습니다.\"\n",
    "    \n",
    "    formatted_results = []\n",
    "    for i, match in enumerate(pinecone_results['matches'], 1):\n",
    "        metadata = match.get('metadata', {})\n",
    "        score = match.get('score', 0)\n",
    "        \n",
    "        result_text = f\"\"\"\n",
    "{i}. 향수명: {metadata.get('perfume_name', '정보없음')}\n",
    "   - 브랜드: {metadata.get('brand', '정보없음')}\n",
    "   - 성별: {metadata.get('gender', '정보없음')}\n",
    "   - 용량: {metadata.get('sizes', '정보없음')}ml\n",
    "   - 계절: {metadata.get('season_score', '정보없음')}\n",
    "   - 사용시간: {metadata.get('day_night_score', '정보없음')}\n",
    "   - 농도: {metadata.get('concentration', '정보없음')}\n",
    "   - 유사도 점수: {score:.3f}\n",
    "\"\"\"\n",
    "        formatted_results.append(result_text.strip())\n",
    "    \n",
    "    return \"\\n\\n\".join(formatted_results)\n",
    "\n",
    "def generate_response(original_query: str, search_results):\n",
    "    \"\"\"검색 결과를 바탕으로 최종 응답 생성\"\"\"\n",
    "    try:\n",
    "        formatted_results = format_search_results(search_results)\n",
    "        \n",
    "        chain = response_prompt | llm\n",
    "        response = chain.invoke({\n",
    "            \"original_query\": original_query,\n",
    "            \"search_results\": formatted_results\n",
    "        })\n",
    "        \n",
    "        return response.content\n",
    "    except Exception as e:\n",
    "        return f\"응답 생성 중 오류가 발생했습니다: {str(e)}\"\n",
    "\n",
    "# ---------- 4) Agent Nodes ----------\n",
    "def LLM_parser_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"실제 RAG 파이프라인을 실행하는 LLM_parser 노드\"\"\"\n",
    "    user_query = None\n",
    "    for m in reversed(state[\"messages\"]):\n",
    "        if isinstance(m, HumanMessage):\n",
    "            user_query = m.content\n",
    "            break\n",
    "    if not user_query:\n",
    "        user_query = \"(empty)\"\n",
    "\n",
    "    try:\n",
    "        print(f\"🔍 LLM_parser 실행: {user_query}\")\n",
    "        \n",
    "        # 1단계: LLM으로 쿼리 파싱\n",
    "        parsed_json = run_llm_parser(user_query)\n",
    "        if \"error\" in parsed_json:\n",
    "            error_msg = f\"[LLM_parser] 쿼리 파싱 오류: {parsed_json['error']}\"\n",
    "            msgs = state[\"messages\"] + [AIMessage(content=error_msg)]\n",
    "            return {\"messages\": msgs, \"next\": None, \"router_json\": state.get(\"router_json\")}\n",
    "        \n",
    "        # 2단계: 메타필터 적용\n",
    "        filtered_json = apply_meta_filters(parsed_json)\n",
    "        \n",
    "        # 3단계: 쿼리 벡터화\n",
    "        query_vector = embeddings.embed_query(user_query)\n",
    "        \n",
    "        # 4단계: Pinecone 검색\n",
    "        search_results = query_pinecone(query_vector, filtered_json, top_k=5)\n",
    "        \n",
    "        # 5단계: 최종 응답 생성\n",
    "        final_response = generate_response(user_query, search_results)\n",
    "        \n",
    "        # 결과 요약\n",
    "        summary = f\"\"\"[LLM_parser] RAG 파이프라인 완료 ✅\n",
    "\n",
    "📊 파싱 결과: {json.dumps(parsed_json, ensure_ascii=False)}\n",
    "🔍 필터링 결과: {json.dumps(filtered_json, ensure_ascii=False)}\n",
    "🎯 검색된 향수 개수: {len(search_results.get('matches', []))}\n",
    "\n",
    "💬 추천 결과:\n",
    "{final_response}\"\"\"\n",
    "\n",
    "        msgs = state[\"messages\"] + [AIMessage(content=summary)]\n",
    "        return {\"messages\": msgs, \"next\": None, \"router_json\": state.get(\"router_json\")}\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"[LLM_parser] RAG 파이프라인 실행 중 오류: {str(e)}\"\n",
    "        msgs = state[\"messages\"] + [AIMessage(content=error_msg)]\n",
    "        return {\"messages\": msgs, \"next\": None, \"router_json\": state.get(\"router_json\")}\n",
    "\n",
    "def passthrough(name: str):\n",
    "    def _node(state: AgentState) -> AgentState:\n",
    "        payload = state.get(\"router_json\") or {}\n",
    "        summary = f\"[{name}] handled. reason={payload.get('reason')} facets={payload.get('facets')} intent={payload.get('query_intent')}\"\n",
    "        msgs = state[\"messages\"] + [AIMessage(content=summary)]\n",
    "        return {\"messages\": msgs, \"next\": None, \"router_json\": state.get(\"router_json\")}\n",
    "    return _node\n",
    "\n",
    "FAQ_agent       = passthrough(\"FAQ_agent\")\n",
    "human_fallback  = passthrough(\"human_fallback\")\n",
    "price_agent     = passthrough(\"price_agent\")\n",
    "ML_agent        = passthrough(\"ML_agent\")\n",
    "\n",
    "# ---------- 5) Build Graph ----------\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"supervisor\", supervisor_node)\n",
    "graph.add_node(\"LLM_parser\", LLM_parser_node)  # 실제 RAG 파이프라인 연결\n",
    "graph.add_node(\"FAQ_agent\", FAQ_agent)\n",
    "graph.add_node(\"human_fallback\", human_fallback)\n",
    "graph.add_node(\"price_agent\", price_agent)\n",
    "graph.add_node(\"ML_agent\", ML_agent)\n",
    "\n",
    "graph.set_entry_point(\"supervisor\")\n",
    "\n",
    "# Conditional routing\n",
    "def router_edge(state: AgentState) -> str:\n",
    "    return state[\"next\"] or \"human_fallback\"\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"supervisor\",\n",
    "    router_edge,\n",
    "    {\n",
    "        \"LLM_parser\": \"LLM_parser\",\n",
    "        \"FAQ_agent\": \"FAQ_agent\",\n",
    "        \"human_fallback\": \"human_fallback\",\n",
    "        \"price_agent\": \"price_agent\",\n",
    "        \"ML_agent\": \"ML_agent\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# End states\n",
    "for node in [\"LLM_parser\", \"FAQ_agent\", \"human_fallback\", \"price_agent\", \"ML_agent\"]:\n",
    "    graph.add_edge(node, END)\n",
    "\n",
    "app = graph.compile()\n",
    "\n",
    "# ---------- 6) Batch Test ----------\n",
    "TEST_QUERIES = [\n",
    "    \"입생로랑 여성용 50ml 겨울용 향수 추천해줘.\",                 \n",
    "    \"디올 EDP로 가을 밤(야간)에 쓸 만한 향수 있어?\",                \n",
    "    \"EDP랑 EDT 차이가 뭐야?\",                                       \n",
    "    \"탑노트·미들노트·베이스노트가 각각 무슨 뜻이야?\",               \n",
    "    \"오늘 점심 뭐 먹을까?\",                                         \n",
    "    \"오늘 서울 날씨 어때?\",                                         \n",
    "    \"샤넬 넘버5 50ml 최저가 알려줘.\",                               \n",
    "    \"디올 소바쥬 가격 얼마야? 어디서 사는 게 제일 싸?\",             \n",
    "    \"여름에 시원한 향수 추천해줘.\",                                 \n",
    "    \"달달한 향 추천해줘.\",                                         \n",
    "]\n",
    "\n",
    "def run_tests():\n",
    "    for q in TEST_QUERIES:\n",
    "        print(\"=\"*80)\n",
    "        print(\"Query:\", q)\n",
    "        init: AgentState = {\n",
    "            \"messages\": [HumanMessage(content=q)],\n",
    "            \"next\": None,\n",
    "            \"router_json\": None\n",
    "        }\n",
    "        out = app.invoke(init)\n",
    "        ai_msgs = [m for m in out[\"messages\"] if isinstance(m, AIMessage)]\n",
    "        router_raw = ai_msgs[-2].content if len(ai_msgs) >= 2 else \"(no router output)\"\n",
    "        agent_summary = ai_msgs[-1].content if ai_msgs else \"(no agent output)\"\n",
    "        print(\"Router JSON:\", router_raw)\n",
    "        print(\"Agent summary:\", agent_summary)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6ae72e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3917280898.py, line 52)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 52\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m위의 코드에다가 분기에 맞는 함수를 저함수들을 사용해서 붙여주고\u001b[39m\n       ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# ML 모델 버전\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from rank_bm25 import BM25Okapi\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "\n",
    "\n",
    "class PerfumeRecommender:\n",
    "    \"\"\"향수 추천 시스템 클래스\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 model_pkl_path: str = \"./models.pkl\", \n",
    "                 perfume_json_path: str = \"perfumes.json\",\n",
    "                 model_name: str = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "                 max_len: int = 256):\n",
    "        \n",
    "        self.model_name = model_name\n",
    "        self.max_len = max_len\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        print(f\"[Device] {self.device}\")\n",
    "        \n",
    "        # 모델 및 데이터 로드\n",
    "        self._load_ml_model(model_pkl_path)\n",
    "        self._load_transformer_model()\n",
    "        self._load_perfume_data(perfume_json_path)\n",
    "        self._build_bm25_index()\n",
    "    \n",
    "    def _load_ml_model(self, pkl_path: str):\n",
    "        \"\"\"저장된 ML 모델 불러오기\"\"\"\n",
    "        data = joblib.load(pkl_path)\n",
    "        self.clf = data[\"classifier\"]\n",
    "        self.mlb = data[\"mlb\"]\n",
    "        self.thresholds = data[\"thresholds\"]\n",
    "        \n",
    "        print(f\"[Loaded model from {pkl_path}]\")\n",
    "        print(f\"Labels: {list(self.mlb.classes_)}\")\n",
    "    \n",
    "    def _load_transformer_model(self):\n",
    "        \"\"\"Transformer 모델 로드\"\"\"\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        self.base_model = AutoModel.from_pretrained(self.model_name).to(self.device)\n",
    "        self.base_model.eval()\n",
    "    \n",
    "    def _load_perfume_data(self, json_path: str):\n",
    "        \"\"\"향수 데이터 로드\"\"\"\n",
    "        with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            self.perfumes = json.load(f)\n",
    "        print(f\"[Loaded {len(self.perfumes)} perfumes from {json_path}]\")\n",
    "    \n",
    "    def _build_bm25_index(self):\n",
    "        \"\"\"BM25 인덱스 구축\"\"\"\n",
    "        self.corpus = [item.get(\"fragrances\", \"\") for item in self.perfumes]\n",
    "        tokenized_corpus = [doc.lower().split() for doc in self.corpus]\n",
    "        self.bm25 = BM25Okapi(tokenized_corpus)\n",
    "        print(\"[BM25 index built]\")\n",
    "    \n",
    "    def encode_texts(self, texts: List[str], batch_size: int = 32) -> np.ndarray:\n",
    "        \"\"\"텍스트를 임베딩으로 변환\"\"\"\n",
    "        all_embeddings = []\n",
    "        \n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch = texts[i:i+batch_size]\n",
    "            enc = self.tokenizer(\n",
    "                batch, \n",
    "                padding=True, \n",
    "                truncation=True, \n",
    "                max_length=self.max_len, \n",
    "                return_tensors=\"pt\"\n",
    "            ).to(self.device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                model_out = self.base_model(**enc)\n",
    "                emb = model_out.last_hidden_state.mean(dim=1)\n",
    "            \n",
    "            all_embeddings.append(emb.cpu().numpy())\n",
    "        \n",
    "        return np.vstack(all_embeddings)\n",
    "    \n",
    "    def predict_labels(self, text: str, topk: int = 3, use_thresholds: bool = True) -> List[str]:\n",
    "        \"\"\"텍스트에서 향수 라벨 예측\"\"\"\n",
    "        emb = self.encode_texts([text], batch_size=1)\n",
    "        proba = self.clf.predict_proba(emb)[0]\n",
    "        \n",
    "        if use_thresholds and self.thresholds:\n",
    "            # threshold 기반 선택\n",
    "            pick = [\n",
    "                i for i, p in enumerate(proba) \n",
    "                if p >= self.thresholds.get(self.mlb.classes_[i], 0.5)\n",
    "            ]\n",
    "            # threshold를 넘는 것이 없으면 topk 선택\n",
    "            if not pick:\n",
    "                pick = np.argsort(-proba)[:topk]\n",
    "        else:\n",
    "            # 상위 topk 선택\n",
    "            pick = np.argsort(-proba)[:topk]\n",
    "        \n",
    "        return [self.mlb.classes_[i] for i in pick]\n",
    "    \n",
    "    def search_perfumes(self, labels: List[str], top_n: int = 5) -> List[Tuple[int, float, Dict]]:\n",
    "        \"\"\"BM25를 사용해 향수 검색\"\"\"\n",
    "        query = \" \".join(labels)\n",
    "        tokenized_query = query.lower().split()\n",
    "        scores = self.bm25.get_scores(tokenized_query)\n",
    "        \n",
    "        # 상위 N개 인덱스 선택\n",
    "        top_idx = np.argsort(scores)[-top_n:][::-1]\n",
    "        \n",
    "        results = []\n",
    "        for idx in top_idx:\n",
    "            results.append((idx, scores[idx], self.perfumes[idx]))\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def recommend(self, \n",
    "                  user_text: str, \n",
    "                  topk_labels: int = 4, \n",
    "                  top_n_perfumes: int = 5,\n",
    "                  use_thresholds: bool = True,\n",
    "                  verbose: bool = True) -> Dict:\n",
    "        \"\"\"전체 추천 파이프라인\"\"\"\n",
    "        \n",
    "        # 1. ML 모델로 라벨 예측\n",
    "        predicted_labels = self.predict_labels(\n",
    "            user_text, \n",
    "            topk=topk_labels, \n",
    "            use_thresholds=use_thresholds\n",
    "        )\n",
    "        \n",
    "        # 2. BM25로 향수 검색\n",
    "        search_results = self.search_perfumes(predicted_labels, top_n=top_n_perfumes)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"=== ML 예측 라벨 ===\")\n",
    "            print(predicted_labels)\n",
    "            print(f\"\\n=== BM25 Top-{top_n_perfumes} 결과 ===\")\n",
    "            \n",
    "            for rank, (idx, score, perfume) in enumerate(search_results, 1):\n",
    "                print(f\"[Rank {rank}] Score: {score:.2f}\")\n",
    "                print(f\"  Brand      : {perfume.get('brand', 'N/A')}\")\n",
    "                print(f\"  Name       : {perfume.get('name_perfume', 'N/A')}\")\n",
    "                print(f\"  Fragrances : {perfume.get('fragrances', 'N/A')}\")\n",
    "                print()\n",
    "        \n",
    "        return {\n",
    "            \"user_input\": user_text,\n",
    "            \"predicted_labels\": predicted_labels,\n",
    "            \"recommendations\": [\n",
    "                {\n",
    "                    \"rank\": rank,\n",
    "                    \"score\": score,\n",
    "                    \"brand\": perfume.get('brand', 'N/A'),\n",
    "                    \"name\": perfume.get('name_perfume', 'N/A'),\n",
    "                    \"fragrances\": perfume.get('fragrances', 'N/A'),\n",
    "                    \"perfume_data\": perfume\n",
    "                }\n",
    "                for rank, (idx, score, perfume) in enumerate(search_results, 1)\n",
    "            ]\n",
    "        }\n",
    "\n",
    "\n",
    "# 사용 예시\n",
    "def main():\n",
    "    # 추천 시스템 초기화\n",
    "    recommender = PerfumeRecommender()\n",
    "    \n",
    "    # 사용자 입력 예시들\n",
    "    test_inputs = [\n",
    "        \"시트러스하고 프루티한 향수 추천해줘\",\n",
    "        \"로맨틱하고 플로랄한 향 원해\",\n",
    "        \"우디하고 스파이시한 향수\",\n",
    "        \"깔끔하고 상쾌한 향\"\n",
    "    ]\n",
    "    \n",
    "    for user_input in test_inputs:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"사용자 입력: {user_input}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        # 추천 실행\n",
    "        result = recommender.recommend(\n",
    "            user_text=user_input,\n",
    "            topk_labels=4,\n",
    "            top_n_perfumes=3,\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "이걸 사용해서 나머지 agent들을 통합해줘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ab684e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 환경 변수 확인:\n",
      "OPENAI_API_KEY: ✅ 설정됨\n",
      "PINECONE_API_KEY: ✅ 설정됨\n",
      "NAVER_CLIENT_ID: ✅ 설정됨\n",
      "NAVER_CLIENT_SECRET: ✅ 설정됨\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Query: 입생로랑 여성용 50ml 겨울용 향수 추천해줘.\n",
      "🔍 LLM_parser 실행: 입생로랑 여성용 50ml 겨울용 향수 추천해줘.\n",
      "Router JSON: {\n",
      "  \"next\": \"LLM_parser\",\n",
      "  \"reason\": \"The query contains multiple facets including brand, gender, size, and season.\",\n",
      "  \"facet_count\": 4,\n",
      "  \"facets\": {\n",
      "    \"brand\": \"입생로랑\",\n",
      "    \"season\": \"겨울\",\n",
      "    \"gender\": \"여성\",\n",
      "    \"sizes\": \"50ml\",\n",
      "    \"day_night_score\": null,\n",
      "    \"concentration\": null\n",
      "  },\n",
      "  \"scent_vibe\": null,\n",
      "  \"query_intent\": \"other\"\n",
      "}\n",
      "Agent summary: [LLM_parser] RAG 파이프라인 완료 ✅\n",
      "\n",
      "📊 파싱 결과: {\"brand\": \"입생로랑\", \"gender\": \"여성\", \"sizes\": \"50\", \"season_score\": \"겨울\", \"concentration\": null, \"day_night_score\": null}\n",
      "🔍 필터링 결과: {\"brand\": \"입생로랑\", \"concentration\": null, \"day_night_score\": null, \"gender\": null, \"season_score\": null, \"sizes\": \"50\"}\n",
      "🎯 검색된 향수 개수: 5\n",
      "\n",
      "💬 추천 결과:\n",
      "안녕하세요! 입생로랑의 겨울용 여성 향수를 찾고 계시군요. 제가 추천드릴 향수는 입생로랑의 **오 드 뚜왈렛** 50ml입니다. \n",
      "\n",
      "### 추천 이유\n",
      "이 향수는 겨울철에 특히 잘 어울리는 향으로, 따뜻하고 포근한 느낌을 주기 때문에 추운 날씨에 잘 어울립니다. \n",
      "\n",
      "### 향의 특징과 느낌\n",
      "입생로랑의 오 드 뚜왈렛은 상큼하면서도 부드러운 플로럴 노트가 특징입니다. 처음에는 신선한 과일 향이 느껴지다가, 시간이 지나면서 따뜻한 우디 노트와 섞여 깊이 있는 향을 만들어냅니다. 이 조화로운 향은 기분을 좋게 하고, 자신감을 주는 매력이 있습니다.\n",
      "\n",
      "### 적합한 상황\n",
      "이 향수는 데일리로 사용하기에 적합하며, 특히 겨울철의 낮 시간에 잘 어울립니다. 친구들과의 만남이나 직장에서도 부담 없이 사용할 수 있어요. 또한, 특별한 날의 데이트에도 잘 어울리는 향입니다.\n",
      "\n",
      "### 가격대 및 용량 조언\n",
      "50ml 용량은 적당한 크기로, 일상에서 자주 사용하기에 좋습니다. 가격대는 보통 중간에서 높은 편에 속하지만, 입생로랑의 품질을 고려했을 때 충분히 가치가 있습니다. \n",
      "\n",
      "이 향수가 마음에 드셨으면 좋겠어요! 혹시 더 궁금한 점이 있으면 언제든지 물어보세요. 😊\n",
      "================================================================================\n",
      "Query: 디올 EDP로 가을 밤(야간)에 쓸 만한 향수 있어?\n",
      "🔍 LLM_parser 실행: 디올 EDP로 가을 밤(야간)에 쓸 만한 향수 있어?\n",
      "Router JSON: {\n",
      "  \"next\": \"LLM_parser\",\n",
      "  \"reason\": \"The query contains multiple facets including brand, season, and day/night score.\",\n",
      "  \"facet_count\": 3,\n",
      "  \"facets\": {\n",
      "    \"brand\": \"Dior\",\n",
      "    \"season\": \"fall\",\n",
      "    \"gender\": null,\n",
      "    \"sizes\": null,\n",
      "    \"day_night_score\": \"night\",\n",
      "    \"concentration\": \"EDP\"\n",
      "  },\n",
      "  \"scent_vibe\": null,\n",
      "  \"query_intent\": \"other\"\n",
      "}\n",
      "Agent summary: [LLM_parser] RAG 파이프라인 완료 ✅\n",
      "\n",
      "📊 파싱 결과: {\"brand\": \"디올\", \"concentration\": \"EDP\", \"day_night_score\": \"야간\", \"gender\": null, \"season_score\": \"가을\", \"sizes\": null}\n",
      "🔍 필터링 결과: {\"brand\": \"디올\", \"concentration\": null, \"day_night_score\": null, \"gender\": null, \"season_score\": null, \"sizes\": null}\n",
      "🎯 검색된 향수 개수: 5\n",
      "\n",
      "💬 추천 결과:\n",
      "안녕하세요! 가을 밤에 어울리는 디올 향수를 찾고 계시군요. 디올은 다양한 매력을 가진 향수로 유명한 브랜드인데요, 가을 밤에 잘 어울리는 향수를 추천해드릴게요.\n",
      "\n",
      "### 추천 향수: 디올 \"미스 디올\" 오 드 퍼퓸 (Miss Dior Eau de Parfum)\n",
      "\n",
      "1. **왜 이 향수를 추천하는지**: 미스 디올은 클래식하면서도 세련된 매력을 지닌 향수로, 가을 밤의 우아함과 잘 어울립니다. 이 향수는 여성스러움을 강조하면서도 깊이 있는 향을 가지고 있어, 특별한 순간에 자신감을 더해줄 것입니다.\n",
      "\n",
      "2. **향의 특징과 느낌**: 미스 디올은 상큼한 시트러스 노트로 시작해, 장미와 재스민의 플로럴한 향이 이어지며, 마지막에는 우디한 머스크와 파촐리의 따뜻한 느낌이 남습니다. 이 조화로운 향은 가을의 쌀쌀한 공기 속에서도 따뜻함을 느끼게 해줍니다.\n",
      "\n",
      "3. **어떤 상황에 적합한지**: 이 향수는 저녁 외출, 데이트, 특별한 행사 등 다양한 상황에서 사용하기 좋습니다. 특히 가을 밤의 로맨틱한 분위기와 잘 어울려, 상대방에게 깊은 인상을 남길 수 있을 것입니다.\n",
      "\n",
      "4. **가격대나 용량 관련 조언**: 미스 디올 오 드 퍼퓸은 보통 50ml 또는 100ml 용량으로 판매되며, 가격대는 약 100,000원에서 150,000원 사이입니다. 처음 사용해보신다면 50ml 용량을 추천드리며, 사용해보시고 마음에 드시면 100ml로 구매하시는 것도 좋습니다.\n",
      "\n",
      "가을 밤에 어울리는 멋진 향수로 미스 디올을 고려해보세요! 향수는 개인의 취향에 따라 다르니, 꼭 테스트해보시고 결정하시길 바랍니다. 좋은 선택 되세요!\n",
      "================================================================================\n",
      "Query: EDP랑 EDT 차이가 뭐야?\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'invoke'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 552\u001b[39m\n\u001b[32m    548\u001b[39m \u001b[38;5;28mprint\u001b[39m()\n\u001b[32m    550\u001b[39m \u001b[38;5;28mprint\u001b[39m()\n\u001b[32m--> \u001b[39m\u001b[32m552\u001b[39m \u001b[43mrun_tests\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 534\u001b[39m, in \u001b[36mrun_tests\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    528\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mQuery:\u001b[39m\u001b[33m\"\u001b[39m, q)\n\u001b[32m    529\u001b[39m init: AgentState = {\n\u001b[32m    530\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [HumanMessage(content=q)],\n\u001b[32m    531\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mnext\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    532\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mrouter_json\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    533\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m out = \u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m ai_msgs = [m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m out[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(m, AIMessage)]\n\u001b[32m    536\u001b[39m router_raw = ai_msgs[-\u001b[32m2\u001b[39m].content \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ai_msgs) >= \u001b[32m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m(no router output)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata2\\miniconda3\\envs\\final-env\\Lib\\site-packages\\langgraph\\pregel\\main.py:3026\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3023\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3024\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3026\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3027\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3028\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3029\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3030\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3031\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3032\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3033\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3034\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3035\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3036\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3037\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3038\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3039\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3040\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3041\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata2\\miniconda3\\envs\\final-env\\Lib\\site-packages\\langgraph\\pregel\\main.py:2647\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2645\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2646\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2647\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2648\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2649\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2650\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2651\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2652\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2653\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2654\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2657\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata2\\miniconda3\\envs\\final-env\\Lib\\site-packages\\langgraph\\pregel\\_runner.py:162\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    160\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata2\\miniconda3\\envs\\final-env\\Lib\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata2\\miniconda3\\envs\\final-env\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:657\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    655\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    656\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m657\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    659\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata2\\miniconda3\\envs\\final-env\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:401\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    399\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    403\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 464\u001b[39m, in \u001b[36mFAQ_agent_node\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m    462\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mFAQ_agent_node\u001b[39m(state: AgentState) -> \u001b[38;5;28mdict\u001b[39m:\n\u001b[32m    463\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"FAQ_agent_nodet 호출\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m     result = \u001b[43mFAQ_agent\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m(state)\n\u001b[32m    465\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: result[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m]}\n",
      "\u001b[31mAttributeError\u001b[39m: 'function' object has no attribute 'invoke'",
      "During task with name 'FAQ_agent' and id '6ac0a91e-abff-d92c-e682-f8224843be93'"
     ]
    }
   ],
   "source": [
    "# pip install -U langchain langgraph langchain-openai tiktoken python-dotenv pinecone-client\n",
    "import os, json, re\n",
    "from typing import TypedDict, List, Optional, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "from pinecone import Pinecone\n",
    "\n",
    "# 환경 변수 로드\n",
    "load_dotenv()\n",
    "\n",
    "# ---------- 0) Config ----------\n",
    "os.environ.setdefault(\"OPENAI_API_KEY\", \"PUT_YOUR_KEY_HERE\")  # or set in env\n",
    "MODEL_NAME = \"gpt-4o-mini\"  # keep it small & fast for routing\n",
    "\n",
    "SUPERVISOR_SYSTEM_PROMPT = \"\"\"\n",
    "You are the \"Perfume Recommendation Supervisor (Router)\". Analyze the user's query (Korean or English) and route to exactly ONE agent below.\n",
    "\n",
    "[Agents]\n",
    "- LLM_parser         : Parses/normalizes multi-facet queries (2+ product facets).\n",
    "- FAQ_agent          : Perfume knowledge / definitions / differences / general questions.\n",
    "- human_fallback     : Non-perfume or off-topic queries.\n",
    "- price_agent        : Price-only intents (cheapest, price, buy, discount, etc.).\n",
    "- ML_agent           : Single-preference recommendations (mood/season vibe like \"fresh summer\", \"sweet\", etc.).\n",
    "\n",
    "[Facets to detect (\"product facets\")]\n",
    "- brand            (e.g., Chanel, Dior, Creed)\n",
    "- season           (spring/summer/fall/winter; \"for summer/winter\")\n",
    "- gender           (male/female/unisex)\n",
    "- sizes            (volume in ml: 30/50/100 ml)\n",
    "- day_night_score  (day/night/daily/office/club, etc.)\n",
    "- concentration    (EDT/EDP/Extrait/Parfum/Cologne)\n",
    "\n",
    "[Price intent keywords (not exhaustive)]\n",
    "- Korean: 가격, 최저가, 얼마, 가격대, 구매, 판매, 할인, 어디서 사, 배송비\n",
    "- English: price, cost, cheapest, buy, purchase, discount\n",
    "\n",
    "[FAQ examples]\n",
    "- Differences between EDP vs EDT, note definitions, longevity/projection, brand/line info.\n",
    "\n",
    "[Single-preference (ML_agent) examples]\n",
    "- \"Recommend a cool perfume for summer\", \"Recommend a sweet scent\", \"One citrusy fresh pick\"\n",
    "  (= 0–1 of the above facets mentioned; primarily taste/mood/situation).\n",
    "\n",
    "[Routing rules (priority)]\n",
    "1) Non-perfume / off-topic → human_fallback\n",
    "2) Clear price-only intent (even if one facet is present as context) → price_agent\n",
    "   e.g., \"Chanel No. 5 50ml cheapest price?\" → price_agent\n",
    "3) Count product facets in the query:\n",
    "   - If facets ≥ 2 → LLM_parser\n",
    "4) Otherwise (single-topic queries):\n",
    "   - Perfume knowledge/definitions → FAQ_agent\n",
    "   - Single taste/mood recommendation → ML_agent\n",
    "5) Tie-breakers:\n",
    "   - If price intent is clear → price_agent\n",
    "   - If facets ≥ 2 → LLM_parser\n",
    "   - Else: knowledge → FAQ_agent, taste → ML_agent\n",
    "\n",
    "[Output format]\n",
    "Return ONLY this JSON (no extra text):\n",
    "{{\n",
    "  \"next\": \"<LLM_parser|FAQ_agent|human_fallback|price_agent|ML_agent>\",\n",
    "  \"reason\": \"<one short English sentence>\",\n",
    "  \"facet_count\": <integer>,\n",
    "  \"facets\": {{\n",
    "    \"brand\": \"<value or null>\",\n",
    "    \"season\": \"<value or null>\",\n",
    "    \"gender\": \"<value or null>\",\n",
    "    \"sizes\": \"<value or null>\",\n",
    "    \"day_night_score\": \"<value or null>\",\n",
    "    \"concentration\": \"<value or null>\"\n",
    "  }},\n",
    "  \"scent_vibe\": \"<value if detected, else null>\",\n",
    "  \"query_intent\": \"<price|faq|scent_pref|non_perfume|other>\"\n",
    "}}\n",
    "\"\"\".strip()\n",
    "\n",
    "# ---------- 1) State ----------\n",
    "class AgentState(TypedDict):\n",
    "    messages: List[BaseMessage]           # conversation log\n",
    "    next: Optional[str]                   # routing decision key\n",
    "    router_json: Optional[Dict[str, Any]] # parsed JSON from router\n",
    "\n",
    "# ---------- 2) LLM 초기화 ----------\n",
    "llm = ChatOpenAI(model=MODEL_NAME, temperature=0)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "# Pinecone 초기화\n",
    "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "index = pc.Index(\"perfume-vectordb2\")\n",
    "\n",
    "router_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", SUPERVISOR_SYSTEM_PROMPT),\n",
    "        (\"user\", \"{query}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "def supervisor_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Call the router LLM and return parsed JSON + routing target.\"\"\"\n",
    "    user_query = None\n",
    "    for m in reversed(state[\"messages\"]):\n",
    "        if isinstance(m, HumanMessage):\n",
    "            user_query = m.content\n",
    "            break\n",
    "    if not user_query:\n",
    "        user_query = \"(empty)\"\n",
    "\n",
    "    chain = router_prompt | llm\n",
    "    ai = chain.invoke({\"query\": user_query})\n",
    "    text = ai.content\n",
    "\n",
    "    # JSON strict parse\n",
    "    chosen = \"human_fallback\"\n",
    "    parsed: Dict[str, Any] = {}\n",
    "    try:\n",
    "        parsed = json.loads(text)\n",
    "        maybe = parsed.get(\"next\")\n",
    "        if isinstance(maybe, str) and maybe in {\"LLM_parser\",\"FAQ_agent\",\"human_fallback\",\"price_agent\",\"ML_agent\"}:\n",
    "            chosen = maybe\n",
    "    except Exception:\n",
    "        parsed = {\"error\": \"invalid_json\", \"raw\": text}\n",
    "\n",
    "    msgs = state[\"messages\"] + [AIMessage(content=text)]\n",
    "    return {\n",
    "        \"messages\": msgs,\n",
    "        \"next\": chosen,\n",
    "        \"router_json\": parsed\n",
    "    }\n",
    "\n",
    "# ---------- 3) RAG Pipeline Functions ----------\n",
    "parse_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"너는 향수 쿼리 파서야.\n",
    "사용자의 질문에서 다음 정보를 JSON 형식으로 추출해줘:\n",
    "- brand: 브랜드명 (예: 샤넬, 디올, 입생로랑 등)\n",
    "- concentration: (퍼퓸, 코롱 등)\n",
    "- day_night_score: 사용시간 (주간, 야간, 데일리 등)\n",
    "- gender: 성별 (남성, 여성, 유니섹스)\n",
    "- season_score: 계절 (봄, 여름, 가을, 겨울)\n",
    "- sizes: 용량 (30ml, 50ml, 100ml 등) 단위는 무시하고 숫자만\n",
    "\n",
    "없는 값은 null로 두고, 반드시 유효한 JSON 형식으로만 응답해줘.\n",
    "\n",
    "예시:\n",
    "{{\"brand\": \"샤넬\", \"gender\": null, \"sizes\": \"50\", \"season_score\": null, \"concentration\": null, \"day_night_score\": null}}\"\"\"),\n",
    "    (\"user\", \"{query}\")\n",
    "])\n",
    "\n",
    "def run_llm_parser(query: str):\n",
    "    \"\"\"사용자 쿼리를 JSON으로 파싱\"\"\"\n",
    "    try:\n",
    "        chain = parse_prompt | llm\n",
    "        ai_response = chain.invoke({\"query\": query})\n",
    "        response_text = ai_response.content.strip()\n",
    "\n",
    "        # JSON 부분만 추출\n",
    "        if \"```json\" in response_text:\n",
    "            response_text = response_text.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "        elif \"```\" in response_text:\n",
    "            response_text = response_text.split(\"```\")[1].strip()\n",
    "\n",
    "        parsed = json.loads(response_text)\n",
    "        return parsed\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"파싱 오류: {str(e)}\"}\n",
    "\n",
    "# 메타필터 함수들\n",
    "def filter_brand(brand_value):\n",
    "    valid_brands = [\n",
    "        '겔랑', '구찌', '끌로에', '나르시소 로드리게즈', '니샤네', '도르세', '디올', '딥티크', '랑콤',\n",
    "        '로라 메르시에', '로에베', '록시땅', '르 라보', '메모', '메종 마르지엘라', '메종 프란시스 커정',\n",
    "        '멜린앤게츠', '미우미우', '바이레도', '반클리프 아펠', '버버리', '베르사체', '불가리', '비디케이',\n",
    "        '산타 마리아 노벨라', '샤넬', '세르주 루텐', '시슬리 코스메틱', '아쿠아 디 파르마', '에따 리브르 도량쥬',\n",
    "        '에르메스', '에스티 로더', '엑스 니힐로', '이니시오 퍼퓸', '이솝', '입생로랑', '제르조프', '조 말론',\n",
    "        '조르지오 아르마니', '줄리엣 헤즈 어 건', '지방시', '질 스튜어트', '크리드', '킬리안', '톰 포드',\n",
    "        '티파니앤코', '퍼퓸 드 말리', '펜할리곤스', '프라다', '프레데릭 말'\n",
    "    ]\n",
    "    if brand_value is None:\n",
    "        return None\n",
    "    return brand_value if brand_value in valid_brands else None\n",
    "\n",
    "def filter_concentration(concentration_value):\n",
    "    valid_concentrations = ['솔리드 퍼퓸', '엑스트레 드 퍼퓸', '오 드 뚜왈렛', '오 드 코롱', '오 드 퍼퓸', '퍼퓸']\n",
    "    if concentration_value is None:\n",
    "        return None\n",
    "    return concentration_value if concentration_value in valid_concentrations else None\n",
    "\n",
    "def filter_day_night_score(day_night_value):\n",
    "    valid_day_night = [\"day\", \"night\"]\n",
    "    if day_night_value is None:\n",
    "        return None\n",
    "    if isinstance(day_night_value, str) and ',' in day_night_value:\n",
    "        values = [v.strip() for v in day_night_value.split(',')]\n",
    "        filtered_values = [v for v in values if v in valid_day_night]\n",
    "        return ','.join(filtered_values) if filtered_values else None\n",
    "    return day_night_value if day_night_value in valid_day_night else None\n",
    "\n",
    "def filter_gender(gender_value):\n",
    "    valid_genders = ['Female', 'Male', 'Unisex', 'unisex ']\n",
    "    if gender_value is None:\n",
    "        return None\n",
    "    return gender_value if gender_value in valid_genders else None\n",
    "\n",
    "def filter_season_score(season_value):\n",
    "    valid_seasons = ['winter', 'spring', 'summer', 'fall']\n",
    "    if season_value is None:\n",
    "        return None\n",
    "    return season_value if season_value in valid_seasons else None\n",
    "\n",
    "def filter_sizes(sizes_value):\n",
    "    valid_sizes = ['30', '50', '75', '100', '150']\n",
    "    if sizes_value is None:\n",
    "        return None\n",
    "    if isinstance(sizes_value, str):\n",
    "        numbers = re.findall(r'\\d+', sizes_value)\n",
    "        for num in numbers:\n",
    "            if num in valid_sizes:\n",
    "                return num\n",
    "    return str(sizes_value) if str(sizes_value) in valid_sizes else None\n",
    "\n",
    "def apply_meta_filters(parsed_json: dict) -> dict:\n",
    "    \"\"\"파싱된 JSON에 메타필터링 적용\"\"\"\n",
    "    if not parsed_json or \"error\" in parsed_json:\n",
    "        return parsed_json\n",
    "    \n",
    "    return {\n",
    "        'brand': filter_brand(parsed_json.get('brand')),\n",
    "        'concentration': filter_concentration(parsed_json.get('concentration')),\n",
    "        'day_night_score': filter_day_night_score(parsed_json.get('day_night_score')),\n",
    "        'gender': filter_gender(parsed_json.get('gender')),\n",
    "        'season_score': filter_season_score(parsed_json.get('season_score')),\n",
    "        'sizes': filter_sizes(parsed_json.get('sizes'))\n",
    "    }\n",
    "\n",
    "def build_pinecone_filter(filtered_json: dict) -> dict:\n",
    "    \"\"\"메타필터링 결과를 Pinecone filter dict로 변환\"\"\"\n",
    "    pinecone_filter = {}\n",
    "    if filtered_json.get(\"brand\"):\n",
    "        pinecone_filter[\"brand\"] = {\"$eq\": filtered_json[\"brand\"]}\n",
    "    if filtered_json.get(\"sizes\"):\n",
    "        pinecone_filter[\"sizes\"] = {\"$eq\": filtered_json[\"sizes\"]}\n",
    "    if filtered_json.get(\"season_score\"):\n",
    "        pinecone_filter[\"season_score\"] = {\"$eq\": filtered_json[\"season_score\"]}\n",
    "    if filtered_json.get(\"gender\"):\n",
    "        pinecone_filter[\"gender\"] = {\"$eq\": filtered_json[\"gender\"]}\n",
    "    if filtered_json.get(\"concentration\"):\n",
    "        pinecone_filter[\"concentration\"] = {\"$eq\": filtered_json[\"concentration\"]}\n",
    "    if filtered_json.get(\"day_night_score\"):\n",
    "        pinecone_filter[\"day_night_score\"] = {\"$eq\": filtered_json[\"day_night_score\"]}\n",
    "    return pinecone_filter\n",
    "@tool\n",
    "def price_tool(user_query: str) -> str: #이거 price_agent 함수야\n",
    "    \"\"\"A tool that uses the Naver Shopping API to look up perfume prices (results are returned as formatted strings)\"\"\"\n",
    "    \n",
    "    url = \"https://openapi.naver.com/v1/search/shop.json\"\n",
    "    headers = {\n",
    "        \"X-Naver-Client-Id\": naver_client_id,\n",
    "        \"X-Naver-Client-Secret\": naver_client_secret\n",
    "    }\n",
    "    params = {\"query\": user_query, \"display\": 5, \"sort\": \"sim\"}\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "    except Exception as e:\n",
    "        return f\"❌ 요청 오류: {e}\"\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        return f\"❌ API 오류: {response.status_code}\"\n",
    "    \n",
    "    data = response.json()\n",
    "    if not data or \"items\" not in data or len(data[\"items\"]) == 0:\n",
    "        return f\"😔 '{user_query}'에 대한 검색 결과가 없습니다.\"\n",
    "    \n",
    "    # HTML 태그 제거 함수\n",
    "    def remove_html_tags(text: str) -> str:\n",
    "        return re.sub(r\"<[^>]+>\", \"\", text)\n",
    "    \n",
    "    # 상위 3개만 정리\n",
    "    products = data[\"items\"][:3]\n",
    "    output = f\"🔍 '{user_query}' 검색 결과:\\n\\n\"\n",
    "    for i, item in enumerate(products, 1):\n",
    "        title = remove_html_tags(item.get(\"title\", \"\"))\n",
    "        lprice = item.get(\"lprice\", \"0\")\n",
    "        mall = item.get(\"mallName\", \"정보 없음\")\n",
    "        link = item.get(\"link\", \"정보 없음\")\n",
    "        \n",
    "        output += f\"📦 {i}. {title}\\n\"\n",
    "        if lprice != \"0\":\n",
    "            output += f\"   💰 가격: {int(lprice):,}원\\n\"\n",
    "        output += f\"   🏪 판매처: {mall}\\n\"\n",
    "        output += f\"   🔗 링크: {link}\\n\\n\"\n",
    "    \n",
    "    return output\n",
    "\n",
    "def human_fallback(state: dict) -> str:\n",
    "    \"\"\"향수 관련 복잡한 질문에 대한 기본 응답\"\"\"\n",
    "    query = state.get(\"input\", \"\")\n",
    "    return (\n",
    "        f\"❓ '{query}' 더 명확한 설명이 필요합니다.\\n\"\n",
    "        f\"👉 질문을 구체적으로 다시 작성해 주세요.\\n\"\n",
    "        f\"💡 또는 향수에 관한 멋진 질문을 해보시는 건 어떨까요?\")\n",
    "\n",
    "def query_pinecone(vector, filtered_json: dict, top_k: int = 5):\n",
    "    \"\"\"Pinecone 벡터 검색 + 메타데이터 필터 적용\"\"\"\n",
    "    pinecone_filter = build_pinecone_filter(filtered_json)\n",
    "    \n",
    "    result = index.query(\n",
    "        vector=vector,\n",
    "        top_k=top_k,\n",
    "        include_metadata=True,\n",
    "        filter=pinecone_filter if pinecone_filter else None\n",
    "    )\n",
    "    return result\n",
    "\n",
    "response_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"너는 향수 전문가야. 사용자의 질문에 대해 검색된 향수 정보를 바탕으로 친절하고 전문적인 추천을 해줘.\n",
    "\n",
    "추천할 때 다음을 포함해줘:\n",
    "1. 왜 이 향수를 추천하는지\n",
    "2. 향의 특징과 느낌\n",
    "3. 어떤 상황에 적합한지\n",
    "4. 가격대나 용량 관련 조언 (있다면)\n",
    "\n",
    "자연스럽고 친근한 톤으로 답변해줘.\"\"\"),\n",
    "    (\"user\", \"\"\"사용자 질문: {original_query}\n",
    "\n",
    "검색된 향수 정보:\n",
    "{search_results}\n",
    "\n",
    "위 정보를 바탕으로 향수를 추천해줘.\"\"\")\n",
    "])\n",
    "\n",
    "def format_search_results(pinecone_results):\n",
    "    \"\"\"Pinecone 검색 결과를 텍스트로 포맷팅\"\"\"\n",
    "    if not pinecone_results or not pinecone_results.get('matches'):\n",
    "        return \"검색된 향수가 없습니다.\"\n",
    "    \n",
    "    formatted_results = []\n",
    "    for i, match in enumerate(pinecone_results['matches'], 1):\n",
    "        metadata = match.get('metadata', {})\n",
    "        score = match.get('score', 0)\n",
    "        \n",
    "        result_text = f\"\"\"\n",
    "{i}. 향수명: {metadata.get('perfume_name', '정보없음')}\n",
    "   - 브랜드: {metadata.get('brand', '정보없음')}\n",
    "   - 성별: {metadata.get('gender', '정보없음')}\n",
    "   - 용량: {metadata.get('sizes', '정보없음')}ml\n",
    "   - 계절: {metadata.get('season_score', '정보없음')}\n",
    "   - 사용시간: {metadata.get('day_night_score', '정보없음')}\n",
    "   - 농도: {metadata.get('concentration', '정보없음')}\n",
    "   - 유사도 점수: {score:.3f}\n",
    "\"\"\"\n",
    "        formatted_results.append(result_text.strip())\n",
    "    \n",
    "    return \"\\n\\n\".join(formatted_results)\n",
    "\n",
    "def generate_response(original_query: str, search_results):\n",
    "    \"\"\"검색 결과를 바탕으로 최종 응답 생성\"\"\"\n",
    "    try:\n",
    "        formatted_results = format_search_results(search_results)\n",
    "        \n",
    "        chain = response_prompt | llm\n",
    "        response = chain.invoke({\n",
    "            \"original_query\": original_query,\n",
    "            \"search_results\": formatted_results\n",
    "        })\n",
    "        \n",
    "        return response.content\n",
    "    except Exception as e:\n",
    "        return f\"응답 생성 중 오류가 발생했습니다: {str(e)}\"\n",
    "\n",
    "# ---------- 4) Agent Nodes ----------\n",
    "def LLM_parser_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"실제 RAG 파이프라인을 실행하는 LLM_parser 노드\"\"\"\n",
    "    user_query = None\n",
    "    for m in reversed(state[\"messages\"]):\n",
    "        if isinstance(m, HumanMessage):\n",
    "            user_query = m.content\n",
    "            break\n",
    "    if not user_query:\n",
    "        user_query = \"(empty)\"\n",
    "\n",
    "    try:\n",
    "        print(f\"🔍 LLM_parser 실행: {user_query}\")\n",
    "        \n",
    "        # 1단계: LLM으로 쿼리 파싱\n",
    "        parsed_json = run_llm_parser(user_query)\n",
    "        if \"error\" in parsed_json:\n",
    "            error_msg = f\"[LLM_parser] 쿼리 파싱 오류: {parsed_json['error']}\"\n",
    "            msgs = state[\"messages\"] + [AIMessage(content=error_msg)]\n",
    "            return {\"messages\": msgs, \"next\": None, \"router_json\": state.get(\"router_json\")}\n",
    "        \n",
    "        # 2단계: 메타필터 적용\n",
    "        filtered_json = apply_meta_filters(parsed_json)\n",
    "        \n",
    "        # 3단계: 쿼리 벡터화\n",
    "        query_vector = embeddings.embed_query(user_query)\n",
    "        \n",
    "        # 4단계: Pinecone 검색\n",
    "        search_results = query_pinecone(query_vector, filtered_json, top_k=5)\n",
    "        \n",
    "        # 5단계: 최종 응답 생성\n",
    "        final_response = generate_response(user_query, search_results)\n",
    "        \n",
    "        # 결과 요약\n",
    "        summary = f\"\"\"[LLM_parser] RAG 파이프라인 완료 ✅\n",
    "\n",
    "📊 파싱 결과: {json.dumps(parsed_json, ensure_ascii=False)}\n",
    "🔍 필터링 결과: {json.dumps(filtered_json, ensure_ascii=False)}\n",
    "🎯 검색된 향수 개수: {len(search_results.get('matches', []))}\n",
    "\n",
    "💬 추천 결과:\n",
    "{final_response}\"\"\"\n",
    "\n",
    "        msgs = state[\"messages\"] + [AIMessage(content=summary)]\n",
    "        return {\"messages\": msgs, \"next\": None, \"router_json\": state.get(\"router_json\")}\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"[LLM_parser] RAG 파이프라인 실행 중 오류: {str(e)}\"\n",
    "        msgs = state[\"messages\"] + [AIMessage(content=error_msg)]\n",
    "        return {\"messages\": msgs, \"next\": None, \"router_json\": state.get(\"router_json\")}\n",
    "\n",
    "def passthrough(name: str):\n",
    "    def _node(state: AgentState) -> AgentState:\n",
    "        payload = state.get(\"router_json\") or {}\n",
    "        summary = f\"[{name}] handled. reason={payload.get('reason')} facets={payload.get('facets')} intent={payload.get('query_intent')}\"\n",
    "        msgs = state[\"messages\"] + [AIMessage(content=summary)]\n",
    "        return {\"messages\": msgs, \"next\": None, \"router_json\": state.get(\"router_json\")}\n",
    "    return _node\n",
    "\n",
    "price_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a perfume price specialist assistant.\n",
    "    \n",
    "When users ask about perfume prices:\n",
    "1. Use the price_tool to search for current prices\n",
    "2. Always respond in Korean\n",
    "3. Format results nicely with emojis and clear information\n",
    "4. Be helpful and friendly\n",
    "    \n",
    "If you can't find price information, politely explain and suggest alternative searches.\"\"\"),\n",
    "    (\"placeholder\", \"{messages}\"),\n",
    "])\n",
    "\n",
    "price_agent = create_react_agent(\n",
    "    llm, \n",
    "    [price_tool],\n",
    "    prompt=price_prompt\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- 7) 에이전트 호출 래퍼 ---\n",
    "def price_agent_node(state: AgentState) -> dict:\n",
    "    \"\"\"Price agent 호출\"\"\"\n",
    "    result = price_agent.invoke(state)\n",
    "    return {\"messages\": result[\"messages\"]}\n",
    "\n",
    "def FAQ_agent_node(state: AgentState) -> dict:\n",
    "    \"\"\"FAQ_agent_nodet 호출\"\"\"\n",
    "    result = FAQ_agent.invoke(state)\n",
    "    return {\"messages\": result[\"messages\"]}\n",
    "\n",
    "def ML_agent_node(state: AgentState) -> dict:\n",
    "    \"\"\"ML_agent 호출\"\"\"\n",
    "    result = ML_agent.invoke(state)\n",
    "    return {\"messages\": result[\"messages\"]}\n",
    "\n",
    "# FAQ_agent       = passthrough(\"FAQ_agent\")\n",
    "# human_fallback  = passthrough(\"human_fallback\")\n",
    "# price_agent     = passthrough(\"price_agent\")\n",
    "# ML_agent        = passthrough(\"ML_agent\")\n",
    "\n",
    "# ---------- 5) Build Graph ----------\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"supervisor\", supervisor_node)\n",
    "graph.add_node(\"LLM_parser\", LLM_parser_node)  # 실제 RAG 파이프라인 연결\n",
    "graph.add_node(\"FAQ_agent\", FAQ_agent_node)\n",
    "graph.add_node(\"human_fallback\", human_fallback)\n",
    "graph.add_node(\"price_agent\", price_agent_node)\n",
    "graph.add_node(\"ML_agent\", ML_agent_node)\n",
    "\n",
    "graph.set_entry_point(\"supervisor\")\n",
    "\n",
    "# Conditional routing\n",
    "def router_edge(state: AgentState) -> str:\n",
    "    return state[\"next\"] or \"human_fallback\"\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"supervisor\",\n",
    "    router_edge,\n",
    "    {\n",
    "        \"LLM_parser\": \"LLM_parser\",\n",
    "        \"FAQ_agent\": \"FAQ_agent\",\n",
    "        \"human_fallback\": \"human_fallback\",\n",
    "        \"price_agent\": \"price_agent\",\n",
    "        \"ML_agent\": \"ML_agent\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# End states\n",
    "for node in [\"LLM_parser\", \"FAQ_agent\", \"human_fallback\", \"price_agent\", \"ML_agent\"]:\n",
    "    graph.add_edge(node, END)\n",
    "\n",
    "app = graph.compile()\n",
    "\n",
    "# ---------- 6) Batch Test ----------\n",
    "TEST_QUERIES = [\n",
    "    \"입생로랑 여성용 50ml 겨울용 향수 추천해줘.\",                 \n",
    "    \"디올 EDP로 가을 밤(야간)에 쓸 만한 향수 있어?\",                \n",
    "    \"EDP랑 EDT 차이가 뭐야?\",                                       \n",
    "    \"탑노트·미들노트·베이스노트가 각각 무슨 뜻이야?\",               \n",
    "    \"오늘 점심 뭐 먹을까?\",                                         \n",
    "    \"오늘 서울 날씨 어때?\",                                         \n",
    "    \"샤넬 넘버5 50ml 최저가 알려줘.\",                               \n",
    "    \"디올 소바쥬 가격 얼마야? 어디서 사는 게 제일 싸?\",             \n",
    "    \"여름에 시원한 향수 추천해줘.\",                                 \n",
    "    \"달달한 향 추천해줘.\",                                         \n",
    "]\n",
    "\n",
    "def run_tests():\n",
    "    for q in TEST_QUERIES:\n",
    "        print(\"=\"*80)\n",
    "        print(\"Query:\", q)\n",
    "        init: AgentState = {\n",
    "            \"messages\": [HumanMessage(content=q)],\n",
    "            \"next\": None,\n",
    "            \"router_json\": None\n",
    "        }\n",
    "        out = app.invoke(init)\n",
    "        ai_msgs = [m for m in out[\"messages\"] if isinstance(m, AIMessage)]\n",
    "        router_raw = ai_msgs[-2].content if len(ai_msgs) >= 2 else \"(no router output)\"\n",
    "        agent_summary = ai_msgs[-1].content if ai_msgs else \"(no agent output)\"\n",
    "        print(\"Router JSON:\", router_raw)\n",
    "        print(\"Agent summary:\", agent_summary)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 환경 변수 확인\n",
    "    print(\"🔧 환경 변수 확인:\")\n",
    "    print(f\"OPENAI_API_KEY: {'✅ 설정됨' if os.getenv('OPENAI_API_KEY') else '❌ 미설정'}\")\n",
    "    print(f\"PINECONE_API_KEY: {'✅ 설정됨' if os.getenv('PINECONE_API_KEY') else '❌ 미설정'}\")\n",
    "    print(f\"NAVER_CLIENT_ID: {'✅ 설정됨' if os.getenv('NAVER_CLIENT_ID') else '❌ 미설정'}\")\n",
    "    print(f\"NAVER_CLIENT_SECRET: {'✅ 설정됨' if os.getenv('NAVER_CLIENT_SECRET') else '❌ 미설정'}\")\n",
    "    print()\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    run_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35e7d78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
