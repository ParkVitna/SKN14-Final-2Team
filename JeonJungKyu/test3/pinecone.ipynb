{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98011299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 환경 변수 로드 완료\n",
      "✅ Pinecone 클라이언트 초기화 완료\n",
      "✅ OpenAI 클라이언트 초기화 완료\n",
      "🚀 Perfume 벡터 업로드 시작!\n",
      "\n",
      "🔨 인덱스 'perfume-vectordb2' 생성 중...\n",
      "✅ 인덱스 'perfume-vectordb2' 생성 완료\n",
      "⏳ 인덱스 준비 상태 확인 중...(최대 10초)\n",
      "⚠️ 준비 확인 타임아웃 → 강제 진행\n",
      "📖 CSV 로딩: perfume_final_vector.csv\n",
      "📊 행 802개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔄 Document 생성: 100%|██████████| 802/802 [00:00<00:00, 11119.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Document 802개 생성 완료\n",
      "\n",
      "================================================================================\n",
      "📋 Document 샘플\n",
      "================================================================================\n",
      "\n",
      "[1] ID: perfume_da4dd656e12bc7dc\n",
      "page_content: 강렬한 매혹의 향기.\n",
      "metadata: {'no': 1, 'brand': '겔랑', 'name': '랭스땅 드 겔랑 오 드 퍼퓸', 'concentration': '오 드 퍼퓸', 'gender': 'Female', 'sizes': ['75'], 'season_score': 'fall', 'day_night_score': 'day', 'id': 'perfume_da4dd656e12bc7dc'}\n",
      "------------------------------------------------------------\n",
      "\n",
      "[2] ID: perfume_b88e79b3bf4bebd1\n",
      "page_content: 이루어질 수 없는 사랑의 전설 스파이시한 복숭아와 페출리의 비밀스러운 만남\n",
      "metadata: {'no': 2, 'brand': '겔랑', 'name': '레전더리 미츠코 오 드 퍼퓸', 'concentration': '오 드 퍼퓸', 'gender': 'Female', 'sizes': ['75'], 'season_score': 'winter', 'day_night_score': 'day', 'id': 'perfume_b88e79b3bf4bebd1'}\n",
      "------------------------------------------------------------\n",
      "\n",
      "[3] ID: perfume_486182a360098d83\n",
      "page_content: 자스민과 샌달우드의 조화로 이루어진 신성한 사랑의 향기\n",
      "metadata: {'no': 3, 'brand': '겔랑', 'name': '레전더리 삼사라 오 드 뚜왈렛', 'concentration': '오 드 뚜왈렛', 'gender': 'Female', 'sizes': ['75'], 'season_score': 'fall', 'day_night_score': 'day', 'id': 'perfume_486182a360098d83'}\n",
      "------------------------------------------------------------\n",
      "================================================================================\n",
      "\n",
      "🔄 임베딩(배치) 생성: batch=128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🧮 임베딩 배치: 100%|██████████| 7/7 [00:12<00:00,  1.74s/it]\n",
      "c:\\Users\\Playdata2\\miniconda3\\envs\\final-env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 벡터 802개 생성 완료\n",
      "📤 업서트(배치): batch=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📦 업서트(batched):  11%|█         | 1/9 [00:03<00:25,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ↳ call#1 batch_size=100 (누적 성공=100, 실패=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📦 업서트(batched):  22%|██▏       | 2/9 [00:04<00:13,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ↳ call#2 batch_size=100 (누적 성공=200, 실패=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📦 업서트(batched):  33%|███▎      | 3/9 [00:05<00:09,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ↳ call#3 batch_size=100 (누적 성공=300, 실패=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📦 업서트(batched):  44%|████▍     | 4/9 [00:06<00:07,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ↳ call#4 batch_size=100 (누적 성공=400, 실패=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📦 업서트(batched):  56%|█████▌    | 5/9 [00:08<00:05,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ↳ call#5 batch_size=100 (누적 성공=500, 실패=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📦 업서트(batched):  67%|██████▋   | 6/9 [00:09<00:04,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ↳ call#6 batch_size=100 (누적 성공=600, 실패=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📦 업서트(batched):  78%|███████▊  | 7/9 [00:11<00:02,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ↳ call#7 batch_size=100 (누적 성공=700, 실패=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📦 업서트(batched):  89%|████████▉ | 8/9 [00:12<00:01,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ↳ call#8 batch_size=100 (누적 성공=800, 실패=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📦 업서트(batched): 100%|██████████| 9/9 [00:12<00:00,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ↳ call#9 batch_size=2 (누적 성공=802, 실패=0)\n",
      "📞 업서트 호출수: 9\n",
      "✅ 업서트 완료 | 성공: 802  실패: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 최종 벡터 수: 0\n",
      "🎉 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import hashlib\n",
    "from typing import Dict, Any, List, Optional, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from openai import OpenAI\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# =========================================\n",
    "# .env 로드\n",
    "# =========================================\n",
    "load_dotenv()\n",
    "\n",
    "# =========================================\n",
    "# 유틸\n",
    "# =========================================\n",
    "def _norm(s: Any) -> str:\n",
    "    s = \"\" if s is None else str(s)\n",
    "    s = s.strip()\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s\n",
    "\n",
    "def make_stable_id(brand: str, name: str) -> str:\n",
    "    \"\"\"브랜드+이름 기반 안정적 ID\"\"\"\n",
    "    base = f\"{brand.strip()}::{name.strip()}\".lower()\n",
    "    hid = hashlib.sha1(base.encode(\"utf-8\")).hexdigest()[:16]\n",
    "    return f\"perfume_{hid}\"\n",
    "\n",
    "def parse_sizes(sizes_str: str) -> List[str]:\n",
    "    \"\"\"sizes 문자열을 파싱해서 리스트로 반환\"\"\"\n",
    "    if pd.isna(sizes_str) or not str(sizes_str).strip() or str(sizes_str).lower() == \"nan\":\n",
    "        return []\n",
    "    \n",
    "    sizes_str = str(sizes_str).strip()\n",
    "    \n",
    "    # [75], [50, 100] 같은 형태 처리\n",
    "    if sizes_str.startswith('[') and sizes_str.endswith(']'):\n",
    "        try:\n",
    "            # 문자열에서 숫자만 추출\n",
    "            numbers = re.findall(r'\\d+', sizes_str)\n",
    "            return numbers\n",
    "        except:\n",
    "            return []\n",
    "    \n",
    "    # 쉼표로 구분된 형태나 다른 형태 처리\n",
    "    numbers = re.findall(r'\\d+', sizes_str)\n",
    "    return numbers\n",
    "\n",
    "class PerfumeVectorUploader:\n",
    "    def __init__(self):\n",
    "        \"\"\"Pinecone / OpenAI 초기화 & 설정\"\"\"\n",
    "        self.pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "        self.openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "        if not self.pinecone_api_key:\n",
    "            raise ValueError(\"❌ PINECONE_API_KEY가 .env에 없습니다.\")\n",
    "        if not self.openai_api_key:\n",
    "            raise ValueError(\"❌ OPENAI_API_KEY가 .env에 없습니다.\")\n",
    "\n",
    "        print(\"✅ 환경 변수 로드 완료\")\n",
    "\n",
    "        # Pinecone\n",
    "        try:\n",
    "            self.pc = Pinecone(api_key=self.pinecone_api_key)\n",
    "            print(\"✅ Pinecone 클라이언트 초기화 완료\")\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"❌ Pinecone 초기화 실패: {e}\")\n",
    "\n",
    "        # OpenAI\n",
    "        try:\n",
    "            self.openai = OpenAI(api_key=self.openai_api_key)\n",
    "            print(\"✅ OpenAI 클라이언트 초기화 완료\")\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"❌ OpenAI 초기화 실패: {e}\")\n",
    "\n",
    "        # ===== 설정 =====\n",
    "        self.index_name = \"perfume-vectordb2\"\n",
    "        self.dimension = 1536\n",
    "        self.embedding_model = \"text-embedding-3-small\"\n",
    "\n",
    "        self.namespace = \"\"   # 필요 시 분리\n",
    "        self.embed_batch_size = 128\n",
    "        self.upsert_batch_size = 100\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 인덱스 재생성 (존재하면 삭제 후 생성)\n",
    "    # -------------------------------------\n",
    "    def recreate_index(self) -> None:\n",
    "        try:\n",
    "            names = [idx.name for idx in self.pc.list_indexes()]\n",
    "            if self.index_name in names:\n",
    "                print(f\"🧨 인덱스 '{self.index_name}' 삭제 중...\")\n",
    "                self.pc.delete_index(self.index_name)\n",
    "\n",
    "            print(f\"🔨 인덱스 '{self.index_name}' 생성 중...\")\n",
    "            self.pc.create_index(\n",
    "                name=self.index_name,\n",
    "                dimension=self.dimension,\n",
    "                metric=\"cosine\",\n",
    "                spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "            )\n",
    "            print(f\"✅ 인덱스 '{self.index_name}' 생성 완료\")\n",
    "            self.wait_until_ready()\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"❌ 인덱스 재생성 실패: {e}\")\n",
    "\n",
    "    def wait_until_ready(self, timeout_sec: int = 10, interval_sec: float = 1.0) -> None:\n",
    "        \"\"\"\n",
    "        인덱스가 ready 될 때까지 짧게 폴링.\n",
    "        - 기본: 최대 10초 동안 1초 간격으로 확인\n",
    "        - 그 이후에는 강제로 진행\n",
    "        \"\"\"\n",
    "        print(f\"⏳ 인덱스 준비 상태 확인 중...(최대 {timeout_sec}초)\")\n",
    "        start = time.time()\n",
    "        while True:\n",
    "            try:\n",
    "                desc = self.pc.describe_index(self.index_name)\n",
    "                status = getattr(desc, \"status\", {}) or {}\n",
    "                ready = False\n",
    "                if isinstance(status, dict):\n",
    "                    ready = bool(status.get(\"ready\")) or (status.get(\"state\") == \"Ready\")\n",
    "                if ready:\n",
    "                    print(\"✅ 인덱스 준비 완료\")\n",
    "                    return\n",
    "            except Exception:\n",
    "                pass\n",
    "            if time.time() - start > timeout_sec:\n",
    "                print(\"⚠️ 준비 확인 타임아웃 → 강제 진행\")\n",
    "                return\n",
    "            time.sleep(interval_sec)\n",
    "\n",
    "    # -------------------------------------\n",
    "    # CSV → Document\n",
    "    # -------------------------------------\n",
    "    def parse_score_string(self, score_str: str) -> Optional[str]:\n",
    "        \"\"\"점수 문자열에서 가장 높은 점수의 키를 반환\"\"\"\n",
    "        if pd.isna(score_str) or not str(score_str).strip() or str(score_str).lower() == \"nan\":\n",
    "            return None\n",
    "        try:\n",
    "            s = str(score_str).strip()\n",
    "            scores: Dict[str, float] = {}\n",
    "            \n",
    "            # winter(14.2) / spring(24.1) 형태 처리\n",
    "            if \"(\" in s and \")\" in s:\n",
    "                pattern = r\"(\\w+)\\s*\\(\\s*([\\d.]+)\\s*\\)\"\n",
    "                for key, val in re.findall(pattern, s):\n",
    "                    try:\n",
    "                        scores[key.strip()] = float(val.strip())\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "            # JSON 형태 처리\n",
    "            elif s.startswith(\"{\") and s.endswith(\"}\"):\n",
    "                try:\n",
    "                    d = json.loads(s)\n",
    "                    for k, v in d.items():\n",
    "                        if isinstance(v, str):\n",
    "                            cv = v.replace(\"%\", \"\").strip()\n",
    "                            if cv:\n",
    "                                scores[str(k)] = float(cv)\n",
    "                        elif isinstance(v, (int, float)):\n",
    "                            scores[str(k)] = float(v)\n",
    "                except json.JSONDecodeError:\n",
    "                    pass\n",
    "            \n",
    "            return max(scores, key=scores.get) if scores else None\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    def csv_to_documents(self, csv_path: str) -> List[Document]:\n",
    "        if not os.path.exists(csv_path):\n",
    "            raise FileNotFoundError(f\"❌ CSV 파일을 찾을 수 없습니다: {csv_path}\")\n",
    "\n",
    "        print(f\"📖 CSV 로딩: {csv_path}\")\n",
    "        df = pd.read_csv(csv_path)\n",
    "        print(f\"📊 행 {len(df)}개\")\n",
    "\n",
    "        docs: List[Document] = []\n",
    "        for _, row in tqdm(df.iterrows(), total=len(df), desc=\"🔄 Document 생성\"):\n",
    "            description = str(row.get(\"description\", \"\")).strip()\n",
    "            if not description or description.lower() == \"nan\":\n",
    "                continue\n",
    "\n",
    "            # 점수에서 최고값 추출\n",
    "            season_top   = self.parse_score_string(str(row.get(\"season_score\", \"\")))\n",
    "            daynight_top = self.parse_score_string(str(row.get(\"day_night_score\", \"\")))\n",
    "\n",
    "            brand = _norm(row.get(\"brand\", \"\"))\n",
    "            name  = _norm(row.get(\"name\", \"\"))\n",
    "            \n",
    "            # sizes를 리스트로 파싱\n",
    "            sizes_list = parse_sizes(str(row.get(\"sizes\", \"\")))\n",
    "\n",
    "            meta: Dict[str, Any] = {\n",
    "                \"no\": int(row.get(\"no\", 0)) if pd.notna(row.get(\"no\")) else 0,\n",
    "                \"brand\": brand,\n",
    "                \"name\": name,\n",
    "                \"concentration\": _norm(row.get(\"concentration\", \"\")),\n",
    "                \"gender\": _norm(row.get(\"gender\", \"\")),\n",
    "                \"sizes\": sizes_list,  # 리스트 형태로 저장\n",
    "            }\n",
    "            \n",
    "            # 최고 점수 항목 추가\n",
    "            if season_top:   \n",
    "                meta[\"season_score\"] = season_top\n",
    "            if daynight_top: \n",
    "                meta[\"day_night_score\"] = daynight_top\n",
    "\n",
    "            # ID 생성\n",
    "            stable_id = make_stable_id(brand, name)\n",
    "            meta[\"id\"] = stable_id\n",
    "\n",
    "            docs.append(Document(page_content=description, metadata=meta))\n",
    "\n",
    "        print(f\"✅ Document {len(docs)}개 생성 완료\")\n",
    "        return docs\n",
    "\n",
    "    def show_sample_documents(self, documents: List[Document], n: int = 3) -> None:\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"📋 Document 샘플\")\n",
    "        print(\"=\" * 80)\n",
    "        for i in range(min(n, len(documents))):\n",
    "            d = documents[i]\n",
    "            print(f\"\\n[{i+1}] ID: {d.metadata['id']}\")\n",
    "            print(f\"page_content: {d.page_content}\")\n",
    "            print(f\"metadata: {d.metadata}\")\n",
    "            print(\"-\" * 60)\n",
    "        print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 배치 임베딩\n",
    "    # -------------------------------------\n",
    "    def embed_batch(self, texts: List[str]) -> List[List[float]]:\n",
    "        resp = self.openai.embeddings.create(model=self.embedding_model, input=texts)\n",
    "        return [item.embedding for item in resp.data]\n",
    "\n",
    "    def documents_to_vectors_batched(self, docs: List[Document]) -> List[Dict]:\n",
    "        vectors: List[Dict] = []\n",
    "        print(f\"🔄 임베딩(배치) 생성: batch={self.embed_batch_size}\")\n",
    "        for i in tqdm(range(0, len(docs), self.embed_batch_size), desc=\"🧮 임베딩 배치\"):\n",
    "            batch_docs = docs[i : i + self.embed_batch_size]\n",
    "            texts = [d.page_content for d in batch_docs]\n",
    "            try:\n",
    "                embs = self.embed_batch(texts)\n",
    "                for d, emb in zip(batch_docs, embs):\n",
    "                    meta = dict(d.metadata)\n",
    "                    meta[\"text\"] = d.page_content  # page_content를 text로 저장\n",
    "                    vectors.append({\"id\": meta[\"id\"], \"values\": emb, \"metadata\": meta})\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ 임베딩 배치 실패 (i={i}): {e}\")\n",
    "                continue\n",
    "        print(f\"✅ 벡터 {len(vectors)}개 생성 완료\")\n",
    "        return vectors\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 업서트(배치)\n",
    "    # -------------------------------------\n",
    "    def upsert_vectors_batched(self, vectors: List[Dict]) -> Tuple[int, int]:\n",
    "        if not vectors:\n",
    "            return 0, 0\n",
    "        index = self.pc.Index(self.index_name)\n",
    "        ok, ng = 0, 0\n",
    "        calls = 0\n",
    "        print(f\"📤 업서트(배치): batch={self.upsert_batch_size}\")\n",
    "        for i in tqdm(range(0, len(vectors), self.upsert_batch_size), desc=\"📦 업서트(batched)\"):\n",
    "            batch = vectors[i : i + self.upsert_batch_size]\n",
    "            try:\n",
    "                res = index.upsert(vectors=batch, namespace=self.namespace)\n",
    "                calls += 1\n",
    "                if hasattr(res, \"upserted_count\") and isinstance(res.upserted_count, int):\n",
    "                    ok += res.upserted_count\n",
    "                else:\n",
    "                    ok += len(batch)\n",
    "            except Exception as e:\n",
    "                ng += len(batch)\n",
    "                print(f\"⚠️ 업서트 실패 (i={i}): {e}\")\n",
    "                continue\n",
    "            print(f\"   ↳ call#{calls} batch_size={len(batch)} (누적 성공={ok}, 실패={ng})\")\n",
    "            time.sleep(0.15)\n",
    "        print(f\"📞 업서트 호출수: {calls}\")\n",
    "        return ok, ng\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 실행\n",
    "    # -------------------------------------\n",
    "    def run(self, csv_path: str) -> None:\n",
    "        print(\"🚀 Perfume 벡터 업로드 시작!\\n\")\n",
    "\n",
    "        # (1) 인덱스 재생성: 존재하면 삭제 → 새로 생성\n",
    "        self.recreate_index()\n",
    "\n",
    "        # (2) CSV→Documents\n",
    "        docs = self.csv_to_documents(csv_path)\n",
    "        if not docs:\n",
    "            print(\"❌ 변환할 문서가 없습니다.\")\n",
    "            return\n",
    "        self.show_sample_documents(docs)\n",
    "\n",
    "        # (3) Documents→Vectors (배치 임베딩)\n",
    "        vectors = self.documents_to_vectors_batched(docs)\n",
    "        if not vectors:\n",
    "            print(\"❌ 생성할 벡터가 없습니다.\")\n",
    "            return\n",
    "\n",
    "        # (4) Upsert (배치)\n",
    "        ok, ng = self.upsert_vectors_batched(vectors)\n",
    "        print(f\"✅ 업서트 완료 | 성공: {ok}  실패: {ng}\")\n",
    "\n",
    "        # (5) 최종 통계\n",
    "        try:\n",
    "            idx = self.pc.Index(self.index_name)\n",
    "            stats = idx.describe_index_stats()\n",
    "            after = stats.get(\"total_vector_count\", 0)\n",
    "            print(f\"\\n📊 최종 벡터 수: {after}\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ 최종 통계 조회 실패: {e}\")\n",
    "\n",
    "        print(\"🎉 완료!\")\n",
    "\n",
    "# =========================================\n",
    "# 메인\n",
    "# =========================================\n",
    "def main():\n",
    "    csv_file = \"perfume_final_vector.csv\"\n",
    "    try:\n",
    "        app = PerfumeVectorUploader()\n",
    "        app.run(csv_file)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 오류 발생: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
