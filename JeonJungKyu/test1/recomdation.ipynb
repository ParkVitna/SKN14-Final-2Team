{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a03d90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Playdata2\\miniconda3\\envs\\final-env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Device] cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Playdata2\\miniconda3\\envs\\final-env\\Lib\\pickle.py:1760: UserWarning: [10:40:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\gbm\\gbtree.cc:359: \n",
      "  Loading from a raw memory buffer (like pickle in Python, RDS in R) on a CPU-only\n",
      "  machine. Consider using `save_model/load_model` instead. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.  Changing `tree_method` to `hist`.\n",
      "  setstate(state)\n",
      "c:\\Users\\Playdata2\\miniconda3\\envs\\final-env\\Lib\\pickle.py:1760: UserWarning: [10:40:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\gbm\\gbtree.cc:384: Changing updater from `grow_gpu_hist` to `grow_quantile_histmaker`.\n",
      "  setstate(state)\n",
      "c:\\Users\\Playdata2\\miniconda3\\envs\\final-env\\Lib\\pickle.py:1760: UserWarning: [10:40:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  setstate(state)\n",
      "c:\\Users\\Playdata2\\miniconda3\\envs\\final-env\\Lib\\pickle.py:1760: UserWarning: [10:40:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  setstate(state)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Loaded model from ./models.pkl]\n",
      "Labels: ['Amber', 'Aromatic', 'Blossom', 'Bouquet', 'Citrus', 'Classical', 'Crisp', 'Dry', 'Floral', 'Flower', 'Fougère', 'Fresh', 'Fresher', 'Fruity', 'Gourmand', 'Green', 'Iris', 'Jasmine', 'Lily', 'Mossy', 'Musk', 'Orange', 'Rich', 'Richer', 'Rose', 'Soft', 'Spicy', 'Tuberose', 'Valley', 'Violet', 'Water', 'White', 'Woods', 'Woody']\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 저장된 VotingClassifier (.pkl) 불러오기 + 예측\n",
    "# ============================================\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# -------------------------------\n",
    "# 설정\n",
    "# -------------------------------\n",
    "MODEL_NAME = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "MAX_LEN = 256\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"[Device] {device}\")\n",
    "\n",
    "# -------------------------------\n",
    "# 1) 저장된 pkl 불러오기\n",
    "# -------------------------------\n",
    "SAVE_PKL = \"./models.pkl\"\n",
    "data = joblib.load(SAVE_PKL)\n",
    "\n",
    "clf = data[\"classifier\"]\n",
    "mlb = data[\"mlb\"]\n",
    "thresholds = data[\"thresholds\"]\n",
    "\n",
    "print(f\"[Loaded model from {SAVE_PKL}]\")\n",
    "print(f\"Labels: {list(mlb.classes_)}\")\n",
    "\n",
    "# -------------------------------\n",
    "# 2) MiniLM 로드 (임베딩 추출용)\n",
    "# -------------------------------\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "base_model = AutoModel.from_pretrained(MODEL_NAME).to(device)\n",
    "base_model.eval()\n",
    "\n",
    "def encode_texts(texts, batch_size=32):\n",
    "    \"\"\"텍스트를 MiniLM 임베딩으로 변환\"\"\"\n",
    "    all_embeddings = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        enc = tokenizer(batch, padding=True, truncation=True, max_length=MAX_LEN, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            model_out = base_model(**enc)\n",
    "            emb = model_out.last_hidden_state.mean(dim=1)\n",
    "        all_embeddings.append(emb.cpu().numpy())\n",
    "    return np.vstack(all_embeddings)\n",
    "\n",
    "# -------------------------------\n",
    "# 3) 예측 함수\n",
    "# -------------------------------\n",
    "def predict_multilingual(text: str, topk=3, thresholds=None):\n",
    "    emb = encode_texts([text], batch_size=1)\n",
    "    proba = clf.predict_proba(emb)[0]\n",
    "\n",
    "    if thresholds is not None:\n",
    "        pick = [i for i, p in enumerate(proba) if p >= thresholds.get(mlb.classes_[i], 0.5)]\n",
    "        if not pick:  # 어떤 것도 threshold 못 넘으면 topk 선택\n",
    "            pick = np.argsort(-proba)[:topk]\n",
    "    else:\n",
    "        pick = np.argsort(-proba)[:topk]\n",
    "\n",
    "    return [mlb.classes_[i] for i in pick]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "849a123a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Example Prediction]\n",
      "['Amber', 'Floral', 'Fresher', 'Fruity']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -------------------------------\n",
    "# 4) 예측 실행\n",
    "# -------------------------------\n",
    "example_text = \"여자친구 달달한향좋아하는데 추천좀\"\n",
    "print(\"\\n[Example Prediction]\")\n",
    "print(predict_multilingual(example_text, topk=3, thresholds=thresholds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
