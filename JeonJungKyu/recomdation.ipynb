{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a03d90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Device] cpu\n",
      "향수 메인 어코드 추출 시스템 테스트\n",
      "============================================================\n",
      "Model Path: ./model.pkl\n",
      "HF Model: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n",
      "Device: cpu\n",
      "Max Length: 256\n",
      "Batch Size: 16\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'inspect_model_bundle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 486\u001b[39m\n\u001b[32m    484\u001b[39m     interactive_test()\n\u001b[32m    485\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m486\u001b[39m     \u001b[43mrun_tests\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 311\u001b[39m, in \u001b[36mrun_tests\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    308\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"테스트 실행 함수\"\"\"\u001b[39;00m\n\u001b[32m    310\u001b[39m \u001b[38;5;66;03m# 먼저 모델 구조 분석\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m311\u001b[39m \u001b[43minspect_model_bundle\u001b[49m(MODEL_PKL)\n\u001b[32m    313\u001b[39m \u001b[38;5;66;03m# 향수 관련 테스트 쿼리들 (메인 어코드 추출용)\u001b[39;00m\n\u001b[32m    314\u001b[39m test_queries = [\n\u001b[32m    315\u001b[39m     \u001b[38;5;66;03m# 계절별 향수 추천\u001b[39;00m\n\u001b[32m    316\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m여름에 뿌릴만한 향수 추천해주세요\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    351\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m허브향이 들어간 자연스러운 향수 추천\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    352\u001b[39m ]\n",
      "\u001b[31mNameError\u001b[39m: name 'inspect_model_bundle' is not defined"
     ]
    }
   ],
   "source": [
    "def create_manual_labels():\n",
    "    \"\"\"수동으로 향수 어코드 라벨을 생성하는 함수 (참고용)\"\"\"\n",
    "    \n",
    "    # 일반적인 향수 어코드들 (45개 클래스 예시)\n",
    "    fragrance_accords = [\n",
    "        \"Citrus\", \"Fresh\", \"Aquatic\", \"Green\", \"Herbal\",           # 0-4: 상쾌한 계열\n",
    "        \"Floral\", \"Rose\", \"Jasmine\", \"Lily\", \"Peony\",             # 5-9: 플로럴 계열  \n",
    "        \"Fruity\", \"Apple\", \"Pear\", \"Peach\", \"Berry\",              # 10-14: 과일 계열\n",
    "        \"Spicy\", \"Pepper\", \"Cinnamon\", \"Ginger\", \"Cardamom\",      # 15-19: 스파이시 계열\n",
    "        \"Woody\", \"Sandalwood\", \"Cedar\", \"Pine\", \"Vetiver\",        # 20-24: 우디 계열\n",
    "        \"Oriental\", \"Amber\", \"Incense\", \"Oud\", \"Patchouli\",       # 25-29: 오리엔탈 계열\n",
    "        \"Gourmand\", \"Vanilla\", \"Caramel\", \"Chocolate\", \"Coffee\",  # 30-34: 구르망 계열\n",
    "        \"Musk\", \"Animalic\", \"Leather\", \"Tobacco\", \"Smoky\",        # 35-39: 깊은 계열\n",
    "        \"Powdery\", \"Clean\", \"Soap\", \"Marine\", \"Ozonic\"            # 40-44: 파우더리/클린 계열\n",
    "    ]\n",
    "    \n",
    "    return fragrance_accords[:45]  # 정확히 45개로 맞춤def inspect_model_bundle(pkl_path: str):\n",
    "    \"\"\"모델 번들 구조를 자세히 분석하는 함수\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"모델 번들 구조 분석\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    try:\n",
    "        obj = joblib.load(pkl_path)\n",
    "        print(f\"메인 객체 타입: {type(obj)}\")\n",
    "        \n",
    "        if isinstance(obj, dict):\n",
    "            print(f\"딕셔너리 키 개수: {len(obj)}\")\n",
    "            for key, value in obj.items():\n",
    "                print(f\"  '{key}': {type(value)}\")\n",
    "                \n",
    "                # 라벨 관련 속성 확인\n",
    "                if hasattr(value, 'classes_'):\n",
    "                    print(f\"    └─ classes_: {len(value.classes_)}개 ({type(value.classes_[0]) if len(value.classes_) > 0 else 'empty'})\")\n",
    "                    if len(value.classes_) > 0:\n",
    "                        print(f\"       샘플: {list(value.classes_[:3])}...\")\n",
    "                \n",
    "                # 배열/리스트인 경우 내용 확인\n",
    "                if isinstance(value, (list, tuple, np.ndarray)):\n",
    "                    print(f\"    └─ 길이: {len(value)}\")\n",
    "                    if len(value) > 0:\n",
    "                        print(f\"       타입: {type(value[0])}\")\n",
    "                        if isinstance(value[0], str):\n",
    "                            print(f\"       샘플: {list(value[:3])}...\")\n",
    "        \n",
    "        else:\n",
    "            print(\"단일 객체 (비딕셔너리)\")\n",
    "            if hasattr(obj, 'classes_'):\n",
    "                print(f\"  classes_: {len(obj.classes_)}개\")\n",
    "                print(f\"  샘플: {list(obj.classes_[:3])}...\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"분석 실패: {e}\")\n",
    "    \n",
    "    print(\"=\"*60)# ============================================\n",
    "# model.pkl 번들 로드 + MiniLM 임베딩 + 예측\n",
    "# (joblib.load, 마스킹 평균풀링, 라벨/임계값 정렬 포함)\n",
    "# ============================================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import joblib\n",
    "import torch\n",
    "from typing import Any, Dict, List, Tuple\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# --------- 설정 ----------\n",
    "MODEL_PKL = os.getenv(\"MODEL_PKL\", \"./model.pkl\")  # 번들 경로\n",
    "HF_MODEL  = os.getenv(\"HF_MODEL\", \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "MAX_LEN   = int(os.getenv(\"MAX_LEN\", 256))\n",
    "DEVICE    = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SZ  = int(os.getenv(\"BATCH_SZ\", 16))\n",
    "print(f\"[Device] {DEVICE}\")\n",
    "\n",
    "# --------- 1) 번들 로드 (수정본) ----------\n",
    "def load_bundle(pkl_path: str) -> Dict[str, Any]:\n",
    "    print(f\"[DEBUG] 번들 파일 로딩 중: {pkl_path}\")\n",
    "    obj = joblib.load(pkl_path)  # ✅ joblib.load로 읽어야 함\n",
    "    \n",
    "    # 번들 구조 디버깅\n",
    "    print(f\"[DEBUG] 로드된 객체 타입: {type(obj)}\")\n",
    "    if isinstance(obj, dict):\n",
    "        print(f\"[DEBUG] 딕셔너리 키들: {list(obj.keys())}\")\n",
    "        bundle = obj\n",
    "    else:\n",
    "        print(f\"[DEBUG] 딕셔너리가 아님. 분류기로 가정\")\n",
    "        bundle = {\"classifier\": obj}\n",
    "\n",
    "    # 분류기 찾기\n",
    "    clf = bundle.get(\"classifier\") or bundle.get(\"model\") or bundle.get(\"clf\")\n",
    "    if clf is None:\n",
    "        # 가능한 모든 키 확인\n",
    "        for key, value in bundle.items():\n",
    "            if hasattr(value, \"predict_proba\"):\n",
    "                print(f\"[DEBUG] '{key}'에서 predict_proba 발견\")\n",
    "                clf = value\n",
    "                break\n",
    "    \n",
    "    if clf is None or not hasattr(clf, \"predict_proba\"):\n",
    "        raise ValueError(\"bundle에 predict_proba 가능한 분류기가 필요합니다.\")\n",
    "\n",
    "    print(f\"[DEBUG] 분류기 타입: {type(clf)}\")\n",
    "    \n",
    "    # MultiLabelBinarizer 찾기\n",
    "    mlb = bundle.get(\"mlb\") or bundle.get(\"multilabel_binarizer\") or bundle.get(\"label_binarizer\")\n",
    "    if mlb is None:\n",
    "        for key, value in bundle.items():\n",
    "            if hasattr(value, \"classes_\") and hasattr(value, \"transform\"):\n",
    "                print(f\"[DEBUG] '{key}'에서 MultiLabelBinarizer 발견\")\n",
    "                mlb = value\n",
    "                break\n",
    "    \n",
    "    if mlb:\n",
    "        print(f\"[DEBUG] MLB 타입: {type(mlb)}, classes 개수: {len(mlb.classes_) if hasattr(mlb, 'classes_') else 'None'}\")\n",
    "    \n",
    "    # 라벨 찾기 (여러 방법 시도)\n",
    "    labels = None\n",
    "    \n",
    "    # 1. 직접 저장된 labels\n",
    "    labels = bundle.get(\"labels\") or bundle.get(\"label_names\") or bundle.get(\"classes\") or bundle.get(\"class_names\")\n",
    "    \n",
    "    # 2. MLB에서 복원\n",
    "    if labels is None and mlb is not None and hasattr(mlb, \"classes_\"):\n",
    "        labels = list(mlb.classes_)\n",
    "        print(f\"[DEBUG] MLB에서 라벨 복원: {len(labels)}개\")\n",
    "        print(f\"[DEBUG] 라벨 샘플: {labels[:5] if len(labels) > 5 else labels}\")\n",
    "    \n",
    "    # 3. 분류기에서 복원\n",
    "    if labels is None and hasattr(clf, \"classes_\"):\n",
    "        labels = list(clf.classes_)\n",
    "        print(f\"[DEBUG] 분류기에서 라벨 복원: {len(labels)}개\")\n",
    "    \n",
    "    # 4. 번들의 모든 키에서 라벨 찾기\n",
    "    if labels is None:\n",
    "        for key, value in bundle.items():\n",
    "            if isinstance(value, (list, tuple, np.ndarray)) and len(value) > 0:\n",
    "                if isinstance(value[0], str):  # 문자열 배열이면 라벨일 가능성\n",
    "                    print(f\"[DEBUG] '{key}'에서 문자열 배열 발견: {len(value)}개\")\n",
    "                    labels = list(value)\n",
    "                    break\n",
    "    \n",
    "    thresholds = bundle.get(\"thresholds\", 0.5)\n",
    "    print(f\"[DEBUG] 임계값 타입: {type(thresholds)}\")\n",
    "\n",
    "    # 라벨 정렬/검증\n",
    "    if hasattr(clf, \"classes_\") and labels is not None:\n",
    "        clf_labels = list(clf.classes_)\n",
    "        if list(labels) != clf_labels:\n",
    "            print(f\"[DEBUG] 라벨 순서 불일치. 분류기 순서로 재정렬\")\n",
    "            idx_map = {lbl: i for i, lbl in enumerate(labels)}\n",
    "            labels = [lbl for lbl in clf_labels if lbl in idx_map]\n",
    "\n",
    "        # thresholds가 dict라면 clf 순서에 맞춰 배열로 변환\n",
    "        if isinstance(thresholds, dict):\n",
    "            thresholds = np.array([float(thresholds.get(lbl, 0.5)) for lbl in labels], dtype=float)\n",
    "\n",
    "    print(f\"[DEBUG] 최종 라벨 개수: {len(labels) if labels else 0}\")\n",
    "    return {\"classifier\": clf, \"mlb\": mlb, \"labels\": labels, \"thresholds\": thresholds}\n",
    "\n",
    "# --------- 2) 임베더 로드 ----------\n",
    "def load_embedder():\n",
    "    tokenizer = AutoTokenizer.from_pretrained(HF_MODEL)\n",
    "    base_model = AutoModel.from_pretrained(HF_MODEL).to(DEVICE).eval()\n",
    "    return tokenizer, base_model\n",
    "\n",
    "@torch.inference_mode()\n",
    "def encode_texts(texts: List[str], tokenizer, base_model, max_len: int = MAX_LEN, batch_size: int = BATCH_SZ) -> np.ndarray:\n",
    "    out = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        enc = tokenizer(\n",
    "            batch, padding=True, truncation=True, max_length=max_len, return_tensors=\"pt\"\n",
    "        ).to(DEVICE)\n",
    "\n",
    "        last = base_model(**enc).last_hidden_state        # (B, L, H)\n",
    "        mask = enc[\"attention_mask\"].unsqueeze(-1)        # (B, L, 1)\n",
    "        summed = (last * mask).sum(dim=1)                 \n",
    "        counts = mask.sum(dim=1).clamp(min=1)             \n",
    "        emb = summed / counts                             \n",
    "        out.append(emb.detach().cpu().numpy())\n",
    "    return np.vstack(out)\n",
    "\n",
    "# --------- 3) 확률 표준화 ----------\n",
    "def _standardize_proba(proba) -> np.ndarray:\n",
    "    if isinstance(proba, list):\n",
    "        cols = []\n",
    "        for p in proba:\n",
    "            p = np.asarray(p)\n",
    "            if p.ndim == 2 and p.shape[1] > 1:\n",
    "                cols.append(p[:, 1])\n",
    "            else:\n",
    "                cols.append(p.ravel())\n",
    "        proba = np.column_stack(cols)\n",
    "    proba = np.asarray(proba)\n",
    "    if proba.ndim == 1:\n",
    "        proba = proba.reshape(1, -1)\n",
    "    return proba\n",
    "\n",
    "# --------- 4) 임계값 적용 (수정본) ----------\n",
    "def apply_thresholds(p: np.ndarray, labels: List[str], thresholds) -> List[Tuple[str, float]]:\n",
    "    n = len(p)\n",
    "    \n",
    "    # labels 검증 및 처리\n",
    "    if labels is None or len(labels) == 0:\n",
    "        print(f\"[WARN] labels가 없음. 인덱스 번호를 사용합니다 (len(p)={n})\")\n",
    "        labels = [f\"class_{i}\" for i in range(n)]\n",
    "    elif len(labels) != n:\n",
    "        print(f\"[WARN] len(p)={n}, len(labels)={len(labels)} → 길이 맞춤\")\n",
    "        if len(labels) < n:\n",
    "            # labels가 부족하면 인덱스로 채움\n",
    "            labels = list(labels) + [f\"class_{i}\" for i in range(len(labels), n)]\n",
    "        else:\n",
    "            # labels가 너무 많으면 자름\n",
    "            labels = labels[:n]\n",
    "\n",
    "    # thresholds 처리\n",
    "    if isinstance(thresholds, dict) and labels is not None:\n",
    "        thr_arr = np.array([float(thresholds.get(lbl, 0.5)) for lbl in labels], dtype=float)\n",
    "    elif hasattr(thresholds, \"__len__\") and not isinstance(thresholds, (str, bytes)):\n",
    "        thr_arr = np.array(thresholds, dtype=float)\n",
    "        if len(thr_arr) != n:\n",
    "            thr_arr = np.full(n, float(np.median(thresholds) if len(thresholds) else 0.5), dtype=float)\n",
    "    else:\n",
    "        thr_arr = np.full(n, float(thresholds), dtype=float)\n",
    "\n",
    "    # 임계값 적용\n",
    "    idx = np.where(p >= thr_arr)[0]\n",
    "    \n",
    "    # 안전한 인덱스 접근\n",
    "    names = []\n",
    "    vals = []\n",
    "    for i in idx:\n",
    "        if i < len(labels):\n",
    "            names.append(labels[i])\n",
    "            vals.append(float(p[i]))\n",
    "    \n",
    "    return sorted(list(zip(names, vals)), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# --------- 5) 예측 클래스 ----------\n",
    "class TextClassifier:\n",
    "    def __init__(self, model_path: str):\n",
    "        print(f\"[Loading] Model bundle from: {model_path}\")\n",
    "        self.bundle = load_bundle(model_path)\n",
    "        self.clf = self.bundle[\"classifier\"]\n",
    "        self.labels = self.bundle[\"labels\"]\n",
    "        self.thresholds = self.bundle[\"thresholds\"]\n",
    "        \n",
    "        print(f\"[Loading] Embedder: {HF_MODEL}\")\n",
    "        self.tokenizer, self.base_model = load_embedder()\n",
    "        \n",
    "        print(f\"[Loaded] Labels: {len(self.labels) if self.labels else 0}\")\n",
    "        if self.labels and len(self.labels) > 0:\n",
    "            print(f\"[Loaded] Sample labels: {self.labels[:5]}{'...' if len(self.labels) > 5 else ''}\")\n",
    "        else:\n",
    "            print(f\"[WARN] labels가 없음 - 런타임에 class_0, class_1... 형태로 생성됨\")\n",
    "        print(f\"[Loaded] Thresholds type: {type(self.thresholds).__name__}\")\n",
    "\n",
    "    def predict_labels(self, texts: List[str], topk: int = 3) -> List[Dict[str, Any]]:\n",
    "        vec = encode_texts(texts, self.tokenizer, self.base_model)\n",
    "        proba = _standardize_proba(self.clf.predict_proba(vec))\n",
    "        results = []\n",
    "        \n",
    "        for i, t in enumerate(texts):\n",
    "            p = proba[i]\n",
    "            n_classes = len(p)\n",
    "            \n",
    "            # labels 안전성 검사\n",
    "            if self.labels is None or len(self.labels) == 0:\n",
    "                current_labels = [f\"class_{j}\" for j in range(n_classes)]\n",
    "                print(f\"[INFO] labels 없음 → class_0, class_1, ... 사용\")\n",
    "            elif len(self.labels) != n_classes:\n",
    "                current_labels = list(self.labels) + [f\"class_{j}\" for j in range(len(self.labels), n_classes)]\n",
    "                if len(current_labels) > n_classes:\n",
    "                    current_labels = current_labels[:n_classes]\n",
    "            else:\n",
    "                current_labels = self.labels\n",
    "            \n",
    "            # TopK 계산\n",
    "            idx_sorted = np.argsort(p)[::-1][:topk]\n",
    "            top_pairs = [(current_labels[j], float(p[j])) for j in idx_sorted if j < len(current_labels)]\n",
    "            \n",
    "            # 임계값 적용\n",
    "            passed = apply_thresholds(p, current_labels, self.thresholds)\n",
    "            \n",
    "            results.append({\n",
    "                \"text\": t,\n",
    "                \"topk\": top_pairs,\n",
    "                \"passed_threshold\": passed,\n",
    "                \"all_probs\": p,\n",
    "            })\n",
    "        return results\n",
    "\n",
    "    def predict_one(self, text: str, topk: int = 5) -> Dict[str, Any]:\n",
    "        out = self.predict_labels([text], topk=topk)[0]\n",
    "        print(f\"\\n[Query] {out['text']}\")\n",
    "        print(f\" - TopK : {', '.join(f'{n}({s:.3f})' for n, s in out['topk'])}\")\n",
    "        if out[\"passed_threshold\"]:\n",
    "            print(f\" - Pass : {', '.join(f'{n}({s:.3f})' for n, s in out['passed_threshold'])}\")\n",
    "        else:\n",
    "            print(\" - Pass : (임계값 통과 없음 → TopK 참고)\")\n",
    "        return out\n",
    "\n",
    "# ============================================\n",
    "# 테스트 코드\n",
    "# ============================================\n",
    "\n",
    "def run_tests():\n",
    "    \"\"\"테스트 실행 함수\"\"\"\n",
    "    \n",
    "    # 먼저 모델 구조 분석\n",
    "    inspect_model_bundle(MODEL_PKL)\n",
    "    \n",
    "    # 향수 관련 테스트 쿼리들 (메인 어코드 추출용)\n",
    "    test_queries = [\n",
    "        # 계절별 향수 추천\n",
    "        \"여름에 뿌릴만한 향수 추천해주세요\",\n",
    "        \"겨울에 어울리는 따뜻한 향수가 뭐가 있을까요?\",\n",
    "        \"봄에 어울리는 플로럴 향수 추천해주세요\",\n",
    "        \"가을에 뿌리기 좋은 우디한 향수는?\",\n",
    "        \n",
    "        # 상황별 향수 추천\n",
    "        \"데이트할 때 뿌리면 좋은 향수 추천\",\n",
    "        \"직장에서 뿌려도 되는 은은한 향수는?\",\n",
    "        \"파티나 클럽에 어울리는 섹시한 향수 추천\",\n",
    "        \"운동할 때 뿌려도 좋은 상쾌한 향수는?\",\n",
    "        \n",
    "        # 성별/연령별 추천\n",
    "        \"20대 여성에게 어울리는 향수 추천해주세요\",\n",
    "        \"30대 남성이 쓰기 좋은 향수는?\",\n",
    "        \"10대가 쓰기에 부담없는 향수 추천\",\n",
    "        \"50대 여성에게 어울리는 우아한 향수는?\",\n",
    "        \n",
    "        # 향조/어코드별 문의\n",
    "        \"시트러스 계열의 상큼한 향수 추천\",\n",
    "        \"바닐라 향이 강한 달콤한 향수는?\",\n",
    "        \"머스크 향이 들어간 향수 추천해주세요\",\n",
    "        \"우디 계열의 중후한 향수가 뭐가 있나요?\",\n",
    "        \"플로럴 부케 향수 중에 추천해주세요\",\n",
    "        \n",
    "        # 브랜드/가격대별\n",
    "        \"샤넬 향수 중에 인기있는거 추천\",\n",
    "        \"10만원 이하로 살 수 있는 좋은 향수는?\",\n",
    "        \"디올 향수 중에 여름용으로 좋은건?\",\n",
    "        \"학생도 살 수 있는 저렴한 향수 추천\",\n",
    "        \n",
    "        # 특정 향 선호도\n",
    "        \"장미향이 나는 향수 추천해주세요\",\n",
    "        \"오션 냄새가 나는 시원한 향수는?\",\n",
    "        \"과일향이 강한 프루티한 향수 추천\",\n",
    "        \"커피나 초콜릿 향이 나는 향수는?\",\n",
    "        \"허브향이 들어간 자연스러운 향수 추천\"\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        # 분류기 초기화\n",
    "        print(f\"\\n모델 로딩을 시도합니다...\")\n",
    "        classifier = TextClassifier(MODEL_PKL)\n",
    "        \n",
    "        # 라벨이 없으면 수동으로 생성 제안\n",
    "        if not classifier.labels or len(classifier.labels) == 0:\n",
    "            print(f\"\\n💡 라벨이 없으므로 향수 어코드를 수동으로 매핑할 수 있습니다.\")\n",
    "            manual_labels = create_manual_labels()\n",
    "            \n",
    "            response = input(f\"수동 향수 어코드 라벨을 사용하시겠습니까? (y/n): \").strip().lower()\n",
    "            if response in ['y', 'yes', '네', 'ㅇ']:\n",
    "                classifier.labels = manual_labels\n",
    "                print(f\"✅ 향수 어코드 라벨 {len(manual_labels)}개를 적용했습니다.\")\n",
    "                print(f\"샘플: {manual_labels[:5]}...\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"향수 메인 어코드 추출 테스트 (predict_one)\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # 개별 테스트 (상위 3개)\n",
    "        for i, query in enumerate(test_queries[:5]):  # 처음 5개만\n",
    "            print(f\"\\n[Test {i+1}]\")\n",
    "            result = classifier.predict_one(query, topk=3)\n",
    "            \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"배치 향수 어코드 추출 테스트\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # 배치 테스트\n",
    "        batch_results = classifier.predict_labels(test_queries[:8], topk=3)\n",
    "        \n",
    "        for i, result in enumerate(batch_results):\n",
    "            print(f\"\\n[Batch {i+1}] {result['text'][:50]}...\")\n",
    "            print(f\"  Top3: {', '.join(f'{n}({s:.3f})' for n, s in result['topk'])}\")\n",
    "            if result['passed_threshold']:\n",
    "                print(f\"  Pass: {', '.join(f'{n}({s:.3f})' for n, s in result['passed_threshold'])}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"메인 어코드 추출 통계\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # 임계값 통과 통계\n",
    "        total_tests = len(batch_results)\n",
    "        passed_tests = sum(1 for r in batch_results if r['passed_threshold'])\n",
    "        \n",
    "        print(f\"전체 테스트: {total_tests}\")\n",
    "        print(f\"임계값 통과: {passed_tests}\")\n",
    "        print(f\"어코드 추출율: {passed_tests/total_tests*100:.1f}%\")\n",
    "        \n",
    "        # 어코드별 통계\n",
    "        accord_counts = {}\n",
    "        for result in batch_results:\n",
    "            for accord, score in result['passed_threshold']:\n",
    "                accord_counts[accord] = accord_counts.get(accord, 0) + 1\n",
    "        \n",
    "        if accord_counts:\n",
    "            print(\"\\n메인 어코드별 등장 횟수:\")\n",
    "            for accord, count in sorted(accord_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "                print(f\"  {accord}: {count}회\")\n",
    "        \n",
    "        print(\"\\n테스트 완료!\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"[ERROR] 모델 파일을 찾을 수 없습니다: {MODEL_PKL}\")\n",
    "        print(\"다음 중 하나를 확인해주세요:\")\n",
    "        print(\"1. model.pkl 파일이 현재 디렉토리에 있는지 확인\")\n",
    "        print(\"2. MODEL_PKL 환경변수로 올바른 경로 설정\")\n",
    "        print(\"3. 예시: export MODEL_PKL='/path/to/your/model.pkl'\")\n",
    "        \n",
    "    except ValueError as e:\n",
    "        print(f\"[ERROR] 모델 로딩 오류: {str(e)}\")\n",
    "        print(\"model.pkl 파일의 구조를 확인해주세요.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] 예상치 못한 오류가 발생했습니다: {str(e)}\")\n",
    "        print(f\"오류 타입: {type(e).__name__}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "def interactive_test():\n",
    "    \"\"\"대화형 테스트 함수\"\"\"\n",
    "    try:\n",
    "        classifier = TextClassifier(MODEL_PKL)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"향수 메인 어코드 추출 - 대화형 모드\")\n",
    "        print(\"=\"*60)\n",
    "        print(\"향수 관련 질문을 입력하면 메인 어코드 3개를 추출합니다.\")\n",
    "        print(\"예시: '여름에 뿌릴만한 향수 추천', '데이트용 향수 추천' 등\")\n",
    "        print(\"종료하려면 'quit' 또는 'exit'를 입력하세요.\")\n",
    "        \n",
    "        while True:\n",
    "            query = input(\"\\n향수 질문 입력: \").strip()\n",
    "            if query.lower() in ['quit', 'exit', '종료']:\n",
    "                break\n",
    "            if not query:\n",
    "                continue\n",
    "                \n",
    "            result = classifier.predict_one(query, topk=3)  # 메인 어코드 3개\n",
    "            \n",
    "            # 추가 정보 표시\n",
    "            if result[\"passed_threshold\"]:\n",
    "                print(f\"\\n✅ 추출된 메인 어코드: {len(result['passed_threshold'])}개\")\n",
    "            else:\n",
    "                print(f\"\\n⚠️  임계값을 넘는 어코드가 없어 상위 3개를 참고하세요\")\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\n프로그램을 종료합니다.\")\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] {str(e)}\")\n",
    "\n",
    "# ============================================\n",
    "# 메인 실행부\n",
    "# ============================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"향수 메인 어코드 추출 시스템 테스트\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 환경 정보 출력\n",
    "    print(f\"Model Path: {MODEL_PKL}\")\n",
    "    print(f\"HF Model: {HF_MODEL}\")\n",
    "    print(f\"Device: {DEVICE}\")\n",
    "    print(f\"Max Length: {MAX_LEN}\")\n",
    "    print(f\"Batch Size: {BATCH_SZ}\")\n",
    "    \n",
    "    # 테스트 선택\n",
    "    import sys\n",
    "    if len(sys.argv) > 1 and sys.argv[1] == \"interactive\":\n",
    "        interactive_test()\n",
    "    else:\n",
    "        run_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23cb9f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Device] cpu\n",
      "향수 메인 어코드 추출 시스템 테스트\n",
      "============================================================\n",
      "Model Path: ./model.pkl\n",
      "HF Model: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n",
      "Device: cpu\n",
      "Max Length: 256\n",
      "Batch Size: 16\n",
      "\n",
      "============================================================\n",
      "모델 번들 구조 분석\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Playdata2\\miniconda3\\envs\\final-env\\Lib\\pickle.py:1760: UserWarning: [15:07:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\gbm\\gbtree.cc:359: \n",
      "  Loading from a raw memory buffer (like pickle in Python, RDS in R) on a CPU-only\n",
      "  machine. Consider using `save_model/load_model` instead. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.  Changing `tree_method` to `hist`.\n",
      "  setstate(state)\n",
      "c:\\Users\\Playdata2\\miniconda3\\envs\\final-env\\Lib\\pickle.py:1760: UserWarning: [15:07:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\gbm\\gbtree.cc:384: Changing updater from `grow_gpu_hist` to `grow_quantile_histmaker`.\n",
      "  setstate(state)\n",
      "c:\\Users\\Playdata2\\miniconda3\\envs\\final-env\\Lib\\pickle.py:1760: UserWarning: [15:07:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  setstate(state)\n",
      "c:\\Users\\Playdata2\\miniconda3\\envs\\final-env\\Lib\\pickle.py:1760: UserWarning: [15:07:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  setstate(state)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "메인 객체 타입: <class 'dict'>\n",
      "딕셔너리 키 개수: 3\n",
      "  'classifier': <class 'sklearn.multiclass.OneVsRestClassifier'>\n",
      "    └─ classes_: 45개 (<class 'numpy.int64'>)\n",
      "       샘플: [np.int64(0), np.int64(1), np.int64(2)]...\n",
      "  'mlb': <class 'sklearn.preprocessing._label.MultiLabelBinarizer'>\n",
      "    └─ classes_: 45개 (<class 'str'>)\n",
      "       샘플: ['$$$', 'Amber', 'Aromatic']...\n",
      "  'thresholds': <class 'dict'>\n",
      "============================================================\n",
      "\n",
      "모델 로딩을 시도합니다...\n",
      "[Loading] Model bundle from: ./model.pkl\n",
      "[DEBUG] 번들 파일 로딩 중: ./model.pkl\n",
      "[DEBUG] 로드된 객체 타입: <class 'dict'>\n",
      "[DEBUG] 딕셔너리 키들: ['classifier', 'mlb', 'thresholds']\n",
      "[DEBUG] 분류기 타입: <class 'sklearn.multiclass.OneVsRestClassifier'>\n",
      "[DEBUG] MLB 타입: <class 'sklearn.preprocessing._label.MultiLabelBinarizer'>, classes 개수: 45\n",
      "[DEBUG] MLB에서 라벨 복원: 45개\n",
      "[DEBUG] 라벨 샘플: ['$$$', 'Amber', 'Aromatic', 'Blossom', 'Bouquet']\n",
      "[DEBUG] 임계값 타입: <class 'dict'>\n",
      "[DEBUG] 라벨 순서 불일치. 분류기 순서로 재정렬\n",
      "[DEBUG] 최종 라벨 개수: 0\n",
      "[Loading] Embedder: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n",
      "[Loaded] Labels: 0\n",
      "[WARN] labels가 없음 - 런타임에 class_0, class_1... 형태로 생성됨\n",
      "[Loaded] Thresholds type: ndarray\n",
      "\n",
      "💡 라벨이 없으므로 향수 어코드를 수동으로 매핑할 수 있습니다.\n",
      "✅ 향수 어코드 라벨 45개를 적용했습니다.\n",
      "샘플: ['Citrus', 'Fresh', 'Aquatic', 'Green', 'Herbal']...\n",
      "\n",
      "============================================================\n",
      "향수 메인 어코드 추출 테스트 (predict_one)\n",
      "============================================================\n",
      "\n",
      "[Test 1]\n",
      "\n",
      "[Query] 여름에 뿌릴만한 향수 추천해주세요\n",
      " - TopK : Berry(0.737), Rose(0.347), Spicy(0.321)\n",
      " - Pass : Berry(0.737)\n",
      "\n",
      "[Test 2]\n",
      "\n",
      "[Query] 겨울에 어울리는 따뜻한 향수가 뭐가 있을까요?\n",
      " - TopK : Berry(0.798), Powdery(0.643), Fresh(0.608)\n",
      " - Pass : Berry(0.798), Powdery(0.643), Fresh(0.608), Chocolate(0.584)\n",
      "\n",
      "[Test 3]\n",
      "\n",
      "[Query] 봄에 어울리는 플로럴 향수 추천해주세요\n",
      " - TopK : Berry(0.804), Fruity(0.444), Rose(0.303)\n",
      " - Pass : Berry(0.804)\n",
      "\n",
      "[Test 4]\n",
      "\n",
      "[Query] 가을에 뿌리기 좋은 우디한 향수는?\n",
      " - TopK : Berry(0.707), Rose(0.403), Powdery(0.309)\n",
      " - Pass : Berry(0.707)\n",
      "\n",
      "[Test 5]\n",
      "\n",
      "[Query] 데이트할 때 뿌리면 좋은 향수 추천\n",
      " - TopK : Berry(0.915), Spicy(0.473), Powdery(0.384)\n",
      " - Pass : Berry(0.915)\n",
      "\n",
      "============================================================\n",
      "배치 향수 어코드 추출 테스트\n",
      "============================================================\n",
      "\n",
      "[Batch 1] 여름에 뿌릴만한 향수 추천해주세요...\n",
      "  Top3: Berry(0.737), Rose(0.347), Spicy(0.321)\n",
      "  Pass: Berry(0.737)\n",
      "\n",
      "[Batch 2] 겨울에 어울리는 따뜻한 향수가 뭐가 있을까요?...\n",
      "  Top3: Berry(0.798), Powdery(0.643), Fresh(0.608)\n",
      "  Pass: Berry(0.798), Powdery(0.643), Fresh(0.608), Chocolate(0.584)\n",
      "\n",
      "[Batch 3] 봄에 어울리는 플로럴 향수 추천해주세요...\n",
      "  Top3: Berry(0.804), Fruity(0.444), Rose(0.303)\n",
      "  Pass: Berry(0.804)\n",
      "\n",
      "[Batch 4] 가을에 뿌리기 좋은 우디한 향수는?...\n",
      "  Top3: Berry(0.707), Rose(0.403), Powdery(0.309)\n",
      "  Pass: Berry(0.707)\n",
      "\n",
      "[Batch 5] 데이트할 때 뿌리면 좋은 향수 추천...\n",
      "  Top3: Berry(0.915), Spicy(0.473), Powdery(0.384)\n",
      "  Pass: Berry(0.915)\n",
      "\n",
      "[Batch 6] 직장에서 뿌려도 되는 은은한 향수는?...\n",
      "  Top3: Berry(0.785), Fresh(0.346), Rose(0.280)\n",
      "  Pass: Berry(0.785)\n",
      "\n",
      "[Batch 7] 파티나 클럽에 어울리는 섹시한 향수 추천...\n",
      "  Top3: Berry(0.805), Fresh(0.609), Spicy(0.474)\n",
      "  Pass: Berry(0.805), Fresh(0.609)\n",
      "\n",
      "[Batch 8] 운동할 때 뿌려도 좋은 상쾌한 향수는?...\n",
      "  Top3: Berry(0.864), Rose(0.395), Pear(0.161)\n",
      "  Pass: Berry(0.864)\n",
      "\n",
      "============================================================\n",
      "메인 어코드 추출 통계\n",
      "============================================================\n",
      "전체 테스트: 8\n",
      "임계값 통과: 8\n",
      "어코드 추출율: 100.0%\n",
      "\n",
      "메인 어코드별 등장 횟수:\n",
      "  Berry: 8회\n",
      "  Fresh: 2회\n",
      "  Powdery: 1회\n",
      "  Chocolate: 1회\n",
      "\n",
      "테스트 완료!\n"
     ]
    }
   ],
   "source": [
    "def create_manual_labels():\n",
    "    \"\"\"수동으로 향수 어코드 라벨을 생성하는 함수 (참고용)\"\"\"\n",
    "    \n",
    "    # 일반적인 향수 어코드들 (45개 클래스 예시)\n",
    "    fragrance_accords = [\n",
    "        \"Citrus\", \"Fresh\", \"Aquatic\", \"Green\", \"Herbal\",           # 0-4: 상쾌한 계열\n",
    "        \"Floral\", \"Rose\", \"Jasmine\", \"Lily\", \"Peony\",             # 5-9: 플로럴 계열  \n",
    "        \"Fruity\", \"Apple\", \"Pear\", \"Peach\", \"Berry\",              # 10-14: 과일 계열\n",
    "        \"Spicy\", \"Pepper\", \"Cinnamon\", \"Ginger\", \"Cardamom\",      # 15-19: 스파이시 계열\n",
    "        \"Woody\", \"Sandalwood\", \"Cedar\", \"Pine\", \"Vetiver\",        # 20-24: 우디 계열\n",
    "        \"Oriental\", \"Amber\", \"Incense\", \"Oud\", \"Patchouli\",       # 25-29: 오리엔탈 계열\n",
    "        \"Gourmand\", \"Vanilla\", \"Caramel\", \"Chocolate\", \"Coffee\",  # 30-34: 구르망 계열\n",
    "        \"Musk\", \"Animalic\", \"Leather\", \"Tobacco\", \"Smoky\",        # 35-39: 깊은 계열\n",
    "        \"Powdery\", \"Clean\", \"Soap\", \"Marine\", \"Ozonic\"            # 40-44: 파우더리/클린 계열\n",
    "    ]\n",
    "    \n",
    "    return fragrance_accords[:45]  # 정확히 45개로 맞춤def inspect_model_bundle(pkl_path: str):\n",
    "    \"\"\"모델 번들 구조를 자세히 분석하는 함수\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"모델 번들 구조 분석\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    try:\n",
    "        obj = joblib.load(pkl_path)\n",
    "        print(f\"메인 객체 타입: {type(obj)}\")\n",
    "        \n",
    "        if isinstance(obj, dict):\n",
    "            print(f\"딕셔너리 키 개수: {len(obj)}\")\n",
    "            for key, value in obj.items():\n",
    "                print(f\"  '{key}': {type(value)}\")\n",
    "                \n",
    "                # 라벨 관련 속성 확인\n",
    "                if hasattr(value, 'classes_'):\n",
    "                    print(f\"    └─ classes_: {len(value.classes_)}개 ({type(value.classes_[0]) if len(value.classes_) > 0 else 'empty'})\")\n",
    "                    if len(value.classes_) > 0:\n",
    "                        print(f\"       샘플: {list(value.classes_[:3])}...\")\n",
    "                \n",
    "                # 배열/리스트인 경우 내용 확인\n",
    "                if isinstance(value, (list, tuple, np.ndarray)):\n",
    "                    print(f\"    └─ 길이: {len(value)}\")\n",
    "                    if len(value) > 0:\n",
    "                        print(f\"       타입: {type(value[0])}\")\n",
    "                        if isinstance(value[0], str):\n",
    "                            print(f\"       샘플: {list(value[:3])}...\")\n",
    "        \n",
    "        else:\n",
    "            print(\"단일 객체 (비딕셔너리)\")\n",
    "            if hasattr(obj, 'classes_'):\n",
    "                print(f\"  classes_: {len(obj.classes_)}개\")\n",
    "                print(f\"  샘플: {list(obj.classes_[:3])}...\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"분석 실패: {e}\")\n",
    "    \n",
    "    print(\"=\"*60)# ============================================\n",
    "# model.pkl 번들 로드 + MiniLM 임베딩 + 예측\n",
    "# (joblib.load, 마스킹 평균풀링, 라벨/임계값 정렬 포함)\n",
    "# ============================================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import joblib\n",
    "import torch\n",
    "from typing import Any, Dict, List, Tuple\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# --------- 설정 ----------\n",
    "MODEL_PKL = os.getenv(\"MODEL_PKL\", \"./model.pkl\")  # 번들 경로\n",
    "HF_MODEL  = os.getenv(\"HF_MODEL\", \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "MAX_LEN   = int(os.getenv(\"MAX_LEN\", 256))\n",
    "DEVICE    = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SZ  = int(os.getenv(\"BATCH_SZ\", 16))\n",
    "print(f\"[Device] {DEVICE}\")\n",
    "\n",
    "# --------- 1) 번들 로드 (수정본) ----------\n",
    "def load_bundle(pkl_path: str) -> Dict[str, Any]:\n",
    "    print(f\"[DEBUG] 번들 파일 로딩 중: {pkl_path}\")\n",
    "    obj = joblib.load(pkl_path)  # ✅ joblib.load로 읽어야 함\n",
    "    \n",
    "    # 번들 구조 디버깅\n",
    "    print(f\"[DEBUG] 로드된 객체 타입: {type(obj)}\")\n",
    "    if isinstance(obj, dict):\n",
    "        print(f\"[DEBUG] 딕셔너리 키들: {list(obj.keys())}\")\n",
    "        bundle = obj\n",
    "    else:\n",
    "        print(f\"[DEBUG] 딕셔너리가 아님. 분류기로 가정\")\n",
    "        bundle = {\"classifier\": obj}\n",
    "\n",
    "    # 분류기 찾기\n",
    "    clf = bundle.get(\"classifier\") or bundle.get(\"model\") or bundle.get(\"clf\")\n",
    "    if clf is None:\n",
    "        # 가능한 모든 키 확인\n",
    "        for key, value in bundle.items():\n",
    "            if hasattr(value, \"predict_proba\"):\n",
    "                print(f\"[DEBUG] '{key}'에서 predict_proba 발견\")\n",
    "                clf = value\n",
    "                break\n",
    "    \n",
    "    if clf is None or not hasattr(clf, \"predict_proba\"):\n",
    "        raise ValueError(\"bundle에 predict_proba 가능한 분류기가 필요합니다.\")\n",
    "\n",
    "    print(f\"[DEBUG] 분류기 타입: {type(clf)}\")\n",
    "    \n",
    "    # MultiLabelBinarizer 찾기\n",
    "    mlb = bundle.get(\"mlb\") or bundle.get(\"multilabel_binarizer\") or bundle.get(\"label_binarizer\")\n",
    "    if mlb is None:\n",
    "        for key, value in bundle.items():\n",
    "            if hasattr(value, \"classes_\") and hasattr(value, \"transform\"):\n",
    "                print(f\"[DEBUG] '{key}'에서 MultiLabelBinarizer 발견\")\n",
    "                mlb = value\n",
    "                break\n",
    "    \n",
    "    if mlb:\n",
    "        print(f\"[DEBUG] MLB 타입: {type(mlb)}, classes 개수: {len(mlb.classes_) if hasattr(mlb, 'classes_') else 'None'}\")\n",
    "    \n",
    "    # 라벨 찾기 (여러 방법 시도)\n",
    "    labels = None\n",
    "    \n",
    "    # 1. 직접 저장된 labels\n",
    "    labels = bundle.get(\"labels\") or bundle.get(\"label_names\") or bundle.get(\"classes\") or bundle.get(\"class_names\")\n",
    "    \n",
    "    # 2. MLB에서 복원\n",
    "    if labels is None and mlb is not None and hasattr(mlb, \"classes_\"):\n",
    "        labels = list(mlb.classes_)\n",
    "        print(f\"[DEBUG] MLB에서 라벨 복원: {len(labels)}개\")\n",
    "        print(f\"[DEBUG] 라벨 샘플: {labels[:5] if len(labels) > 5 else labels}\")\n",
    "    \n",
    "    # 3. 분류기에서 복원\n",
    "    if labels is None and hasattr(clf, \"classes_\"):\n",
    "        labels = list(clf.classes_)\n",
    "        print(f\"[DEBUG] 분류기에서 라벨 복원: {len(labels)}개\")\n",
    "    \n",
    "    # 4. 번들의 모든 키에서 라벨 찾기\n",
    "    if labels is None:\n",
    "        for key, value in bundle.items():\n",
    "            if isinstance(value, (list, tuple, np.ndarray)) and len(value) > 0:\n",
    "                if isinstance(value[0], str):  # 문자열 배열이면 라벨일 가능성\n",
    "                    print(f\"[DEBUG] '{key}'에서 문자열 배열 발견: {len(value)}개\")\n",
    "                    labels = list(value)\n",
    "                    break\n",
    "    \n",
    "    thresholds = bundle.get(\"thresholds\", 0.5)\n",
    "    print(f\"[DEBUG] 임계값 타입: {type(thresholds)}\")\n",
    "\n",
    "    # 라벨 정렬/검증\n",
    "    if hasattr(clf, \"classes_\") and labels is not None:\n",
    "        clf_labels = list(clf.classes_)\n",
    "        if list(labels) != clf_labels:\n",
    "            print(f\"[DEBUG] 라벨 순서 불일치. 분류기 순서로 재정렬\")\n",
    "            idx_map = {lbl: i for i, lbl in enumerate(labels)}\n",
    "            labels = [lbl for lbl in clf_labels if lbl in idx_map]\n",
    "\n",
    "        # thresholds가 dict라면 clf 순서에 맞춰 배열로 변환\n",
    "        if isinstance(thresholds, dict):\n",
    "            thresholds = np.array([float(thresholds.get(lbl, 0.5)) for lbl in labels], dtype=float)\n",
    "\n",
    "    print(f\"[DEBUG] 최종 라벨 개수: {len(labels) if labels else 0}\")\n",
    "    return {\"classifier\": clf, \"mlb\": mlb, \"labels\": labels, \"thresholds\": thresholds}\n",
    "\n",
    "def inspect_model_bundle(pkl_path: str):\n",
    "    \"\"\"모델 번들 구조를 자세히 분석하는 함수\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"모델 번들 구조 분석\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    try:\n",
    "        obj = joblib.load(pkl_path)\n",
    "        print(f\"메인 객체 타입: {type(obj)}\")\n",
    "        \n",
    "        if isinstance(obj, dict):\n",
    "            print(f\"딕셔너리 키 개수: {len(obj)}\")\n",
    "            for key, value in obj.items():\n",
    "                print(f\"  '{key}': {type(value)}\")\n",
    "                \n",
    "                # 라벨 관련 속성 확인\n",
    "                if hasattr(value, 'classes_'):\n",
    "                    print(f\"    └─ classes_: {len(value.classes_)}개 ({type(value.classes_[0]) if len(value.classes_) > 0 else 'empty'})\")\n",
    "                    if len(value.classes_) > 0:\n",
    "                        print(f\"       샘플: {list(value.classes_[:3])}...\")\n",
    "                \n",
    "                # 배열/리스트인 경우 내용 확인\n",
    "                if isinstance(value, (list, tuple, np.ndarray)):\n",
    "                    print(f\"    └─ 길이: {len(value)}\")\n",
    "                    if len(value) > 0:\n",
    "                        print(f\"       타입: {type(value[0])}\")\n",
    "                        if isinstance(value[0], str):\n",
    "                            print(f\"       샘플: {list(value[:3])}...\")\n",
    "        \n",
    "        else:\n",
    "            print(\"단일 객체 (비딕셔너리)\")\n",
    "            if hasattr(obj, 'classes_'):\n",
    "                print(f\"  classes_: {len(obj.classes_)}개\")\n",
    "                print(f\"  샘플: {list(obj.classes_[:3])}...\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"분석 실패: {e}\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "\n",
    "def create_manual_labels():\n",
    "    \"\"\"수동으로 향수 어코드 라벨을 생성하는 함수 (참고용)\"\"\"\n",
    "    \n",
    "    # 일반적인 향수 어코드들 (45개 클래스 예시)\n",
    "    fragrance_accords = [\n",
    "        \"Citrus\", \"Fresh\", \"Aquatic\", \"Green\", \"Herbal\",           # 0-4: 상쾌한 계열\n",
    "        \"Floral\", \"Rose\", \"Jasmine\", \"Lily\", \"Peony\",             # 5-9: 플로럴 계열  \n",
    "        \"Fruity\", \"Apple\", \"Pear\", \"Peach\", \"Berry\",              # 10-14: 과일 계열\n",
    "        \"Spicy\", \"Pepper\", \"Cinnamon\", \"Ginger\", \"Cardamom\",      # 15-19: 스파이시 계열\n",
    "        \"Woody\", \"Sandalwood\", \"Cedar\", \"Pine\", \"Vetiver\",        # 20-24: 우디 계열\n",
    "        \"Oriental\", \"Amber\", \"Incense\", \"Oud\", \"Patchouli\",       # 25-29: 오리엔탈 계열\n",
    "        \"Gourmand\", \"Vanilla\", \"Caramel\", \"Chocolate\", \"Coffee\",  # 30-34: 구르망 계열\n",
    "        \"Musk\", \"Animalic\", \"Leather\", \"Tobacco\", \"Smoky\",        # 35-39: 깊은 계열\n",
    "        \"Powdery\", \"Clean\", \"Soap\", \"Marine\", \"Ozonic\"            # 40-44: 파우더리/클린 계열\n",
    "    ]\n",
    "    \n",
    "    return fragrance_accords[:45]  # 정확히 45개로 맞춤\n",
    "\n",
    "# --------- 2) 임베더 로드 ----------\n",
    "def load_embedder():\n",
    "    tokenizer = AutoTokenizer.from_pretrained(HF_MODEL)\n",
    "    base_model = AutoModel.from_pretrained(HF_MODEL).to(DEVICE).eval()\n",
    "    return tokenizer, base_model\n",
    "\n",
    "@torch.inference_mode()\n",
    "def encode_texts(texts: List[str], tokenizer, base_model, max_len: int = MAX_LEN, batch_size: int = BATCH_SZ) -> np.ndarray:\n",
    "    out = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        enc = tokenizer(\n",
    "            batch, padding=True, truncation=True, max_length=max_len, return_tensors=\"pt\"\n",
    "        ).to(DEVICE)\n",
    "\n",
    "        last = base_model(**enc).last_hidden_state        # (B, L, H)\n",
    "        mask = enc[\"attention_mask\"].unsqueeze(-1)        # (B, L, 1)\n",
    "        summed = (last * mask).sum(dim=1)                 \n",
    "        counts = mask.sum(dim=1).clamp(min=1)             \n",
    "        emb = summed / counts                             \n",
    "        out.append(emb.detach().cpu().numpy())\n",
    "    return np.vstack(out)\n",
    "\n",
    "# --------- 3) 확률 표준화 ----------\n",
    "def _standardize_proba(proba) -> np.ndarray:\n",
    "    if isinstance(proba, list):\n",
    "        cols = []\n",
    "        for p in proba:\n",
    "            p = np.asarray(p)\n",
    "            if p.ndim == 2 and p.shape[1] > 1:\n",
    "                cols.append(p[:, 1])\n",
    "            else:\n",
    "                cols.append(p.ravel())\n",
    "        proba = np.column_stack(cols)\n",
    "    proba = np.asarray(proba)\n",
    "    if proba.ndim == 1:\n",
    "        proba = proba.reshape(1, -1)\n",
    "    return proba\n",
    "\n",
    "# --------- 4) 임계값 적용 (수정본) ----------\n",
    "def apply_thresholds(p: np.ndarray, labels: List[str], thresholds) -> List[Tuple[str, float]]:\n",
    "    n = len(p)\n",
    "    \n",
    "    # labels 검증 및 처리\n",
    "    if labels is None or len(labels) == 0:\n",
    "        print(f\"[WARN] labels가 없음. 인덱스 번호를 사용합니다 (len(p)={n})\")\n",
    "        labels = [f\"class_{i}\" for i in range(n)]\n",
    "    elif len(labels) != n:\n",
    "        print(f\"[WARN] len(p)={n}, len(labels)={len(labels)} → 길이 맞춤\")\n",
    "        if len(labels) < n:\n",
    "            # labels가 부족하면 인덱스로 채움\n",
    "            labels = list(labels) + [f\"class_{i}\" for i in range(len(labels), n)]\n",
    "        else:\n",
    "            # labels가 너무 많으면 자름\n",
    "            labels = labels[:n]\n",
    "\n",
    "    # thresholds 처리\n",
    "    if isinstance(thresholds, dict) and labels is not None:\n",
    "        thr_arr = np.array([float(thresholds.get(lbl, 0.5)) for lbl in labels], dtype=float)\n",
    "    elif hasattr(thresholds, \"__len__\") and not isinstance(thresholds, (str, bytes)):\n",
    "        thr_arr = np.array(thresholds, dtype=float)\n",
    "        if len(thr_arr) != n:\n",
    "            thr_arr = np.full(n, float(np.median(thresholds) if len(thresholds) else 0.5), dtype=float)\n",
    "    else:\n",
    "        thr_arr = np.full(n, float(thresholds), dtype=float)\n",
    "\n",
    "    # 임계값 적용\n",
    "    idx = np.where(p >= thr_arr)[0]\n",
    "    \n",
    "    # 안전한 인덱스 접근\n",
    "    names = []\n",
    "    vals = []\n",
    "    for i in idx:\n",
    "        if i < len(labels):\n",
    "            names.append(labels[i])\n",
    "            vals.append(float(p[i]))\n",
    "    \n",
    "    return sorted(list(zip(names, vals)), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# --------- 5) 예측 클래스 ----------\n",
    "class TextClassifier:\n",
    "    def __init__(self, model_path: str):\n",
    "        print(f\"[Loading] Model bundle from: {model_path}\")\n",
    "        self.bundle = load_bundle(model_path)\n",
    "        self.clf = self.bundle[\"classifier\"]\n",
    "        self.labels = self.bundle[\"labels\"]\n",
    "        self.thresholds = self.bundle[\"thresholds\"]\n",
    "        \n",
    "        print(f\"[Loading] Embedder: {HF_MODEL}\")\n",
    "        self.tokenizer, self.base_model = load_embedder()\n",
    "        \n",
    "        print(f\"[Loaded] Labels: {len(self.labels) if self.labels else 0}\")\n",
    "        if self.labels and len(self.labels) > 0:\n",
    "            print(f\"[Loaded] Sample labels: {self.labels[:5]}{'...' if len(self.labels) > 5 else ''}\")\n",
    "        else:\n",
    "            print(f\"[WARN] labels가 없음 - 런타임에 class_0, class_1... 형태로 생성됨\")\n",
    "        print(f\"[Loaded] Thresholds type: {type(self.thresholds).__name__}\")\n",
    "\n",
    "    def predict_labels(self, texts: List[str], topk: int = 3) -> List[Dict[str, Any]]:\n",
    "        vec = encode_texts(texts, self.tokenizer, self.base_model)\n",
    "        proba = _standardize_proba(self.clf.predict_proba(vec))\n",
    "        results = []\n",
    "        \n",
    "        for i, t in enumerate(texts):\n",
    "            p = proba[i]\n",
    "            n_classes = len(p)\n",
    "            \n",
    "            # labels 안전성 검사\n",
    "            if self.labels is None or len(self.labels) == 0:\n",
    "                current_labels = [f\"class_{j}\" for j in range(n_classes)]\n",
    "                print(f\"[INFO] labels 없음 → class_0, class_1, ... 사용\")\n",
    "            elif len(self.labels) != n_classes:\n",
    "                current_labels = list(self.labels) + [f\"class_{j}\" for j in range(len(self.labels), n_classes)]\n",
    "                if len(current_labels) > n_classes:\n",
    "                    current_labels = current_labels[:n_classes]\n",
    "            else:\n",
    "                current_labels = self.labels\n",
    "            \n",
    "            # TopK 계산\n",
    "            idx_sorted = np.argsort(p)[::-1][:topk]\n",
    "            top_pairs = [(current_labels[j], float(p[j])) for j in idx_sorted if j < len(current_labels)]\n",
    "            \n",
    "            # 임계값 적용\n",
    "            passed = apply_thresholds(p, current_labels, self.thresholds)\n",
    "            \n",
    "            results.append({\n",
    "                \"text\": t,\n",
    "                \"topk\": top_pairs,\n",
    "                \"passed_threshold\": passed,\n",
    "                \"all_probs\": p,\n",
    "            })\n",
    "        return results\n",
    "\n",
    "    def predict_one(self, text: str, topk: int = 5) -> Dict[str, Any]:\n",
    "        out = self.predict_labels([text], topk=topk)[0]\n",
    "        print(f\"\\n[Query] {out['text']}\")\n",
    "        print(f\" - TopK : {', '.join(f'{n}({s:.3f})' for n, s in out['topk'])}\")\n",
    "        if out[\"passed_threshold\"]:\n",
    "            print(f\" - Pass : {', '.join(f'{n}({s:.3f})' for n, s in out['passed_threshold'])}\")\n",
    "        else:\n",
    "            print(\" - Pass : (임계값 통과 없음 → TopK 참고)\")\n",
    "        return out\n",
    "\n",
    "# ============================================\n",
    "# 테스트 코드\n",
    "# ============================================\n",
    "\n",
    "def run_tests():\n",
    "    \"\"\"테스트 실행 함수\"\"\"\n",
    "    \n",
    "    # 먼저 모델 구조 분석\n",
    "    inspect_model_bundle(MODEL_PKL)\n",
    "    \n",
    "    # 향수 관련 테스트 쿼리들 (메인 어코드 추출용)\n",
    "    test_queries = [\n",
    "        # 계절별 향수 추천\n",
    "        \"여름에 뿌릴만한 향수 추천해주세요\",\n",
    "        \"겨울에 어울리는 따뜻한 향수가 뭐가 있을까요?\",\n",
    "        \"봄에 어울리는 플로럴 향수 추천해주세요\",\n",
    "        \"가을에 뿌리기 좋은 우디한 향수는?\",\n",
    "        \n",
    "        # 상황별 향수 추천\n",
    "        \"데이트할 때 뿌리면 좋은 향수 추천\",\n",
    "        \"직장에서 뿌려도 되는 은은한 향수는?\",\n",
    "        \"파티나 클럽에 어울리는 섹시한 향수 추천\",\n",
    "        \"운동할 때 뿌려도 좋은 상쾌한 향수는?\",\n",
    "        \n",
    "        # 성별/연령별 추천\n",
    "        \"20대 여성에게 어울리는 향수 추천해주세요\",\n",
    "        \"30대 남성이 쓰기 좋은 향수는?\",\n",
    "        \"10대가 쓰기에 부담없는 향수 추천\",\n",
    "        \"50대 여성에게 어울리는 우아한 향수는?\",\n",
    "        \n",
    "        # 향조/어코드별 문의\n",
    "        \"시트러스 계열의 상큼한 향수 추천\",\n",
    "        \"바닐라 향이 강한 달콤한 향수는?\",\n",
    "        \"머스크 향이 들어간 향수 추천해주세요\",\n",
    "        \"우디 계열의 중후한 향수가 뭐가 있나요?\",\n",
    "        \"플로럴 부케 향수 중에 추천해주세요\",\n",
    "        \n",
    "        # 브랜드/가격대별\n",
    "        \"샤넬 향수 중에 인기있는거 추천\",\n",
    "        \"10만원 이하로 살 수 있는 좋은 향수는?\",\n",
    "        \"디올 향수 중에 여름용으로 좋은건?\",\n",
    "        \"학생도 살 수 있는 저렴한 향수 추천\",\n",
    "        \n",
    "        # 특정 향 선호도\n",
    "        \"장미향이 나는 향수 추천해주세요\",\n",
    "        \"오션 냄새가 나는 시원한 향수는?\",\n",
    "        \"과일향이 강한 프루티한 향수 추천\",\n",
    "        \"커피나 초콜릿 향이 나는 향수는?\",\n",
    "        \"허브향이 들어간 자연스러운 향수 추천\"\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        # 분류기 초기화\n",
    "        print(f\"\\n모델 로딩을 시도합니다...\")\n",
    "        classifier = TextClassifier(MODEL_PKL)\n",
    "        \n",
    "        # 라벨이 없으면 수동으로 생성 제안\n",
    "        if not classifier.labels or len(classifier.labels) == 0:\n",
    "            print(f\"\\n💡 라벨이 없으므로 향수 어코드를 수동으로 매핑할 수 있습니다.\")\n",
    "            manual_labels = create_manual_labels()\n",
    "            \n",
    "            response = input(f\"수동 향수 어코드 라벨을 사용하시겠습니까? (y/n): \").strip().lower()\n",
    "            if response in ['y', 'yes', '네', 'ㅇ']:\n",
    "                classifier.labels = manual_labels\n",
    "                print(f\"✅ 향수 어코드 라벨 {len(manual_labels)}개를 적용했습니다.\")\n",
    "                print(f\"샘플: {manual_labels[:5]}...\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"향수 메인 어코드 추출 테스트 (predict_one)\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # 개별 테스트 (상위 3개)\n",
    "        for i, query in enumerate(test_queries[:5]):  # 처음 5개만\n",
    "            print(f\"\\n[Test {i+1}]\")\n",
    "            result = classifier.predict_one(query, topk=3)\n",
    "            \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"배치 향수 어코드 추출 테스트\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # 배치 테스트\n",
    "        batch_results = classifier.predict_labels(test_queries[:8], topk=3)\n",
    "        \n",
    "        for i, result in enumerate(batch_results):\n",
    "            print(f\"\\n[Batch {i+1}] {result['text'][:50]}...\")\n",
    "            print(f\"  Top3: {', '.join(f'{n}({s:.3f})' for n, s in result['topk'])}\")\n",
    "            if result['passed_threshold']:\n",
    "                print(f\"  Pass: {', '.join(f'{n}({s:.3f})' for n, s in result['passed_threshold'])}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"메인 어코드 추출 통계\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # 임계값 통과 통계\n",
    "        total_tests = len(batch_results)\n",
    "        passed_tests = sum(1 for r in batch_results if r['passed_threshold'])\n",
    "        \n",
    "        print(f\"전체 테스트: {total_tests}\")\n",
    "        print(f\"임계값 통과: {passed_tests}\")\n",
    "        print(f\"어코드 추출율: {passed_tests/total_tests*100:.1f}%\")\n",
    "        \n",
    "        # 어코드별 통계\n",
    "        accord_counts = {}\n",
    "        for result in batch_results:\n",
    "            for accord, score in result['passed_threshold']:\n",
    "                accord_counts[accord] = accord_counts.get(accord, 0) + 1\n",
    "        \n",
    "        if accord_counts:\n",
    "            print(\"\\n메인 어코드별 등장 횟수:\")\n",
    "            for accord, count in sorted(accord_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "                print(f\"  {accord}: {count}회\")\n",
    "        \n",
    "        print(\"\\n테스트 완료!\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"[ERROR] 모델 파일을 찾을 수 없습니다: {MODEL_PKL}\")\n",
    "        print(\"다음 중 하나를 확인해주세요:\")\n",
    "        print(\"1. model.pkl 파일이 현재 디렉토리에 있는지 확인\")\n",
    "        print(\"2. MODEL_PKL 환경변수로 올바른 경로 설정\")\n",
    "        print(\"3. 예시: export MODEL_PKL='/path/to/your/model.pkl'\")\n",
    "        \n",
    "    except ValueError as e:\n",
    "        print(f\"[ERROR] 모델 로딩 오류: {str(e)}\")\n",
    "        print(\"model.pkl 파일의 구조를 확인해주세요.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] 예상치 못한 오류가 발생했습니다: {str(e)}\")\n",
    "        print(f\"오류 타입: {type(e).__name__}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "def interactive_test():\n",
    "    \"\"\"대화형 테스트 함수\"\"\"\n",
    "    try:\n",
    "        classifier = TextClassifier(MODEL_PKL)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"향수 메인 어코드 추출 - 대화형 모드\")\n",
    "        print(\"=\"*60)\n",
    "        print(\"향수 관련 질문을 입력하면 메인 어코드 3개를 추출합니다.\")\n",
    "        print(\"예시: '여름에 뿌릴만한 향수 추천', '데이트용 향수 추천' 등\")\n",
    "        print(\"종료하려면 'quit' 또는 'exit'를 입력하세요.\")\n",
    "        \n",
    "        while True:\n",
    "            query = input(\"\\n향수 질문 입력: \").strip()\n",
    "            if query.lower() in ['quit', 'exit', '종료']:\n",
    "                break\n",
    "            if not query:\n",
    "                continue\n",
    "                \n",
    "            result = classifier.predict_one(query, topk=3)  # 메인 어코드 3개\n",
    "            \n",
    "            # 추가 정보 표시\n",
    "            if result[\"passed_threshold\"]:\n",
    "                print(f\"\\n✅ 추출된 메인 어코드: {len(result['passed_threshold'])}개\")\n",
    "            else:\n",
    "                print(f\"\\n⚠️  임계값을 넘는 어코드가 없어 상위 3개를 참고하세요\")\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\n프로그램을 종료합니다.\")\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] {str(e)}\")\n",
    "\n",
    "# ============================================\n",
    "# 메인 실행부\n",
    "# ============================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"향수 메인 어코드 추출 시스템 테스트\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 환경 정보 출력\n",
    "    print(f\"Model Path: {MODEL_PKL}\")\n",
    "    print(f\"HF Model: {HF_MODEL}\")\n",
    "    print(f\"Device: {DEVICE}\")\n",
    "    print(f\"Max Length: {MAX_LEN}\")\n",
    "    print(f\"Batch Size: {BATCH_SZ}\")\n",
    "    \n",
    "    # 테스트 선택\n",
    "    import sys\n",
    "    if len(sys.argv) > 1 and sys.argv[1] == \"interactive\":\n",
    "        interactive_test()\n",
    "    else:\n",
    "        run_tests()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
