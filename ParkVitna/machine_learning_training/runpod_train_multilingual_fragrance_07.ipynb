{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82e18482-f900-4e8f-b546-527539f2c839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch<3.0,>=2.2 in /usr/local/lib/python3.11/dist-packages (2.8.0.dev20250319+cu128)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.22.0.dev20250319+cu128)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0.dev20250319+cu128)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.2) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.2) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.2) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.2) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.2) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.2) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.61 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.2) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.57 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.2) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.57 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.2) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.8.0.87 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.2) (9.8.0.87)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.3.14 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.2) (12.8.3.14)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.41 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.2) (11.3.3.41)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.55 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.2) (10.3.9.55)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.2.55 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.2) (11.7.2.55)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.7.53 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.2) (12.5.7.53)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.2) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.25.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.2) (2.25.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.55 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.2) (12.8.55)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.61 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.2) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.0.11 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.2) (1.13.0.11)\n",
      "Requirement already satisfied: pytorch-triton==3.3.0+git96316ce5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.2) (3.3.0+git96316ce5)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-triton==3.3.0+git96316ce5->torch<3.0,>=2.2) (77.0.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.3.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch<3.0,>=2.2) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0,>=2.2) (2.1.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.7.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.3.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.3.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.5.2)\n",
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (5.1.0)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.55.4)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.16.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.8.0.dev20250319+cu128)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.34.4)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.0.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2025.7.34)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.9)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.61 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.57 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.57 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.8.0.87 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.8.0.87)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.3.14 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.8.3.14)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.41 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.3.41)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.55 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.9.55)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.2.55 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.2.55)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.7.53 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.7.53)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.25.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.25.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.55 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.8.55)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.61 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.0.11 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.0.11)\n",
      "Requirement already satisfied: pytorch-triton==3.3.0+git96316ce5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3.0+git96316ce5)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-triton==3.3.0+git96316ce5->torch>=1.11.0->sentence-transformers) (77.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 설치 (Runpod A40 / 로컬)\n",
    "# ============================================\n",
    "\n",
    "# CPU 전용\n",
    "# python -m pip install -U \"torch>=2.2,<3.0\" scikit-learn pandas numpy joblib sentence-transformers transformers\n",
    "\n",
    "# GPU (CUDA 12.1, Runpod A40)\n",
    "!python -m pip install -U \"torch>=2.2,<3.0\" torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "!python -m pip install -U scikit-learn pandas numpy joblib sentence-transformers transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6938d4eb-0935-49df-b92d-de1d37e9126f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: transformers 4.55.4\n",
      "Uninstalling transformers-4.55.4:\n",
      "  Successfully uninstalled transformers-4.55.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mFound existing installation: huggingface-hub 0.34.4\n",
      "Uninstalling huggingface-hub-0.34.4:\n",
      "  Successfully uninstalled huggingface-hub-0.34.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mFound existing installation: tokenizers 0.21.4\n",
      "Uninstalling tokenizers-0.21.4:\n",
      "  Successfully uninstalled tokenizers-0.21.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting transformers\n",
      "  Downloading transformers-4.55.4-py3-none-any.whl.metadata (41 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.16.1)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2025.7.34)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
      "Downloading transformers-4.55.4-py3-none-any.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m753.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m561.5/561.5 kB\u001b[0m \u001b[31m602.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m958.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.34.4 tokenizers-0.21.4 transformers-4.55.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall transformers -y\n",
    "!pip uninstall huggingface-hub -y\n",
    "!pip uninstall tokenizers -y\n",
    "\n",
    "!pip install --no-cache-dir transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f671e0c6-e3ef-4ac7-b441-0aa443879d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Device] cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 0.2803\n",
      "Epoch 2 | Train Loss: 0.1823\n",
      "Epoch 3 | Train Loss: 0.1771\n",
      "Epoch 4 | Train Loss: 0.1702\n",
      "Epoch 5 | Train Loss: 0.1642\n",
      "Epoch 6 | Train Loss: 0.1581\n",
      "Epoch 7 | Train Loss: 0.1529\n",
      "Epoch 8 | Train Loss: 0.1479\n",
      "\n",
      "[Best Thresholds per label]\n",
      "$$$: 0.20\n",
      "Amber: 0.28\n",
      "Aromatic: 0.20\n",
      "Blossom: 0.20\n",
      "Bouquet: 0.20\n",
      "Carnation: 0.20\n",
      "Citrus: 0.24\n",
      "Classical: 0.24\n",
      "Crisp: 0.20\n",
      "Dry: 0.20\n",
      "Floral: 0.30\n",
      "Flower: 0.20\n",
      "Fougère: 0.22\n",
      "Fresh: 0.20\n",
      "Fresher: 0.30\n",
      "Fruity: 0.20\n",
      "Gardenia: 0.20\n",
      "Gourmand: 0.20\n",
      "Green: 0.20\n",
      "Honeysuckle: 0.20\n",
      "Iris: 0.20\n",
      "Jasmine: 0.20\n",
      "Lilac: 0.20\n",
      "Lily: 0.20\n",
      "Magnolia: 0.20\n",
      "Mimosa: 0.20\n",
      "Mossy: 0.20\n",
      "Musk: 0.20\n",
      "Orange: 0.20\n",
      "Oriental: 0.20\n",
      "Rich: 0.20\n",
      "Richer: 0.20\n",
      "Rose: 0.20\n",
      "Soft: 0.20\n",
      "Spicy: 0.20\n",
      "Tuberose: 0.20\n",
      "Valley: 0.20\n",
      "Violet: 0.20\n",
      "Water: 0.20\n",
      "White: 0.20\n",
      "Woods: 0.22\n",
      "Woody: 0.20\n",
      "info: 0.20\n",
      "of: 0.20\n",
      "the: 0.20\n",
      "\n",
      "=== Threshold-based ===\n",
      "Micro-F1: 0.4926\n",
      "Macro-F1: 0.1344\n",
      "Sample-F1: 0.4951\n",
      "\n",
      "[classification_report @thr]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         $$$       0.00      0.00      0.00         1\n",
      "       Amber       0.48      0.74      0.58      1744\n",
      "    Aromatic       0.32      0.59      0.42       420\n",
      "     Blossom       0.00      0.00      0.00        26\n",
      "     Bouquet       0.00      0.00      0.00        39\n",
      "   Carnation       0.00      0.00      0.00         1\n",
      "      Citrus       0.33      0.52      0.40       993\n",
      "   Classical       0.35      0.63      0.45      1171\n",
      "       Crisp       0.28      0.32      0.30       896\n",
      "         Dry       0.44      0.22      0.30       251\n",
      "      Floral       0.69      0.77      0.73      2193\n",
      "      Flower       0.26      0.04      0.08       340\n",
      "     Fougère       0.33      0.57      0.41       420\n",
      "       Fresh       0.00      0.00      0.00        25\n",
      "     Fresher       0.60      0.91      0.73      2918\n",
      "      Fruity       0.33      0.66      0.44       961\n",
      "    Gardenia       0.00      0.00      0.00        10\n",
      "    Gourmand       0.75      0.02      0.03       340\n",
      "       Green       0.00      0.00      0.00       308\n",
      " Honeysuckle       0.00      0.00      0.00         0\n",
      "        Iris       0.00      0.00      0.00        31\n",
      "     Jasmine       0.00      0.00      0.00        22\n",
      "       Lilac       0.00      0.00      0.00         1\n",
      "        Lily       0.00      0.00      0.00        10\n",
      "    Magnolia       0.00      0.00      0.00         6\n",
      "      Mimosa       0.00      0.00      0.00         1\n",
      "       Mossy       0.00      0.00      0.00       255\n",
      "        Musk       0.00      0.00      0.00       109\n",
      "      Orange       0.00      0.00      0.00        26\n",
      "    Oriental       0.00      0.00      0.00         5\n",
      "        Rich       0.00      0.00      0.00        48\n",
      "      Richer       0.00      0.00      0.00       194\n",
      "        Rose       0.26      0.22      0.24       153\n",
      "        Soft       0.20      0.07      0.10       563\n",
      "       Spicy       0.00      0.00      0.00        43\n",
      "    Tuberose       0.00      0.00      0.00        21\n",
      "      Valley       0.00      0.00      0.00         7\n",
      "      Violet       0.00      0.00      0.00         8\n",
      "       Water       0.15      0.02      0.04       184\n",
      "       White       0.16      0.01      0.02       340\n",
      "       Woods       0.32      0.71      0.44      1099\n",
      "       Woody       0.26      0.53      0.35       691\n",
      "        info       0.00      0.00      0.00         1\n",
      "          of       0.00      0.00      0.00         7\n",
      "         the       0.00      0.00      0.00         7\n",
      "\n",
      "   micro avg       0.43      0.57      0.49     16889\n",
      "   macro avg       0.14      0.17      0.13     16889\n",
      "weighted avg       0.41      0.57      0.45     16889\n",
      " samples avg       0.45      0.58      0.50     16889\n",
      "\n",
      "\n",
      "=== Top-K-based ===\n",
      "Micro-F1: 0.4808\n",
      "Macro-F1: 0.1086\n",
      "Sample-F1: 0.4805\n",
      "\n",
      "[Example Prediction]\n",
      "['Citrus', 'Floral', 'Fresher', 'Fruity']\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# MiniLM 임베딩 + AutoModelForSequenceClassification + Threshold 최적화 + Epoch 8\n",
    "# ============================================\n",
    "\n",
    "import os, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "\n",
    "# -------------------------------\n",
    "# 설정\n",
    "# -------------------------------\n",
    "DATA_CSV = \"perfumes_huggingface.csv\"\n",
    "MODEL_NAME = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "TOP_K = 3\n",
    "RARE_MIN_COUNT = 7\n",
    "MAX_LEN = 384\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 8\n",
    "LR = 1e-5\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"[Device] {device}\")\n",
    "\n",
    "# -------------------------------\n",
    "# 유틸 함수\n",
    "# -------------------------------\n",
    "def split_labels(s: str):\n",
    "    s = str(s)\n",
    "    for sep in [\",\", \"|\", \"/\", \";\"]:\n",
    "        s = s.replace(sep, \" \")\n",
    "    return [t.strip() for t in s.split() if t.strip()]\n",
    "\n",
    "# -------------------------------\n",
    "# 1) 데이터 로드 & 전처리\n",
    "# -------------------------------\n",
    "df = pd.read_csv(DATA_CSV, sep=\"|\", engine=\"python\", on_bad_lines=\"skip\")\n",
    "df = df[~df[\"description\"].isna()].copy()\n",
    "df[\"labels\"] = df[\"fragrances\"].apply(split_labels)\n",
    "\n",
    "cnt = Counter([l for L in df[\"labels\"] for l in L])\n",
    "rare = {k for k, v in cnt.items() if v <= RARE_MIN_COUNT}\n",
    "df[\"labels\"] = df[\"labels\"].apply(lambda L: [l for l in L if l not in rare])\n",
    "df = df[df[\"labels\"].map(len) > 0].copy()\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "Y = mlb.fit_transform(df[\"labels\"])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_text, X_val_text, y_train, y_val = train_test_split(\n",
    "    df[\"description\"].tolist(), Y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# 2) 토크나이저 및 데이터셋\n",
    "# -------------------------------\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "class PerfumeDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.encodings = tokenizer(texts, padding=True, truncation=True, max_length=MAX_LEN, return_tensors=\"pt\")\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = PerfumeDataset(X_train_text, y_train)\n",
    "val_dataset = PerfumeDataset(X_val_text, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "# -------------------------------\n",
    "# 3) 모델 & 옵티마이저\n",
    "# -------------------------------\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=Y.shape[1],\n",
    "    problem_type=\"multi_label_classification\"\n",
    ").to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=LR)\n",
    "loss_fn = BCEWithLogitsLoss()\n",
    "\n",
    "# -------------------------------\n",
    "# 4) 학습 루프\n",
    "# -------------------------------\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        inputs = {k: v.to(device) for k, v in batch.items() if k != \"labels\"}\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        loss = loss_fn(outputs.logits, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | Train Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# -------------------------------\n",
    "# 5) 검증 예측 & Threshold 최적화\n",
    "# -------------------------------\n",
    "model.eval()\n",
    "all_logits, all_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        inputs = {k: v.to(device) for k, v in batch.items() if k != \"labels\"}\n",
    "        labels = batch[\"labels\"].cpu().numpy()\n",
    "        outputs = model(**inputs).logits.cpu().numpy()\n",
    "        all_logits.append(outputs)\n",
    "        all_labels.append(labels)\n",
    "\n",
    "y_val_proba = torch.sigmoid(torch.tensor(np.vstack(all_logits))).numpy()\n",
    "y_val = np.vstack(all_labels)\n",
    "\n",
    "thresholds = {}\n",
    "y_val_pred_opt = np.zeros_like(y_val)\n",
    "\n",
    "for i, label in enumerate(mlb.classes_):\n",
    "    best_thr, best_f1 = 0.5, -1\n",
    "    for thr in np.linspace(0.2, 0.5, 16):\n",
    "        pred = (y_val_proba[:, i] >= thr).astype(int)\n",
    "        f1 = f1_score(y_val[:, i], pred, zero_division=0)\n",
    "        if f1 > best_f1:\n",
    "            best_thr, best_f1 = thr, f1\n",
    "    thresholds[label] = best_thr\n",
    "    y_val_pred_opt[:, i] = (y_val_proba[:, i] >= best_thr).astype(int)\n",
    "\n",
    "print(\"\\n[Best Thresholds per label]\")\n",
    "for k, v in thresholds.items():\n",
    "    print(f\"{k}: {v:.2f}\")\n",
    "\n",
    "# -------------------------------\n",
    "# 6) 평가\n",
    "# -------------------------------\n",
    "print(\"\\n=== Threshold-based ===\")\n",
    "print(f\"Micro-F1: {f1_score(y_val, y_val_pred_opt, average='micro'):.4f}\")\n",
    "print(f\"Macro-F1: {f1_score(y_val, y_val_pred_opt, average='macro'):.4f}\")\n",
    "print(f\"Sample-F1: {f1_score(y_val, y_val_pred_opt, average='samples'):.4f}\")\n",
    "print(\"\\n[classification_report @thr]\")\n",
    "print(classification_report(y_val, y_val_pred_opt, target_names=mlb.classes_, zero_division=0))\n",
    "\n",
    "# Top-K 기반 예측도 비교\n",
    "topk_preds = np.argsort(-y_val_proba, axis=1)[:, :TOP_K]\n",
    "topk_bin = np.zeros_like(y_val)\n",
    "for i, preds in enumerate(topk_preds):\n",
    "    topk_bin[i, preds] = 1\n",
    "\n",
    "print(\"\\n=== Top-K-based ===\")\n",
    "print(f\"Micro-F1: {f1_score(y_val, topk_bin, average='micro'):.4f}\")\n",
    "print(f\"Macro-F1: {f1_score(y_val, topk_bin, average='macro'):.4f}\")\n",
    "print(f\"Sample-F1: {f1_score(y_val, topk_bin, average='samples'):.4f}\")\n",
    "\n",
    "# -------------------------------\n",
    "# 7) 예측 함수\n",
    "# -------------------------------\n",
    "def predict_multilingual(text: str, topk=3, thresholds=None):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=MAX_LEN).to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "        proba = torch.sigmoid(logits).cpu().numpy()[0]\n",
    "\n",
    "    if thresholds is not None:\n",
    "        pick = [i for i, p in enumerate(proba) if p >= thresholds.get(mlb.classes_[i], 0.5)]\n",
    "        if not pick:\n",
    "            pick = np.argsort(-proba)[:topk]\n",
    "    else:\n",
    "        pick = np.argsort(-proba)[:topk]\n",
    "\n",
    "    return [mlb.classes_[i] for i in pick]\n",
    "\n",
    "# -------------------------------\n",
    "# 예시 실행\n",
    "# -------------------------------\n",
    "print(\"\\n[Example Prediction]\")\n",
    "print(predict_multilingual(\"바닷가에서 느껴지는 시원하고 약간 달콤한 향이 좋아요\", topk=3, thresholds=thresholds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdb7b7b9-cb09-415b-9599-d1ca0bbc5929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Example Prediction]\n",
      "['Citrus', 'Floral', 'Fresher', 'Fruity']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[Example Prediction]\")\n",
    "print(predict_multilingual(\"깨끗하게 빨래하고 말린 상쾌한 향\", topk=3, thresholds=thresholds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79d0633f-926b-42f1-bd54-9ea999bee6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Example Prediction]\n",
      "['Citrus', 'Floral', 'Fresher']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[Example Prediction]\")\n",
    "print(predict_multilingual(\"바다향\", topk=3, thresholds=thresholds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
