{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1418f755-2102-4323-8ee5-555d25cb3a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch<3.0,>=2.2 in /usr/local/lib/python3.11/dist-packages (2.8.0.dev20250319+cu128)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.22.0.dev20250319+cu128)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0.dev20250319+cu128)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.2) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.2) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.2) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.2) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.2) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.2) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.61 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.2) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.57 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.2) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.57 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.2) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.8.0.87 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.2) (9.8.0.87)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.3.14 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.2) (12.8.3.14)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.41 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.2) (11.3.3.41)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.55 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.2) (10.3.9.55)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.2.55 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.2) (11.7.2.55)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.7.53 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.2) (12.5.7.53)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.2) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.25.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.2) (2.25.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.55 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.2) (12.8.55)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.61 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.2) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.0.11 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.2) (1.13.0.11)\n",
      "Requirement already satisfied: pytorch-triton==3.3.0+git96316ce5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.2) (3.3.0+git96316ce5)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-triton==3.3.0+git96316ce5->torch<3.0,>=2.2) (77.0.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.3.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch<3.0,>=2.2) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0,>=2.2) (2.1.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (5.1.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.7.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.3.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.3.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.5.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.55.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.8.0.dev20250319+cu128)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.16.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.34.4)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.0.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.16.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.7.34)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.8)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.61 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.57 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.57 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.8.0.87 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.8.0.87)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.3.14 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.8.3.14)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.41 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.3.41)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.55 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.9.55)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.2.55 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.2.55)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.7.53 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.7.53)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.25.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.25.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.55 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.8.55)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.61 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.0.11 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.0.11)\n",
      "Requirement already satisfied: pytorch-triton==3.3.0+git96316ce5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3.0+git96316ce5)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-triton==3.3.0+git96316ce5->torch>=1.11.0->sentence-transformers) (77.0.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.1.31)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python -m pip install -U \"torch>=2.2,<3.0\" torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "!python -m pip install -U sentence-transformers scikit-learn pandas numpy joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61bc15c1-c600-432b-87ac-35b39353f661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Device] cuda | Torch CUDA available: True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22510cbdb97048d08004ee913f182033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/341 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a22abb8dbef40e4baad26207a46ac98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a1cafe86f894e7c9dd8c8598e037a04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bab3a3966bf543c086160682f92e348d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6672b1fb93764d51b54f1c0ad329c52e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/610 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f139b2174764a358f7e7485e992cc0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/539M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc03f3dfefa2477b97d2d15d9d05fd8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/531 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8c74f15059e4aca8993207f9c927de7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c63ad336526043fab068fdc86c581002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1da5a9027fbc486885e1e1a4dc88caa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d5d38769ffc478c9d06e441586cbddd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "732dededdc4f40739774f2d6cf76dd99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/114 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "106e97598d4c4899b24ec6e00d37b245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "2_Dense/model.safetensors:   0%|          | 0.00/1.58M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Embed] train: (21001, 512) | time: 17.16s | thru: 1223.8/s\n",
      "[Embed] valid: (5251, 512) | time: 4.25s | thru: 1236.3/s\n",
      "[Train] OvR-LogReg: 59.70s\n",
      "\n",
      "=== Threshold-based ===\n",
      "Micro-F1: 0.3211\n",
      "Macro-F1: 0.1823\n",
      "Sample-F1: 0.3262\n",
      "\n",
      "[classification_report @thr]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Amber       0.40      0.88      0.55      1738\n",
      "    Aromatic       0.19      0.86      0.31       450\n",
      "     Blossom       0.02      0.44      0.04        25\n",
      "     Bouquet       0.02      0.57      0.04        47\n",
      "   Carnation       0.00      0.00      0.00         2\n",
      "      Citrus       0.22      0.85      0.35       981\n",
      "   Classical       0.31      0.84      0.45      1313\n",
      "       Crisp       0.19      0.87      0.32       858\n",
      "         Dry       0.09      0.83      0.16       260\n",
      "      Floral       0.59      0.88      0.71      2141\n",
      "      Flower       0.09      0.81      0.17       329\n",
      "     Fougère       0.19      0.86      0.31       450\n",
      "       Fresh       0.01      0.23      0.01        22\n",
      "     Fresher       0.59      0.87      0.71      2838\n",
      "      Fruity       0.24      0.86      0.37       899\n",
      "    Gardenia       0.02      0.80      0.04         5\n",
      "    Gourmand       0.11      0.79      0.19       326\n",
      "       Green       0.08      0.76      0.15       314\n",
      "        Iris       0.03      0.58      0.06        36\n",
      "     Jasmine       0.09      0.56      0.15        36\n",
      "        Lily       0.02      0.62      0.04         8\n",
      "    Magnolia       0.06      0.75      0.11         4\n",
      "      Mimosa       0.10      0.29      0.15         7\n",
      "       Mossy       0.06      0.76      0.11       251\n",
      "        Musk       0.03      0.55      0.06        82\n",
      "      Orange       0.02      0.44      0.04        25\n",
      "    Oriental       0.00      0.00      0.00         1\n",
      "        Rich       0.01      0.49      0.03        41\n",
      "      Richer       0.06      0.83      0.11       179\n",
      "        Rose       0.13      0.82      0.22       182\n",
      "        Soft       0.12      0.84      0.21       489\n",
      "       Spicy       0.02      0.67      0.04        42\n",
      "    Tuberose       0.03      0.46      0.06        26\n",
      "      Valley       0.02      0.50      0.03         6\n",
      "      Violet       0.05      0.75      0.09         4\n",
      "       Water       0.07      0.80      0.14       166\n",
      "       White       0.09      0.81      0.17       329\n",
      "       Woods       0.28      0.88      0.43      1138\n",
      "       Woody       0.19      0.86      0.31       683\n",
      "          of       0.02      0.50      0.03         6\n",
      "         the       0.02      0.50      0.03         6\n",
      "\n",
      "   micro avg       0.20      0.85      0.32     16745\n",
      "   macro avg       0.12      0.66      0.18     16745\n",
      "weighted avg       0.33      0.85      0.45     16745\n",
      " samples avg       0.21      0.85      0.33     16745\n",
      "\n",
      "\n",
      "=== Top-K-based ===\n",
      "Micro-F1: 0.3105\n",
      "Macro-F1: 0.2028\n",
      "Sample-F1: 0.3085\n",
      "\n",
      "[classification_report @topK]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Amber       0.58      0.27      0.37      1738\n",
      "    Aromatic       0.34      0.53      0.42       450\n",
      "     Blossom       0.05      0.32      0.09        25\n",
      "     Bouquet       0.04      0.28      0.06        47\n",
      "   Carnation       0.00      0.00      0.00         2\n",
      "      Citrus       0.43      0.25      0.31       981\n",
      "   Classical       0.44      0.24      0.31      1313\n",
      "       Crisp       0.35      0.24      0.29       858\n",
      "         Dry       0.17      0.34      0.23       260\n",
      "      Floral       0.76      0.50      0.60      2141\n",
      "      Flower       0.14      0.21      0.17       329\n",
      "     Fougère       0.32      0.57      0.41       450\n",
      "       Fresh       0.01      0.14      0.02        22\n",
      "     Fresher       0.72      0.19      0.30      2838\n",
      "      Fruity       0.43      0.33      0.37       899\n",
      "    Gardenia       0.06      0.60      0.11         5\n",
      "    Gourmand       0.21      0.40      0.27       326\n",
      "       Green       0.18      0.27      0.22       314\n",
      "        Iris       0.08      0.50      0.14        36\n",
      "     Jasmine       0.20      0.36      0.25        36\n",
      "        Lily       0.08      0.50      0.14         8\n",
      "    Magnolia       0.08      0.25      0.12         4\n",
      "      Mimosa       0.29      0.29      0.29         7\n",
      "       Mossy       0.10      0.18      0.13       251\n",
      "        Musk       0.05      0.27      0.09        82\n",
      "      Orange       0.06      0.32      0.10        25\n",
      "    Oriental       0.00      0.00      0.00         1\n",
      "        Rich       0.01      0.15      0.03        41\n",
      "      Richer       0.09      0.28      0.13       179\n",
      "        Rose       0.34      0.60      0.44       182\n",
      "        Soft       0.25      0.21      0.23       489\n",
      "       Spicy       0.04      0.43      0.07        42\n",
      "    Tuberose       0.11      0.35      0.17        26\n",
      "      Valley       0.00      0.00      0.00         6\n",
      "      Violet       0.12      0.50      0.20         4\n",
      "       Water       0.17      0.54      0.25       166\n",
      "       White       0.15      0.15      0.15       329\n",
      "       Woods       0.45      0.23      0.31      1138\n",
      "       Woody       0.30      0.29      0.30       683\n",
      "          of       0.05      0.50      0.10         6\n",
      "         the       0.07      0.50      0.13         6\n",
      "\n",
      "   micro avg       0.32      0.30      0.31     16745\n",
      "   macro avg       0.20      0.32      0.20     16745\n",
      "weighted avg       0.47      0.30      0.34     16745\n",
      " samples avg       0.32      0.31      0.31     16745\n",
      "\n",
      "\n",
      "[Example Prediction]\n",
      "['Water', 'Crisp', 'Fresher']\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 설치 (Runpod A40 / 로컬)\n",
    "# ============================================\n",
    "# CPU 전용\n",
    "# python -m pip install -U sentence-transformers \"torch>=2.2,<3.0\" scikit-learn pandas numpy joblib\n",
    "\n",
    "# GPU (CUDA 12.1, Runpod A40)\n",
    "# python -m pip install -U \"torch>=2.2,<3.0\" torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "# python -m pip install -U sentence-transformers scikit-learn pandas numpy joblib\n",
    "# ============================================\n",
    "\n",
    "import os, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# -------------------------------\n",
    "# 설정\n",
    "# -------------------------------\n",
    "DATA_CSV = \"perfumes_huggingface.csv\"  # 경로 맞게 수정\n",
    "MODEL_NAME = \"distiluse-base-multilingual-cased-v2\"  # 또는 \"paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "THRESHOLD = 0.35\n",
    "TOP_K = 3\n",
    "RARE_MIN_COUNT = 10  # <= 이하면 제거 (5~30 튜닝 권장)\n",
    "\n",
    "# -------------------------------\n",
    "# 유틸\n",
    "# -------------------------------\n",
    "def split_labels(s: str):\n",
    "    s = str(s)\n",
    "    for sep in [\",\", \"|\", \"/\", \";\"]:\n",
    "        s = s.replace(sep, \" \")\n",
    "    return [t.strip() for t in s.split() if t.strip()]\n",
    "\n",
    "def encode_with_auto_batch(embedder: SentenceTransformer, texts, init_bs=1024, min_bs=64):\n",
    "    \"\"\"\n",
    "    CUDA OOM 시 배치 크기를 절반으로 줄여가며 재시도.\n",
    "    GPU면 큰 배치로 빠르게, CPU면 init_bs를 작게 설정 권장.\n",
    "    \"\"\"\n",
    "    bs = init_bs\n",
    "    Xs = []\n",
    "    i = 0\n",
    "    n = len(texts)\n",
    "    while i < n:\n",
    "        j = min(i + bs, n)\n",
    "        chunk = texts[i:j]\n",
    "        try:\n",
    "            emb = embedder.encode(chunk, batch_size=bs, convert_to_numpy=True, show_progress_bar=False)\n",
    "            Xs.append(emb)\n",
    "            i = j\n",
    "        except RuntimeError as e:\n",
    "            if \"CUDA out of memory\" in str(e) and bs > min_bs:\n",
    "                torch.cuda.empty_cache()\n",
    "                bs = max(min_bs, bs // 2)\n",
    "                print(f\"[WARN] CUDA OOM → batch_size 축소: {bs}\")\n",
    "                continue\n",
    "            raise\n",
    "    return np.vstack(Xs)\n",
    "\n",
    "# -------------------------------\n",
    "# 1) 데이터 로드 & 전처리\n",
    "# -------------------------------\n",
    "df = pd.read_csv(DATA_CSV, sep=\"|\", engine=\"python\", on_bad_lines=\"skip\")\n",
    "df = df[~df[\"description\"].isna()].copy()\n",
    "df[\"labels\"] = df[\"fragrances\"].apply(split_labels)\n",
    "\n",
    "# 희소 라벨 제거\n",
    "cnt = Counter([l for L in df[\"labels\"] for l in L])\n",
    "rare = {k for k, v in cnt.items() if v <= RARE_MIN_COUNT}\n",
    "df[\"labels\"] = df[\"labels\"].apply(lambda L: [l for l in L if l not in rare])\n",
    "df = df[df[\"labels\"].map(len) > 0].copy()\n",
    "\n",
    "# 타깃 인코딩\n",
    "mlb = MultiLabelBinarizer()\n",
    "Y = mlb.fit_transform(df[\"labels\"])\n",
    "\n",
    "# -------------------------------\n",
    "# 2) 데이터 분할 (다중라벨 → stratify 사용 X)\n",
    "# -------------------------------\n",
    "X_train_text, X_val_text, y_train, y_val = train_test_split(\n",
    "    df[\"description\"].tolist(), Y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# 3) 디바이스 & 임베더\n",
    "# -------------------------------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"[Device] {device} | Torch CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "embedder = SentenceTransformer(MODEL_NAME, device=device)\n",
    "\n",
    "# GPU면 큰 배치, CPU면 작은 배치\n",
    "init_bs = 1024 if device == \"cuda\" else 128\n",
    "\n",
    "# -------------------------------\n",
    "# 4) 임베딩 (자동 배치 조절 + 벤치마킹)\n",
    "# -------------------------------\n",
    "t0 = time.perf_counter()\n",
    "X_train = encode_with_auto_batch(embedder, X_train_text, init_bs=init_bs, min_bs=64)\n",
    "t1 = time.perf_counter()\n",
    "print(f\"[Embed] train: {X_train.shape} | time: {t1 - t0:.2f}s | thru: {len(X_train_text)/(t1-t0+1e-9):.1f}/s\")\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "X_val = encode_with_auto_batch(embedder, X_val_text, init_bs=init_bs, min_bs=64)\n",
    "t1 = time.perf_counter()\n",
    "print(f\"[Embed] valid: {X_val.shape} | time: {t1 - t0:.2f}s | thru: {len(X_val_text)/(t1-t0+1e-9):.1f}/s\")\n",
    "\n",
    "# -------------------------------\n",
    "# 5) 분류기 학습 (CPU 기반)\n",
    "# -------------------------------\n",
    "clf = OneVsRestClassifier(\n",
    "    LogisticRegression(max_iter=2000, C=2.0, class_weight=\"balanced\")\n",
    ")\n",
    "t0 = time.perf_counter()\n",
    "clf.fit(X_train, y_train)\n",
    "t1 = time.perf_counter()\n",
    "print(f\"[Train] OvR-LogReg: {t1 - t0:.2f}s\")\n",
    "\n",
    "# -------------------------------\n",
    "# 6) 검증 평가 (임계값 & Top-K)\n",
    "# -------------------------------\n",
    "try:\n",
    "    y_val_proba = clf.predict_proba(X_val)\n",
    "except Exception:\n",
    "    scores = clf.decision_function(X_val)\n",
    "    y_val_proba = 1 / (1 + np.exp(-scores))\n",
    "\n",
    "# 임계값\n",
    "y_val_thr = (y_val_proba >= THRESHOLD).astype(int)\n",
    "print(\"\\n=== Threshold-based ===\")\n",
    "print(f\"Micro-F1: {f1_score(y_val, y_val_thr, average='micro'):.4f}\")\n",
    "print(f\"Macro-F1: {f1_score(y_val, y_val_thr, average='macro'):.4f}\")\n",
    "print(f\"Sample-F1: {f1_score(y_val, y_val_thr, average='samples'):.4f}\")\n",
    "print(\"\\n[classification_report @thr]\")\n",
    "print(classification_report(y_val, y_val_thr, target_names=mlb.classes_, zero_division=0))\n",
    "\n",
    "# Top-K\n",
    "top_idx = np.argsort(-y_val_proba, axis=1)[:, :TOP_K]\n",
    "y_val_topk = np.zeros_like(y_val_proba, dtype=int)\n",
    "for i, idxs in enumerate(top_idx):\n",
    "    y_val_topk[i, idxs] = 1\n",
    "\n",
    "print(\"\\n=== Top-K-based ===\")\n",
    "print(f\"Micro-F1: {f1_score(y_val, y_val_topk, average='micro'):.4f}\")\n",
    "print(f\"Macro-F1: {f1_score(y_val, y_val_topk, average='macro'):.4f}\")\n",
    "print(f\"Sample-F1: {f1_score(y_val, y_val_topk, average='samples'):.4f}\")\n",
    "print(\"\\n[classification_report @topK]\")\n",
    "print(classification_report(y_val, y_val_topk, target_names=mlb.classes_, zero_division=0))\n",
    "\n",
    "# -------------------------------\n",
    "# 7) 예측 함수 (한국어/영어 입력 그대로)\n",
    "# -------------------------------\n",
    "def predict_multilingual(text: str, topk=3, threshold=None):\n",
    "    v = encode_with_auto_batch(embedder, [text], init_bs=64 if device==\"cpu\" else 256, min_bs=32)\n",
    "    try:\n",
    "        proba = clf.predict_proba(v)[0]\n",
    "    except Exception:\n",
    "        score = clf.decision_function(v)[0]\n",
    "        proba = 1 / (1 + np.exp(-score))\n",
    "    if threshold is not None:\n",
    "        pick = np.where(proba >= threshold)[0]\n",
    "    else:\n",
    "        pick = np.argsort(-proba)[:topk]\n",
    "    return [mlb.classes_[i] for i in pick]\n",
    "\n",
    "# 예시\n",
    "print(\"\\n[Example Prediction]\")\n",
    "print(predict_multilingual(\"바닷가에서 느껴지는 시원하고 약간 달콤한 향이 좋아요\", topk=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e26373a2-714f-4fc8-83d1-91bcd67e9cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Example Prediction]\n",
      "['Soft', 'Water', 'Crisp']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[Example Prediction]\")\n",
    "print(predict_multilingual(\"깨끗하게 빨래하고 말린 상쾌한 향\", topk=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4595165d-70e0-4770-ba34-8114bb7a22d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Example Prediction]\n",
      "['Water', 'Aromatic', 'Fougère']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[Example Prediction]\")\n",
    "print(predict_multilingual(\"바다향\", topk=3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
