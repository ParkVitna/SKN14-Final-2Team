{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f07a12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28a476c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perfume_final columns: ['brand', 'name', 'eng_name', 'size_ml', 'price_krw', 'detail_url', 'concentration', 'main_accords', 'top_notes', 'middle_notes', 'base_notes', 'description', 'notes_score', 'season_score', 'day_night_score']\n",
      "perfumes_hf columns: ['brand', 'name', 'family', 'subfamily', 'fragrances', 'ingredients', 'origin', 'gender', 'years', 'description', 'image_name,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === 1. 데이터 로드 ===\n",
    "final_path = \"perfume_final(부향률_용어_통일).csv\"\n",
    "hf_path = \"C:\\\\Workspaces\\\\SKN14-Final-2Team\\\\Seong9\\\\deep_learning\\\\data_preprocessing\\\\perfumes_hf.csv\"\n",
    "output_path = \"perfume_final(_with_gender).csv\"\n",
    "\n",
    "\n",
    "\n",
    "df_hf = pd.read_csv(\n",
    "    hf_path, sep=\"|\", encoding=\"utf-8-sig\", engine=\"python\",\n",
    "    on_bad_lines=\"skip\"\n",
    ")\n",
    "df_final = pd.read_csv(final_path, encoding=\"utf-8-sig\")\n",
    "\n",
    "\n",
    "print(\"perfume_final columns:\", df_final.columns.tolist())\n",
    "print(\"perfumes_hf columns:\", df_hf.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0003641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 2. 키 정규화 ===\n",
    "def norm(s): return s.astype(str).str.strip().str.replace(r\"\\s+\",\" \",regex=True).str.lower()\n",
    "df_final[\"__key\"] = norm(df_final[\"eng_name\"])\n",
    "df_hf = df_hf.rename(columns={\"name\":\"eng_name\"})\n",
    "df_hf[\"__key\"] = norm(df_hf[\"eng_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "684ec4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 저장 완료: perfume_final(_with_gender).csv\n",
      "  brand          name  eng_name  size_ml  price_krw  \\\n",
      "0   크리드   어벤투스 오 드 퍼퓸   Aventus       50     255000   \n",
      "1   크리드   어벤투스 오 드 퍼퓸   Aventus      100     399220   \n",
      "2  톰 포드  오드 우드 오 드 퍼퓸  Eau Wood       30     179000   \n",
      "3  톰 포드  오드 우드 오 드 퍼퓸  Eau Wood       50     249000   \n",
      "4    이솝     테싯 오 드 퍼퓸     Tecit       50     135000   \n",
      "\n",
      "                                  detail_url concentration  \\\n",
      "0   https://www.bysuco.com/product/show/9370        오 드 퍼퓸   \n",
      "1   https://www.bysuco.com/product/show/9370        오 드 퍼퓸   \n",
      "2  https://www.bysuco.com/product/show/10716        오 드 퍼퓸   \n",
      "3  https://www.bysuco.com/product/show/10716        오 드 퍼퓸   \n",
      "4   https://www.bysuco.com/product/show/9970        오 드 퍼퓸   \n",
      "\n",
      "         main_accords                top_notes      middle_notes  \\\n",
      "0          프루티 스위트 레더  베르가못 블랙 커런트 애플 레몬 핑크 페퍼  파인애플 패출리 모로칸 자스민   \n",
      "1          프루티 스위트 레더  베르가못 블랙 커런트 애플 레몬 핑크 페퍼  파인애플 패출리 모로칸 자스민   \n",
      "2       우디 오우드 웜 스파이시                      NaN               NaN   \n",
      "3       우디 오우드 웜 스파이시                      NaN               NaN   \n",
      "4  시트러스 아로마틱 프레쉬 스파이시                  유자 시트러스                바질   \n",
      "\n",
      "                 base_notes                             description  \\\n",
      "0  자작나무 머스크 오크 모스 암브록산 시더우드             용기와 힘 비전 그리고 성공을 기원하는 고급진 향   \n",
      "1  자작나무 머스크 오크 모스 암브록산 시더우드             용기와 힘 비전 그리고 성공을 기원하는 고급진 향   \n",
      "2                       NaN  청량한 소나무 계열의 향과 부드러운 침구가 부드럽게 감싸주는 듯한 향   \n",
      "3                       NaN  청량한 소나무 계열의 향과 부드러운 침구가 부드럽게 감싸주는 듯한 향   \n",
      "4                   베티버 클로브  이솝의 시그니처 향기로 따뜻하고 생기넘치며 마음을 릴렉싱 시켜주는 향   \n",
      "\n",
      "                                         notes_score  \\\n",
      "0  fruity(100.0) / sweet(68.4) / woody(66.0) / le...   \n",
      "1  fruity(100.0) / sweet(68.4) / woody(66.0) / le...   \n",
      "2  warm spicy(100.0) / woody(92.4) / vanilla(76.1...   \n",
      "3  warm spicy(100.0) / woody(92.4) / vanilla(76.1...   \n",
      "4  citrus(100.0) / aromatic(93.7) / fresh spicy(9...   \n",
      "\n",
      "                                        season_score  \\\n",
      "0  winter(11.2) / spring(11.3) / summer(3.5) / fa...   \n",
      "1  winter(11.2) / spring(11.3) / summer(3.5) / fa...   \n",
      "2  winter(14.0) / spring(6.5) / summer(31.8) / fa...   \n",
      "3  winter(14.0) / spring(6.5) / summer(31.8) / fa...   \n",
      "4  winter(28.1) / spring(10.5) / summer(3.1) / fa...   \n",
      "\n",
      "            day_night_score gender  \n",
      "0   day(97.5) / night(99.3)   Male  \n",
      "1   day(97.5) / night(99.3)   Male  \n",
      "2   day(70.5) / night(30.1)    NaN  \n",
      "3   day(70.5) / night(30.1)    NaN  \n",
      "4  day(93.4) / night(100.0)    NaN  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# === 3. 이름 정규화 ===\n",
    "def norm(s):\n",
    "    return (s.astype(str).str.strip()\n",
    "                     .str.replace(r\"\\s+\",\" \",regex=True)\n",
    "                     .str.lower())\n",
    "\n",
    "# === 4.키 만들기 (final, hf 모두) === \n",
    "df_final[\"__key\"] = norm(df_final[\"eng_name\"])\n",
    "df_hf2 = df_hf.rename(columns={\"name\":\"eng_name\"}).copy()\n",
    "df_hf2[\"__key\"] = norm(df_hf2[\"eng_name\"])\n",
    "\n",
    "# === 5.hf를 이름별 대표 gender로 축약 (최빈값) === \n",
    "def mode_or_nan(s):\n",
    "    x = s.dropna()\n",
    "    if x.empty: return np.nan\n",
    "    vc = x.value_counts()\n",
    "    return sorted(vc[vc.eq(vc.max())].index)[0]\n",
    "\n",
    "hf_key_gender = df_hf2.groupby(\"__key\", as_index=False)[\"gender\"].agg(mode_or_nan)\n",
    "\n",
    "# === 6. many-to-one 병합 ===\n",
    "df_merge = (df_final\n",
    "            .merge(hf_key_gender, on=\"__key\", how=\"left\", validate=\"m:1\")\n",
    "            .drop(columns=\"__key\"))\n",
    "\n",
    "# === 7. 저장 ===\n",
    "df_merge.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"✅ 저장 완료: {output_path}\")\n",
    "print(df_merge.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "846349c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perfumes_gender columns: ['brand', 'name', 'eng_name', 'size_ml', 'price_krw', 'detail_url', 'concentration', 'main_accords', 'top_notes', 'middle_notes', 'base_notes', 'description', 'notes_score', 'season_score', 'day_night_score', 'gender']\n",
      "gender 결측치 개수: 935\n"
     ]
    }
   ],
   "source": [
    "# === 8. 병합물 데이터 확인 ===\n",
    "df_gender = pd.read_csv(output_path, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"perfumes_gender columns:\", df_gender.columns.tolist())\n",
    "\n",
    "\n",
    "missing_count = df_gender[\"gender\"].isna().sum()\n",
    "print(\"gender 결측치 개수:\", missing_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95e131e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 저장 완료: C:\\Workspaces\\SKN14-Final-2Team\\Seong9\\perfume_final_gender_filled_all.csv\n",
      "채워진 gender: 643/1395 (46.1%)\n"
     ]
    }
   ],
   "source": [
    "# === Jupyter 전용: 브랜드 매핑 + 단계적 병합 + 경량 퍼지 매칭 ===\n",
    "# 1) 아래 경로 3개만 여러분 환경에 맞게 수정하세요.\n",
    "USER_CSV = r\"C:\\Workspaces\\SKN14-Final-2Team\\Seong9\\perfume_final(_with_gender).csv\"\n",
    "REF_CSV  = r\"C:\\Workspaces\\SKN14-Final-2Team\\Seong9\\deep_learning\\data_preprocessing\\perfumes_hf.csv\"\n",
    "OUT_DIR  = r\"C:\\Workspaces\\SKN14-Final-2Team\\Seong9\"\n",
    "\n",
    "# 2) 퍼지 매칭 임계값 (원하면 조절)\n",
    "FUZZY_AUTO  = 0.90  # 이 이상은 자동 반영\n",
    "FUZZY_REVIEW_FLOOR = 0.80  # 이 이상~AUTO 미만은 검토 리스트로\n",
    "\n",
    "import os, re, unicodedata, pandas as pd, numpy as np\n",
    "from difflib import SequenceMatcher\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------- 유틸 ----------\n",
    "def ensure_path(p: str) -> Path:\n",
    "    path = Path(p)\n",
    "    if not path.exists():\n",
    "        # 폴더/파일 점검 힌트\n",
    "        raise FileNotFoundError(f\"경로 없음: {path}\\n- 디렉토리 존재? {path.parent} -> {path.parent.exists()}\\n- 파일명(띄어쓰기/괄호/대소문자) 다시 확인하세요.\")\n",
    "    return path\n",
    "\n",
    "def sniff_sep_by_head(path: Path, enc=\"utf-8-sig\"):\n",
    "    with open(path, \"r\", encoding=enc, errors=\"replace\") as f:\n",
    "        head = f.readline()\n",
    "    candidates = [(\"|\", head.count(\"|\")), (\",\", head.count(\",\")), (\"\\t\", head.count(\"\\t\")), (\";\", head.count(\";\"))]\n",
    "    candidates.sort(key=lambda x: x[1], reverse=True)\n",
    "    return candidates[0][0] if candidates and candidates[0][1] > 0 else \",\"\n",
    "\n",
    "def load_any_csv(path: Path, prefer_pipe=False):\n",
    "    # utf-8-sig 우선, 실패시 cp949 시도\n",
    "    try:\n",
    "        sep = \"|\" if prefer_pipe else sniff_sep_by_head(path, \"utf-8-sig\")\n",
    "        return pd.read_csv(path, sep=sep, encoding=\"utf-8-sig\", engine=\"python\", on_bad_lines=\"skip\")\n",
    "    except Exception:\n",
    "        sep = \"|\" if prefer_pipe else sniff_sep_by_head(path, \"cp949\")\n",
    "        return pd.read_csv(path, sep=sep, encoding=\"cp949\", engine=\"python\", on_bad_lines=\"skip\")\n",
    "\n",
    "\n",
    "def strip_accents(s: str) -> str:\n",
    "    s = unicodedata.normalize('NFKD', s)\n",
    "    return ''.join(ch for ch in s if not unicodedata.combining(ch))\n",
    "\n",
    "def clean_name(x: str) -> str:\n",
    "    if pd.isna(x): return \"\"\n",
    "    s = str(x)\n",
    "    s = strip_accents(s)\n",
    "    # 괄호 내용/용량/농도 표기 제거\n",
    "    s = re.sub(r\"[\\(\\[\\{].*?[\\)\\]\\}]\", \" \", s)\n",
    "    s = re.sub(r\"\\b\\d+(\\.\\d+)?\\s*(ml|mL|ML|oz|OZ|fl\\.?\\s*oz)\\b\", \" \", s)\n",
    "    s = re.sub(r\"\\b(extrait|edp|edt|edc|parfum|intense|eau\\s*de\\s*parfum|eau\\s*de\\s*toilette|eau\\s*de\\s*cologne)\\b\", \" \", s, flags=re.IGNORECASE)\n",
    "    # 안전 문자만 남기고 공백 정리\n",
    "    s = re.sub(r\"[^\\w\\s\\-&/']\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip().lower()\n",
    "    return s\n",
    "\n",
    "def mode_or_nan(s: pd.Series):\n",
    "    x = s.dropna()\n",
    "    if x.empty: return np.nan\n",
    "    vc = x.value_counts()\n",
    "    return sorted(vc[vc.eq(vc.max())].index)[0]  # 동률이면 사전순\n",
    "\n",
    "def token_overlap_score(a: str, b: str) -> float:\n",
    "    ta, tb = set(a.split()), set(b.split())\n",
    "    if not ta or not tb: return 0.0\n",
    "    inter, union = len(ta & tb), len(ta | tb)\n",
    "    return inter/union\n",
    "\n",
    "# ---------- 실행 ----------\n",
    "USER_CSV = str(ensure_path(USER_CSV))\n",
    "REF_CSV  = str(ensure_path(REF_CSV))\n",
    "OUT_DIR  = str(ensure_path(OUT_DIR))\n",
    "out_csv   = str(Path(OUT_DIR) / \"perfume_final_gender_filled_all.csv\")\n",
    "review_csv= str(Path(OUT_DIR) / \"perfume_gender_review_needed_all.csv\")\n",
    "\n",
    "# 사용자/레퍼런스 로드 (레퍼런스는 파이프 가능성 높음)\n",
    "df_user = load_any_csv(Path(USER_CSV))\n",
    "df_ref  = load_any_csv(Path(REF_CSV), prefer_pipe=True)\n",
    "\n",
    "# 레퍼런스 헤더 정리(마지막 열 이름에 콤마 꼬임 방지)\n",
    "df_ref.columns = [c.split(\",\")[0].strip() for c in df_ref.columns]\n",
    "\n",
    "# 필수 컬럼 확인/선택\n",
    "def pick(df, cands, tag):\n",
    "    for c in cands:\n",
    "        if c in df.columns: return c\n",
    "    raise KeyError(f\"[{tag}] 필요한 컬럼을 찾지 못함. 후보: {cands}\\n현재 컬럼: {df.columns.tolist()}\")\n",
    "\n",
    "user_brand_col = pick(df_user, [\"brand\",\"brand_eng\",\"brand_en\"], \"user\")\n",
    "user_name_col  = pick(df_user, [\"eng_name\",\"name_eng\",\"name_en\",\"name\",\"name_perfume\",\"english_name\"], \"user\")\n",
    "ref_brand_col  = pick(df_ref,  [\"brand\",\"brand_eng\",\"brand_en\"], \"ref\")\n",
    "ref_name_col   = pick(df_ref,  [\"name\",\"name_eng\",\"name_en\",\"name_perfume\",\"english_name\"], \"ref\")\n",
    "if \"gender\" not in df_ref.columns:\n",
    "    raise KeyError(f\"[ref] 'gender' 컬럼 없음. 현재 컬럼: {df_ref.columns.tolist()}\")\n",
    "\n",
    "# --- 브랜드 매핑(초안; 필요시 아래 dict에 추가) ---\n",
    "brand_map = {\n",
    "    \"샤넬\": \"Chanel\", \"디올\": \"Dior\", \"구찌\": \"Gucci\", \"에르메스\": \"Hermès\",\n",
    "    \"메종 마르지엘라\": \"Maison Margiela\", \"톰 포드\": \"Tom Ford\",\n",
    "    \"프레데릭 말\": \"Frédéric Malle\", \"딥티크\": \"Diptyque\", \"조 말론\": \"Jo Malone\",\n",
    "    \"킬리안\": \"Kilian\", \"바이레도\": \"Byredo\", \"이솝\": \"Aesop\", \"르 라보\": \"Le Labo\",\n",
    "    \"겔랑\": \"Guerlain\", \"입생로랑\": \"Yves Saint Laurent\", \"아쿠아 디 파르마\": \"Acqua di Parma\",\n",
    "    \"몽블랑\": \"Montblanc\", \"프라다\": \"Prada\", \"돌체앤가바나\": \"Dolce & Gabbana\",\n",
    "    \"로에베\": \"Loewe\", \"메종 프란시스 커정\": \"Maison Francis Kurkdjian\",\n",
    "}\n",
    "df_user[\"brand_mapped\"] = df_user[user_brand_col].map(brand_map).fillna(df_user[user_brand_col])\n",
    "\n",
    "# 정규화 키 준비\n",
    "df_user[\"_brand_norm\"] = df_user[\"brand_mapped\"].map(clean_name)\n",
    "df_user[\"_name_norm\"]  = df_user[user_name_col].map(clean_name)\n",
    "df_user[\"_key0\"]       = (df_user[\"_brand_norm\"] + \"||\" + df_user[\"_name_norm\"])\n",
    "\n",
    "df_ref[\"_brand_norm\"] = df_ref[ref_brand_col].map(clean_name)\n",
    "df_ref[\"_name_norm\"]  = df_ref[ref_name_col].map(clean_name)\n",
    "df_ref[\"_key0\"]       = (df_ref[\"_brand_norm\"] + \"||\" + df_ref[\"_name_norm\"])\n",
    "\n",
    "# === 안전 병합: 사용자 gender 보존 → 레퍼런스 gender는 별칭으로 머지 ===\n",
    "\n",
    "# 0) 사용자쪽에 gender가 이미 있으면 보존\n",
    "if \"gender\" in df_user.columns:\n",
    "    df_user = df_user.rename(columns={\"gender\": \"gender_orig\"})\n",
    "\n",
    "# 1) brand+name 정확 매칭 (ref 쪽 gender를 'gender_ref'로 명시)\n",
    "ref_gender_by_key = (\n",
    "    df_ref.groupby(\"_key0\", as_index=False)[\"gender\"]\n",
    "          .agg(mode_or_nan)\n",
    "          .rename(columns={\"gender\":\"gender_ref\"})\n",
    ")\n",
    "m1 = df_user.merge(ref_gender_by_key, on=\"_key0\", how=\"left\", validate=\"m:1\")\n",
    "\n",
    "# 2) name-only 정확 매칭(잔여만) — 역시 별칭으로 받아서 채움\n",
    "ref_gender_by_name = (\n",
    "    df_ref.groupby(\"_name_norm\", as_index=False)[\"gender\"]\n",
    "          .agg(mode_or_nan)\n",
    "          .rename(columns={\"gender\":\"gender_ref2\"})\n",
    ")\n",
    "\n",
    "# 채울 그릇 만들기: 우선순위는 key → name\n",
    "m1[\"gender_filled\"] = m1[\"gender_ref\"]\n",
    "mask = m1[\"gender_filled\"].isna()\n",
    "m1.loc[mask, \"gender_filled\"] = (\n",
    "    m1.loc[mask]\n",
    "      .merge(ref_gender_by_name, on=\"_name_norm\", how=\"left\")[\"gender_ref2\"]\n",
    "      .values\n",
    ")\n",
    "\n",
    "# 3) (선택) 퍼지 매칭을 한다면, m1[\"gender_filled\"] 가 NaN인 행만 대상으로 진행하여\n",
    "#    m1.loc[apply_idx, \"gender_filled\"] = ... 형태로 채워 넣으세요.\n",
    "\n",
    "# 4) 최종 정리: 최종 gender 컬럼 확정\n",
    "#    - 기존 사용자 gender가 있었으면 우선 보존본 사용, 없으면 filled 사용\n",
    "if \"gender_orig\" in m1.columns:\n",
    "    # 기존값 우선, 없으면 새로 채운 값\n",
    "    m1[\"gender\"] = m1[\"gender_orig\"].where(m1[\"gender_orig\"].notna(), m1[\"gender_filled\"])\n",
    "else:\n",
    "    m1[\"gender\"] = m1[\"gender_filled\"]\n",
    "\n",
    "# 5) 보조 컬럼 정리\n",
    "drop_cols = [\"gender_ref\", \"gender_ref2\", \"gender_filled\"]\n",
    "m1_final = m1.drop(columns=[c for c in drop_cols if c in m1.columns], errors=\"ignore\")\n",
    "\n",
    "# 6) 저장\n",
    "out_csv = str(Path(OUT_DIR) / \"perfume_final_gender_filled_all.csv\")\n",
    "m1_final.to_csv(out_csv, index=False, encoding=\"utf-8-sig\")\n",
    "print(\"✅ 저장 완료:\", out_csv)\n",
    "\n",
    "# 요약\n",
    "total = len(m1_final)\n",
    "filled = m1_final[\"gender\"].notna().sum()\n",
    "print(f\"채워진 gender: {filled}/{total} ({filled/total:.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2460ef9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 저장 완료: C:\\Workspaces\\SKN14-Final-2Team\\Seong9\\deep_learning\\data_preprocessing\\perfume_final_gender_filled_all.csv\n",
      "검토 필요 목록: C:\\Workspaces\\SKN14-Final-2Team\\Seong9\\deep_learning\\data_preprocessing\\perfume_gender_review_needed_all.csv\n",
      "총 행: 1395\n",
      "최종 gender 채움 비율: 0.5519713261648745\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np, re, unicodedata\n",
    "from difflib import SequenceMatcher\n",
    "from pathlib import Path\n",
    "\n",
    "# === 파일 경로 ===\n",
    "USER_CSV = r\"C:\\Workspaces\\SKN14-Final-2Team\\Seong9\\perfume_final(_with_gender).csv\"\n",
    "REF_CSV  = r\"C:\\Workspaces\\SKN14-Final-2Team\\Seong9\\deep_learning\\data_preprocessing\\perfumes_hf.csv\"\n",
    "OUT_DIR  = r\"C:\\Workspaces\\SKN14-Final-2Team\\Seong9\\deep_learning\\data_preprocessing\"\n",
    "\n",
    "OUT_CSV   = str(Path(OUT_DIR) / \"perfume_final_gender_filled_all.csv\")\n",
    "REVIEW_CSV= str(Path(OUT_DIR) / \"perfume_gender_review_needed_all.csv\")\n",
    "\n",
    "# === 유틸 함수 ===\n",
    "def strip_accents(s: str) -> str:\n",
    "    s = unicodedata.normalize('NFKD', s)\n",
    "    return ''.join(ch for ch in s if not unicodedata.combining(ch))\n",
    "\n",
    "def clean_name(x: str) -> str:\n",
    "    if pd.isna(x): return \"\"\n",
    "    s = str(x)\n",
    "    s = strip_accents(s)\n",
    "    s = re.sub(r\"[\\(\\[\\{].*?[\\)\\]\\}]\", \" \", s)\n",
    "    s = re.sub(r\"\\b\\d+(\\.\\d+)?\\s*(ml|mL|ML|oz|OZ|fl\\.?\\s*oz)\\b\", \" \", s)\n",
    "    s = re.sub(r\"\\b(extrait|edp|edt|edc|parfum|intense|eau\\s*de\\s*parfum|eau\\s*de\\s*toilette|eau\\s*de\\s*cologne)\\b\",\n",
    "               \" \", s, flags=re.IGNORECASE)\n",
    "    s = re.sub(r\"[^\\w\\s\\-&/']\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip().lower()\n",
    "    return s\n",
    "\n",
    "def norm_key(brand, name):\n",
    "    return f\"{clean_name(str(brand))}||{clean_name(str(name))}\"\n",
    "\n",
    "def mode_or_nan(s: pd.Series):\n",
    "    x = s.dropna()\n",
    "    if x.empty: return np.nan\n",
    "    vc = x.value_counts()\n",
    "    return sorted(vc[vc.eq(vc.max())].index)[0]\n",
    "\n",
    "def token_overlap_score(a: str, b: str) -> float:\n",
    "    ta, tb = set(a.split()), set(b.split())\n",
    "    if not ta or not tb: return 0.0\n",
    "    inter, union = len(ta & tb), len(ta | tb)\n",
    "    return inter/union\n",
    "\n",
    "# === 데이터 로드 ===\n",
    "df_user = pd.read_csv(USER_CSV, encoding=\"utf-8-sig\")\n",
    "df_ref  = pd.read_csv(REF_CSV, sep=\"|\", encoding=\"utf-8-sig\", engine=\"python\", on_bad_lines=\"skip\")\n",
    "df_ref.columns = [c.split(\",\")[0].strip() for c in df_ref.columns]\n",
    "\n",
    "# === 사용자 gender 보존 ===\n",
    "if \"gender\" in df_user.columns:\n",
    "    df_user = df_user.rename(columns={\"gender\": \"gender_orig\"})\n",
    "\n",
    "# === 컬럼 지정 ===\n",
    "user_brand_col = \"brand\"\n",
    "user_name_col  = \"eng_name\" if \"eng_name\" in df_user.columns else \"name_eng\"\n",
    "ref_brand_col  = \"brand\"\n",
    "ref_name_col   = \"name\"\n",
    "\n",
    "# === 정규화 키 ===\n",
    "df_user[\"_brand_norm\"] = df_user[user_brand_col].map(clean_name)\n",
    "df_user[\"_name_norm\"]  = df_user[user_name_col].map(clean_name)\n",
    "df_user[\"_key0\"]       = df_user.apply(lambda r: norm_key(r[user_brand_col], r[user_name_col]), axis=1)\n",
    "\n",
    "df_ref[\"_brand_norm\"] = df_ref[ref_brand_col].map(clean_name)\n",
    "df_ref[\"_name_norm\"]  = df_ref[ref_name_col].map(clean_name)\n",
    "df_ref[\"_key0\"]       = df_ref.apply(lambda r: norm_key(r[ref_brand_col], r[ref_name_col]), axis=1)\n",
    "\n",
    "# === 1) brand+name 정확 매칭 ===\n",
    "ref_gender_by_key = (\n",
    "    df_ref.groupby(\"_key0\", as_index=False)[\"gender\"]\n",
    "          .agg(mode_or_nan)\n",
    "          .rename(columns={\"gender\":\"gender_ref\"})\n",
    ")\n",
    "m1 = df_user.merge(ref_gender_by_key, on=\"_key0\", how=\"left\", validate=\"m:1\")\n",
    "m1[\"gender_filled\"] = m1[\"gender_ref\"]\n",
    "\n",
    "# === 2) name-only 매칭 ===\n",
    "ref_gender_by_name = (\n",
    "    df_ref.groupby(\"_name_norm\", as_index=False)[\"gender\"]\n",
    "          .agg(mode_or_nan)\n",
    "          .rename(columns={\"gender\":\"gender_ref2\"})\n",
    ")\n",
    "mask = m1[\"gender_filled\"].isna()\n",
    "m1.loc[mask, \"gender_filled\"] = (\n",
    "    m1.loc[mask].merge(ref_gender_by_name, on=\"_name_norm\", how=\"left\")[\"gender_ref2\"].values\n",
    ")\n",
    "\n",
    "# === 3) 퍼지 매칭(브랜드 블록 + 후보 제한) ===\n",
    "FUZZY_AUTO = 0.90\n",
    "FUZZY_REVIEW_FLOOR = 0.80\n",
    "remain = m1[m1[\"gender_filled\"].isna()].copy()\n",
    "review_rows = []\n",
    "\n",
    "if not remain.empty:\n",
    "    ref_blocks = {b: grp for b, grp in df_ref.groupby(\"_brand_norm\")}\n",
    "    for idx, row in remain.iterrows():\n",
    "        b = row[\"_brand_norm\"]\n",
    "        q = row[\"_name_norm\"]\n",
    "        cand_grp = ref_blocks.get(b, df_ref)\n",
    "        cand_names = cand_grp[\"_name_norm\"].dropna().unique().tolist()\n",
    "        if not cand_names:\n",
    "            continue\n",
    "        prelim = sorted(((cand, token_overlap_score(q, cand)) for cand in cand_names),\n",
    "                        key=lambda x: x[1], reverse=True)[:40]  # 상위 40개만 상세검사\n",
    "        best_name, best_score = None, 0.0\n",
    "        for cand, _ in prelim:\n",
    "            sc = SequenceMatcher(None, q, cand).ratio()\n",
    "            if sc > best_score:\n",
    "                best_score, best_name = sc, cand\n",
    "        if best_name and best_score >= FUZZY_REVIEW_FLOOR:\n",
    "            g = mode_or_nan(cand_grp[cand_grp[\"_name_norm\"] == best_name][\"gender\"])\n",
    "            if best_score >= FUZZY_AUTO:\n",
    "                m1.at[idx, \"gender_filled\"] = g\n",
    "            else:\n",
    "                review_rows.append({\n",
    "                    \"brand_input\": row[user_brand_col],\n",
    "                    \"eng_name_input\": row[user_name_col],\n",
    "                    \"suggested_name_norm\": best_name,\n",
    "                    \"suggested_gender\": g,\n",
    "                    \"similarity\": round(best_score, 4)\n",
    "                })\n",
    "\n",
    "# === 4) 최종 gender 합치기 ===\n",
    "if \"gender_orig\" in m1.columns:\n",
    "    m1[\"gender_final\"] = m1[\"gender_orig\"].where(m1[\"gender_orig\"].notna(), m1[\"gender_filled\"])\n",
    "else:\n",
    "    m1[\"gender_final\"] = m1[\"gender_filled\"]\n",
    "\n",
    "# === 5) 저장 ===\n",
    "final_out = m1.drop(columns=[\"_key0\",\"gender_ref\",\"gender_ref2\",\"gender_filled\"], errors=\"ignore\")\n",
    "final_out.to_csv(OUT_CSV, index=False, encoding=\"utf-8-sig\")\n",
    "pd.DataFrame(review_rows).to_csv(REVIEW_CSV, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"✅ 저장 완료:\", OUT_CSV)\n",
    "print(\"검토 필요 목록:\", REVIEW_CSV)\n",
    "print(\"총 행:\", len(final_out))\n",
    "print(\"최종 gender 채움 비율:\", final_out[\"gender_final\"].notna().mean())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scentlab_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
